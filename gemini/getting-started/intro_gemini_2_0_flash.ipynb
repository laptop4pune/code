{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laptop4pune/code/blob/master/gemini/getting-started/intro_gemini_2_0_flash.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# _1113_6BacktesterV6.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime # Import datetime for timestamp IDs\n",
        "import uuid  # Keep uuid import in case it's used elsewhere, although not for generate_trade_id now\n",
        "import sys # Import sys to check for handlers\n",
        "# from _012_instruments import get_instrument_type # Removed unused import\n",
        "# --- Logging Configuration ---\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Also ensure the root logger has a handler and is set to DEBUG,\n",
        "# in case basicConfig was called elsewhere previously.\n",
        "if not logging.root.handlers:\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "else:\n",
        "    # If handlers exist, ensure at least one handler's level is DEBUG\n",
        "    # and the root logger's level is DEBUG\n",
        "    logging.root.setLevel(logging.DEBUG)\n",
        "    handler_found = False\n",
        "    for handler in logging.root.handlers:\n",
        "        if isinstance(handler, logging.StreamHandler) and handler.stream in [sys.stdout, sys.stderr]:\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler_found = True\n",
        "    # If no suitable handler is found (e.g., only file handlers), add a StreamHandler\n",
        "    if not handler_found:\n",
        "         stream_handler = logging.StreamHandler(sys.stdout)\n",
        "         stream_handler.setLevel(logging.DEBUG)\n",
        "         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "         stream_handler.setFormatter(formatter)\n",
        "         logging.root.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "print(\"Logging level set to DEBUG for test.\")\n",
        "\n",
        "# Examine the __init__ method for data validation logic\n",
        "# Check for the existence of the required_columns and log warnings for potential entry/exit data columns.\n",
        "\n",
        "# required_columns check\n",
        "# missing_required = [col for col in required_columns if col not in data.columns]\n",
        "# if missing_required:\n",
        "#      raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "# entry_columns_to_check and exit_data_columns_to_check check\n",
        "# missing_data_cols = [col for col in entry_columns_to_check + exit_data_columns_to_check if col not in data.columns]\n",
        "# if missing_data_cols:\n",
        "#      logger.warning(f\"Input data is missing potential indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records.\")\n",
        "\n",
        "# The current code already performs these checks.\n",
        "# required_columns are checked and raise a ValueError if missing.\n",
        "# entry_columns_to_check and exit_data_columns_to_check are checked and log a warning if missing.\n",
        "\n",
        "# Add comments to clarify assumptions about columns expected in input data.\n",
        "\n",
        "class BacktesterV3:\n",
        "    \"\"\"\n",
        "    A simple backtesting engine for evaluating trading strategies.\n",
        "    Processes historical data bar by bar, generates signals, and simulates trades.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, instrument_keys: list, active_strategies_instances: dict, initial_capital: float):\n",
        "        \"\"\"\n",
        "        Includes the same parameters as the original __init__\n",
        "\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            data: A pandas DataFrame containing historical market data for all instruments,\n",
        "                expected to have columns like 'timestamp', 'instrument_key',\n",
        "                'open', 'high', 'low', 'close', 'volume', etc. It is also expected\n",
        "                to contain pre-calculated indicator and pattern columns used by\n",
        "                the strategies and for recording trade details.\n",
        "            instrument_keys: A list of unique instrument keys present in the data.\n",
        "            active_strategies_instances: A dictionary where keys are strategy names\n",
        "                                        (strings) and values are instantiated strategy\n",
        "                                        objects with a `generate_signal(data_point)` method.\n",
        "            initial_capital: The starting capital for the backtest simulation.\n",
        "        \"\"\"\n",
        "        if data is None or data.empty:\n",
        "            raise ValueError(\"Input data DataFrame is None or empty.\")\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n",
        "        if data.index.name is not None:\n",
        "            logger.warning(\"Input data index is not None. Consider resetting the index before passing to Backtester.\")\n",
        "\n",
        "\n",
        "        # Ensure essential columns are present and sorted\n",
        "        required_columns = ['timestamp', 'instrument_key', 'open', 'high', 'low', 'close']\n",
        "        # Define columns expected to be in the input data for recording trade details.\n",
        "        # These are typically pre-calculated indicators or pattern detection results.\n",
        "        entry_exit_data_columns_expected = [\n",
        "            'Trend', 'SMA20', 'RSI', 'RSIMA', 'ATR', 'ADX', 'Volatility',\n",
        "            'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "            'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "            'name', 'interval', 'Currency',\n",
        "            'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "            'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price'\n",
        "        ]\n",
        "\n",
        "        # The backtester expects these columns to be pre-calculated and provided in the input data.\n",
        "        # Strategies generate signals based on these columns, and their values at the time of\n",
        "        # entry and exit are recorded in the completed_trades DataFrame.\n",
        "\n",
        "\n",
        "        # Perform a relaxed check: log a warning if potential entry/exit columns from data are missing\n",
        "        missing_data_cols = [col for col in entry_exit_data_columns_expected if col not in data.columns]\n",
        "        if missing_data_cols:\n",
        "            logger.warning(f\"Input data is missing expected indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records. Ensure your data preparation includes these columns if strategies or analysis depend on them.\")\n",
        "\n",
        "\n",
        "        # Ensure mandatory required columns are present\n",
        "        missing_required = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_required:\n",
        "            raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "\n",
        "        # Ensure timestamp is datetime and sorted\n",
        "        try:\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
        "                data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True) # Convert to UTC\n",
        "            # Drop rows where timestamp conversion failed\n",
        "            data = data.dropna(subset=['timestamp'])\n",
        "            # Sort by timestamp and then instrument_key to process bars chronologically per instrument\n",
        "            self.data = data.sort_values(by=['timestamp', 'instrument_key']).reset_index(drop=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing timestamp column in data: {e}\")\n",
        "\n",
        "\n",
        "        self.instrument_keys = instrument_keys\n",
        "        self.active_strategies_instances = active_strategies_instances\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # --- Backtesting State Variables ---\n",
        "        self.current_capital = initial_capital\n",
        "        self.positions = {}  # Dictionary to track open positions {instrument_key: {...entry details...}}\n",
        "        self.completed_trades = [] # List to store completed trades\n",
        "        self.trade_id_counter = 0 # Simple counter for trade IDs\n",
        "        self.debug_log = [] # List to store debug information\n",
        "\n",
        "        # Debug lists to capture values\n",
        "        self._debug_timestamps = []\n",
        "        self._debug_close_values = []\n",
        "        self._debug_validity = []\n",
        "\n",
        "        # Simple Slippage and Commission model (can be customized)\n",
        "        self.slippage_pct = 0.001  # 0.1% slippage per trade\n",
        "        self.commission_per_trade = 0.01 # $0.01 fixed commission per trade\n",
        "\n",
        "\n",
        "        logger.info(f\"BacktesterV2 initialized with {len(self.instrument_keys)} instruments and {len(self.active_strategies_instances)} active strategies.\")\n",
        "        logger.info(f\"Initial Capital: {self.initial_capital}\")\n",
        "        logger.info(f\"Data shape for backtesting: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def generate_trade_id(self, timestamp: datetime):\n",
        "        \"\"\"Generates a unique trade ID using a provided timestamp.\"\"\"\n",
        "        # Using microseconds to increase the chance of uniqueness\n",
        "        return timestamp.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    def execute_trade(self, trade_id: str, instrument_key: str, timestamp: datetime, signal: str, strategy_name: str, price: float, data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Simulates executing a trade based on a signal.\n",
        "\n",
        "        Args:\n",
        "            trade_id: Unique identifier for the trade.\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the trade execution (bar close time).\n",
        "            signal: The trading signal ('BUY' or 'SELL').\n",
        "            strategy_name: The name of the strategy generating the signal.\n",
        "            price: The execution price (typically the close price of the bar).\n",
        "            data_point: The pandas Series representing the data row for this bar. This Series\n",
        "                        is expected to contain pre-calculated indicators and pattern data\n",
        "                        used for entry/exit conditions and recording.\n",
        "        \"\"\"\n",
        "        # Determine instrument type to handle lot size/quantity logic\n",
        "        # instrument_type = get_instrument_type(instrument_key) # Removed due to import error\n",
        "        instrument_type = 'Unknown' # Placeholder\n",
        "\n",
        "\n",
        "        # Simple fixed quantity logic (can be replaced with dynamic position sizing)\n",
        "        quantity_to_trade = 1 # Example: trade 1 unit/lot\n",
        "\n",
        "        if signal == 'BUY':\n",
        "            # Check if we already have a position in this instrument (optional, depending on strategy)\n",
        "            if instrument_key not in self.positions:\n",
        "                # Simulate buying\n",
        "                cost = quantity_to_trade * price\n",
        "                # Check if we have enough capital\n",
        "                if self.current_capital >= cost:\n",
        "                    self.current_capital -= cost\n",
        "\n",
        "                    # Calculate entry costs (slippage and commission on entry)\n",
        "                    entry_slippage = cost * self.slippage_pct\n",
        "                    entry_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (entry_slippage + entry_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Capture entry-specific details from the data_point and other variables\n",
        "                    self.positions[instrument_key] = {\n",
        "                        'quantity': quantity_to_trade,\n",
        "                        'entry_price': price, # This is the execution price for this simple model\n",
        "                        'entry_time': timestamp,\n",
        "                        'strategy': strategy_name,\n",
        "                        'trade_id': trade_id,\n",
        "                        'instrument_type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'side': 'BUY', # Store trade side\n",
        "\n",
        "                        # --- Entry-Specific Columns (Populated from data_point at Entry) ---\n",
        "                        'Strategy_name': strategy_name,\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'name': data_point.get('name'), # Use .get() to avoid errors if column is missing\n",
        "                        'interval': data_point.get('interval'),\n",
        "                        'Position_type': 'Long', # Assuming BUY means Long position\n",
        "                        'Entry_order_type': 'Market', # Assuming market order execution on close\n",
        "                        'Entry_timestamp': timestamp,\n",
        "                        'Entry_price_trigger': None, # Not explicitly handled in this simple model\n",
        "                        'Entry_price_execution': price,\n",
        "                        'Entry_shares': quantity_to_trade, # Using quantity_to_trade as shares\n",
        "                        'Entry_cost': cost, # Gross cost before fees\n",
        "                        'Entry_signal_type': signal,\n",
        "                        'Entry_Trend': data_point.get('Trend'), # Capture Trend at Entry\n",
        "                        'Entry_SMA20': data_point.get('SMA20'), # Capture SMA20 at Entry\n",
        "                        'Entry_RSI': data_point.get('RSI'), # Capture RSI at Entry\n",
        "                        'Entry_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Entry\n",
        "                        'Entry_ATR': data_point.get('ATR'), # Capture ATR at Entry\n",
        "                        'Entry_ADX': data_point.get('ADX'), # Capture ADX at Entry\n",
        "                        'Entry_Volatility': data_point.get('Volatility'), # Capture Volatility at Entry\n",
        "                        'Entry_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Entry\n",
        "                        'Entry_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Entry\n",
        "                        'Entry_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Entry\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Entry\n",
        "                        'Instrument_Type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'Currency': data_point.get('Currency'),\n",
        "                        'Slippage_Entry': entry_slippage, # Store entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Store entry commission\n",
        "\n",
        "                        # Placeholder for other entry-specific details that might be calculated by strategy (e.g., initial stop/target)\n",
        "                        'Initial_Stop_Loss_Distance (%)': data_point.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': data_point.get('Risk_Amount'),\n",
        "                        'Reward_Amount': data_point.get('Reward_Amount'),\n",
        "\n",
        "\n",
        "                        # Placeholders for exit/other info that will be filled on close\n",
        "                        # These fields are included here so the structure is consistent for retrieval on exit,\n",
        "                        # even though their values are None at the time of entry.\n",
        "                         'Max_Favorable_Excursion_MFE': None, # Will be calculated on exit\n",
        "                         'Max_Adverse_Excursion_MAE': None, # Will be calculated on exit\n",
        "                        'Current_trailing_stop': None, # Need logic for trailing stops\n",
        "                        'Trailing_stop_method': None,\n",
        "                        'Trailing_stop_value': None,\n",
        "                        'Stop_loss_price': None,\n",
        "\n",
        "\n",
        "                        'Exit_Trend': None, 'Exit_signal_type': None, 'Exit_SMA20': None,\n",
        "                        'Exit_RSI': None, 'Exit_RSI_MA': None, 'Exit_ATR': None, 'Exit_ADX': None,\n",
        "                        'Exit_Volatility': None, 'Exit_Breakout_Detected': None,\n",
        "                        'Exit_Breakdown_Detected': None, 'Exit_Bullish_Candlestick_Name': None,\n",
        "                        'Exit_Bearish_Candlestick_Name': None, 'Exit_Bullish_Chart_Pattern_Detected': None,\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': None, 'Exit_shares': None,\n",
        "                        'Exit_cost': None, 'Exit_revenue': None, 'PnL_trade': None,\n",
        "                        'Trade_type': None, 'Profit_loss': None, 'Exit_reason': None,\n",
        "                        'Slippage': None, 'Commission_Fees': None, 'Trade_Duration': None,\n",
        "                        'Exit_Order_Type': None\n",
        "                    }\n",
        "\n",
        "                    # --- Add debug logging for Entry columns here ---\n",
        "                    logger.debug(f\"DEBUG Entry Data Point for {instrument_key} at {timestamp}:\")\n",
        "                    debug_cols_to_check = [\n",
        "                        'Trend', 'SMA20', 'RSI', 'RSI_MA', 'ATR', 'ADX', 'Volatility',\n",
        "                        'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "                        'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "                        'Currency', 'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "                        'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE', 'Current_trailing_stop',\n",
        "                        'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price', 'Exit_Trend',\n",
        "                        'Exit_signal_type', 'Exit_SMA20', 'Exit_RSI', 'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX',\n",
        "                        'Exit_Volatility', 'Exit_Breakout_Detected', 'Exit_Breakdown_Detected',\n",
        "                        'Exit_Bullish_Candlestick_Name', 'Exit_Bearish_Candlestick_Name',\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected', 'Exit_Bearish_Chart_Pattern_Detected',\n",
        "                        'Exit_cost'\n",
        "                    ]\n",
        "                    for col in debug_cols_to_check:\n",
        "                         logger.debug(f\"  {col}: {data_point.get(col, 'Column Not Found or None')}\")\n",
        "                    # --- End Debug Logging ---\n",
        "\n",
        "\n",
        "                    logger.info(f\"Executed BUY trade {trade_id} for {instrument_key} at {timestamp} @ {price} (Qty: {quantity_to_trade}). Costs: Slippage={entry_slippage:.4f}, Commission={entry_commission:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'BUY', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'slippage': entry_slippage, 'commission': entry_commission})\n",
        "                else:\n",
        "                    logger.warning(f\"Insufficient capital ({self.current_capital:.2f}) to BUY {instrument_key} at {price} (Cost: {cost:.2f}). Skipping trade {trade_id}.\")\n",
        "                    self.debug_log.append({'type': 'SKIP_BUY_CAPITAL', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Insufficient Capital'})\n",
        "\n",
        "            else:\n",
        "                # Already in a position, maybe add to it or skip depending on strategy rules\n",
        "                logger.debug(f\"Skipping BUY signal for {instrument_key} at {timestamp}. Already in a position.\")\n",
        "                self.debug_log.append({'type': 'SKIP_BUY_POSITION', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Already in Position'})\n",
        "\n",
        "\n",
        "        elif signal == 'SELL':\n",
        "            # For backtesting, a 'SELL' signal usually means closing a long position or opening a short position\n",
        "            # Let's assume 'SELL' means closing a long position if one exists for simplicity in this example.\n",
        "            # For a shorting strategy, you'd need different logic.\n",
        "            if instrument_key in self.positions and self.positions[instrument_key]['side'] == 'BUY':\n",
        "                # Simulate selling to close a long position\n",
        "                position = self.positions[instrument_key]\n",
        "                quantity_to_sell = position['quantity']\n",
        "                entry_price = position['entry_price']\n",
        "                entry_time = position['entry_time']\n",
        "                strategy_opened = position['strategy']\n",
        "                open_trade_id = position['trade_id']\n",
        "\n",
        "\n",
        "                revenue = quantity_to_sell * price\n",
        "                self.current_capital += revenue\n",
        "\n",
        "                # Calculate Profit/Loss (Gross PnL)\n",
        "                gross_pnl = (price - entry_price) * quantity_to_sell # For long position\n",
        "\n",
        "                # Calculate exit costs (slippage and commission on exit)\n",
        "                exit_slippage = revenue * self.slippage_pct\n",
        "                exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "                # Calculate Net PnL\n",
        "                total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "                total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "                pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "                # Calculate Trade Duration\n",
        "                trade_duration = (timestamp - entry_time).total_seconds() if pd.notnull(timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "                # Record completed trade - Populate all desired columns\n",
        "                trade_record = {\n",
        "                    'open_trade_id': open_trade_id,\n",
        "                    'close_trade_id': trade_id,\n",
        "                    'instrument_key': instrument_key,\n",
        "                    'instrument_type': position.get('instrument_type'), # Assuming this key is correct in position\n",
        "                    'side': position.get('side'), # Side of the position being closed (BUY/LONG)\n",
        "                    'quantity': quantity_to_sell, # Quantity closed\n",
        "                    'entry_price': entry_price,\n",
        "                    'entry_time': entry_time,\n",
        "                    'exit_price': price,\n",
        "                    'exit_time': timestamp,\n",
        "                    'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "                    'strategy_opened': strategy_opened,\n",
        "                    'strategy_closed': strategy_name, # Record which strategy/signal closed it\n",
        "\n",
        "                    # --- Transfer Entry Details from Position ---\n",
        "                    'Strategy_name': position.get('Strategy_name'),\n",
        "                    'instrument_key': position.get('instrument_key'),\n",
        "                    'name': position.get('name'),\n",
        "                    'interval': position.get('interval'),\n",
        "                    'Position_type': position.get('Position_type'),\n",
        "                    'Entry_order_type': position.get('Entry_order_type'),\n",
        "                    'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                    'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                    'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                    'Entry_shares': position.get('Entry_shares'),\n",
        "                    'Entry_cost': position.get('Entry_cost'),\n",
        "                    'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                    'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                    'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                    'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                    'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                    'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                    'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                    'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                    'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                    'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                    'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Detected'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                    'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Detected'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                    'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Detected_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                    'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Detected_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                    'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                    'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                    'Slippage_Entry': position.get('Slippage_Entry'), # Transfer entry slippage\n",
        "                    'Commission_Fees_Entry': position.get('Commission_Fees_Entry'), # Transfer entry commission\n",
        "                    'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                    'Risk_Amount': position.get('Risk_Amount'),\n",
        "                    'Reward_Amount': position.get('Reward_Amount'),\n",
        "                    'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                    'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                    # --- Exit-Specific Columns (Populated from data_point at Exit) ---\n",
        "                    'Exit_Trend': data_point.get('Exit_Trend'), # Capture Trend at Exit\n",
        "                    'Exit_signal_type': signal, # Signal that triggered the exit\n",
        "                    'Exit_SMA20': data_point.get('Exit_SMA20'), # Capture SMA20 at Exit\n",
        "                    'Exit_RSI': data_point.get('Exit_RSI'), # Capture RSI at Exit\n",
        "                    'Exit_RSI_MA': data_point.get('Exit_RSI_MA'), # Capture RSI_MA at Exit\n",
        "                    'Exit_ATR': data_point.get('Exit_ATR'), # Capture ATR at Exit\n",
        "                    'Exit_ADX': data_point.get('Exit_ADX'), # Capture ADX at Exit\n",
        "                    'Exit_Volatility': data_point.get('Exit_Volatility'), # Capture Volatility at Exit\n",
        "                    'Exit_Breakout_Detected': data_point.get('Exit_Breakout_Detected'), # Capture Breakout_Detected at Exit\n",
        "                    'Exit_Breakdown_Detected': data_point.get('Exit_Breakdown_Detected'), # Capture Breakdown_Detected at Exit\n",
        "                    'Exit_Bullish_Candlestick_Name': data_point.get('Exit_Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Exit\n",
        "                    'Exit_Bearish_Candlestick_Name': data_point.get('Exit_Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Exit\n",
        "                    'Exit_Bullish_Chart_Pattern_Detected': data_point.get('Exit_Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Exit\n",
        "                    'Exit_Bearish_Chart_Pattern_Detected': data_point.get('Exit_Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Exit\n",
        "                    'Exit_shares': quantity_to_sell, # Shares exited\n",
        "                    'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "                    'Exit_revenue': revenue, # Gross revenue before fees\n",
        "                    'PnL_trade': pnl_trade, # Net PnL after costs\n",
        "                    'Trade_type': 'Long Close (Signal)', # Or 'Long' if trade refers to the full cycle\n",
        "                    'Profit_loss': pnl_trade, # Update Profit_loss to net PnL\n",
        "                    'Exit_reason': f'Signal_{signal}', # Reason for exit\n",
        "                    'Exit_Order_Type': 'Market', # Set Exit_Order_Type to 'Market'\n",
        "\n",
        "                    # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                    'Current_trailing_stop': data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                    'Trailing_stop_method': data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                    'Trailing_stop_value': data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                    'Stop_loss_price': data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "                    'Slippage': total_slippage, # Total slippage for the round trip\n",
        "                    'Commission_Fees': total_commission, # Total commission for the round trip\n",
        "                    'Trade_Duration': trade_duration,\n",
        "\n",
        "                }\n",
        "                self.completed_trades.append(trade_record)\n",
        "\n",
        "\n",
        "                # Remove position\n",
        "                del self.positions[instrument_key]\n",
        "\n",
        "                logger.info(f\"Executed SELL trade {trade_id} for {instrument_key} at {timestamp} @ {price} to CLOSE long position {open_trade_id}. Gross PnL: {gross_pnl:.2f}. Costs: Slippage={total_slippage:.4f}, Commission={total_commission:.2f}. Net PnL: {pnl_trade:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                self.debug_log.append({'type': 'SELL_CLOSE_LONG', 'open_trade_id': open_trade_id, 'close_trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_sell, 'gross_pnl': gross_pnl, 'net_pnl': pnl_trade, 'strategy_closed': strategy_name})\n",
        "\n",
        "\n",
        "            else:\n",
        "                # No matching long position to close, or maybe a shorting signal\n",
        "                # For this simple backtester, we'll just log and skip if no long position\n",
        "                logger.debug(f\"Skipping SELL signal for {instrument_key} at {timestamp}. No matching long position to close.\")\n",
        "                self.debug_log.append({'type': 'SKIP_SELL_NO_LONG', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'strategy': strategy_name, 'reason': 'No Long Position'})\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the backtesting simulation bar by bar through the data.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting backtest simulation...\")\n",
        "\n",
        "        # Group data by timestamp first, then iterate through timestamps\n",
        "        # This processes all instruments available at a given time before moving to the next time.\n",
        "        grouped_by_time = self.data.groupby('timestamp')\n",
        "\n",
        "        for timestamp, time_slice_df in grouped_by_time:\n",
        "            # Process data for all instruments available at this timestamp\n",
        "            for index, data_point in time_slice_df.iterrows():\n",
        "                instrument_key = data_point['instrument_key']\n",
        "                current_price = data_point['close'] # Assume close price for execution\n",
        "\n",
        "                # Debug capture\n",
        "                self._debug_timestamps.append(timestamp)\n",
        "                self._debug_close_values.append(current_price)\n",
        "                self._debug_validity.append(pd.notna(current_price))\n",
        "\n",
        "                # Ensure current_price is valid for trading\n",
        "                if pd.isna(current_price):\n",
        "                    logger.debug(f\"Skipping signal generation for {instrument_key} at {timestamp} due to invalid close price ({current_price}).\")\n",
        "                    self.debug_log.append({'type': 'SKIP_SIGNAL_PRICE_NAN', 'instrument': instrument_key, 'time': timestamp, 'reason': 'Invalid Price'})\n",
        "                    continue # Skip this data point if price is invalid\n",
        "\n",
        "                # Check for signals from all active strategies for this data point\n",
        "                # Pass the single data_point (as a Series) to the strategy\n",
        "                # The strategy is expected to handle a single row/Series or convert it internally\n",
        "                # For the backtester's execute_trade, we need the Series directly.\n",
        "\n",
        "                for strategy_name, strategy_instance in self.active_strategies_instances.items():\n",
        "                    try:\n",
        "                        # Pass the single data_point Series to the strategy's generate_signal\n",
        "                        # Ensure data_point is passed as a DataFrame slice if strategy expects DataFrame\n",
        "                        signal = strategy_instance.generate_signal(pd.DataFrame([data_point]))\n",
        "                        # Ensure signal is a string, handle potential None returns gracefully\n",
        "                        signal = str(signal).upper() if signal is not None else 'HOLD'\n",
        "\n",
        "                        if signal in ['BUY', 'SELL']:\n",
        "                            # Generate a unique trade ID for this potential trade using the bar's timestamp\n",
        "                            trade_id = self.generate_trade_id(timestamp) # Pass the historical timestamp\n",
        "                            # Pass the original data_point Series to execute_trade\n",
        "                            self.execute_trade(trade_id, instrument_key, timestamp, signal, strategy_name, current_price, data_point)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error generating signal for {instrument_key} at {timestamp} using strategy '{strategy_name}': {e}\", exc_info=True)\n",
        "                        self.debug_log.append({'type': 'STRATEGY_ERROR', 'instrument': instrument_key, 'time': timestamp, 'strategy': strategy_name, 'error': str(e)})\n",
        "\n",
        "\n",
        "        # After iterating through all data, close any remaining open positions\n",
        "        self.close_all_positions(self.data['timestamp'].max()) # Use the timestamp of the last data point as exit time\n",
        "\n",
        "        logger.info(\"Backtest simulation completed.\")\n",
        "        logger.info(f\"Final Capital: {self.current_capital:.2f}\")\n",
        "        logger.info(f\"Number of completed trades: {len(self.completed_trades)}\")\n",
        "        logger.info(f\"Number of open positions remaining: {len(self.positions)}\")\n",
        "\n",
        "        # Return completed trades as a DataFrame for analysis\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "            # Ensure numeric columns are numeric\n",
        "            numeric_cols = [\n",
        "                'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "            ]\n",
        "            for col in numeric_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "            return completed_trades_df\n",
        "        else:\n",
        "            logger.warning(\"No completed trades recorded. Returning empty DataFrame.\")\n",
        "            return pd.DataFrame() # Return empty DataFrame if no trades\n",
        "\n",
        "\n",
        "    def close_all_positions(self, exit_timestamp: datetime):\n",
        "        \"\"\"\n",
        "        Closes all remaining open positions at the specified exit timestamp.\n",
        "        Assumes closing at the price of the last available bar for each instrument.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Closing all remaining {len(self.positions)} open positions at {exit_timestamp}...\")\n",
        "\n",
        "        # Get the last known price and data point for each instrument with an open position\n",
        "        last_data_points = self.data.groupby('instrument_key').tail(1).set_index('instrument_key')\n",
        "        last_prices = last_data_points['close'].to_dict()\n",
        "\n",
        "\n",
        "        positions_to_close = list(self.positions.keys()) # Iterate over a copy\n",
        "\n",
        "        for instrument_key in positions_to_close:\n",
        "            if instrument_key in self.positions: # Check if position still exists (wasn't closed by a signal just before the end)\n",
        "                position = self.positions[instrument_key]\n",
        "                closing_price = last_prices.get(instrument_key, np.nan) # Get last price, default to NaN if instrument not found\n",
        "\n",
        "                # Get the last data point for the instrument to capture exit conditions\n",
        "                last_data_point = last_data_points.get(instrument_key, pd.Series({})) # Use empty Series if no data found\n",
        "\n",
        "\n",
        "                if pd.notna(closing_price):\n",
        "                    trade_id = self.generate_trade_id(exit_timestamp) # Generate a new trade ID for the closing trade using exit_timestamp\n",
        "                    # Simulate selling to close a long position\n",
        "                    quantity_to_sell = position['quantity']\n",
        "                    entry_price = position['entry_price']\n",
        "                    entry_time = position['entry_time']\n",
        "                    strategy_opened = position['strategy']\n",
        "                    open_trade_id = position['trade_id']\n",
        "\n",
        "\n",
        "                    revenue = quantity_to_sell * closing_price\n",
        "                    self.current_capital += revenue\n",
        "\n",
        "                    # Calculate Profit/Loss (Gross PnL)\n",
        "                    gross_pnl = (closing_price - entry_price) * quantity_to_sell # For long position\n",
        "\n",
        "                    # Calculate exit costs (slippage and commission on exit)\n",
        "                    exit_slippage = revenue * self.slippage_pct\n",
        "                    exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Calculate Net PnL\n",
        "                    total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "                    total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "                    pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "\n",
        "                    # Calculate Trade Duration\n",
        "                    trade_duration = (exit_timestamp - entry_time).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "\n",
        "                    # Record completed trade - Populate all desired columns\n",
        "                    trade_record = {\n",
        "                        'open_trade_id': open_trade_id,\n",
        "                        'close_trade_id': trade_id, # New ID for closing\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'), # Use .get() for safety\n",
        "                        'side': position.get('side'), # Side of the position being closed (BUY/LONG)\n",
        "                        'quantity': quantity_to_sell, # Quantity closed\n",
        "                        'entry_price': entry_price,\n",
        "                        'entry_time': entry_time,\n",
        "                        'exit_price': closing_price,\n",
        "                        'exit_time': exit_timestamp, # Use the provided exit timestamp\n",
        "                        'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "                        'strategy_opened': strategy_opened,\n",
        "                        'strategy_closed': 'Backtester_Forced_Close', # Indicate it was closed by the backtester\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': position.get('Slippage_Entry'), # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': position.get('Commission_Fees_Entry'), # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Exit_Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close', # Indicate forced close\n",
        "                        'Exit_SMA20': last_data_point.get('Exit_SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('Exit_RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('Exit_RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('Exit_ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('Exit_ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Exit_Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Exit_Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Exit_Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Exit_Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Exit_Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Exit_Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Exit_Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': quantity_to_sell, # Shares exited\n",
        "                        'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "                        'Exit_revenue': revenue, # Gross revenue before fees\n",
        "                        'PnL_trade': pnl_trade, # Net PnL after costs\n",
        "                        'Trade_type': 'Long Close (Forced)', # Or 'Long' if trade refers to the full cycle\n",
        "                        'Profit_loss': pnl_trade, # Update Profit_loss to net PnL\n",
        "                        'Exit_reason': 'Backtester_Forced_Close', # Reason for exit\n",
        "                        'Exit_Order_Type': 'Market', # Set Exit_Order_Type to 'Market' or 'Forced'\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "\n",
        "                        'Slippage': total_slippage, # Total slippage for the round trip\n",
        "                        'Commission_Fees': total_commission, # Total commission for the round trip\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(trade_record)\n",
        "\n",
        "                    # Remove position\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "                    logger.info(f\"Closed remaining position {open_trade_id} for {instrument_key} at {exit_timestamp} @ {closing_price}. Gross PnL: {gross_pnl:.2f}. Costs: Slippage={total_slippage:.4f}, Commission={total_commission:.2f}. Net PnL: {pnl_trade:.2f}. Capital: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE', 'open_trade_id': open_trade_id, 'close_trade_id': trade_id, 'instrument': instrument_key, 'time': exit_timestamp, 'price': closing_price, 'quantity': quantity_to_sell, 'gross_pnl': gross_pnl, 'net_pnl': pnl_trade, 'strategy_closed': 'Backtester_Forced_Close'})\n",
        "\n",
        "                else:\n",
        "                    logger.warning(f\"Could not find last price for {instrument_key}. Cannot close position {position['trade_id']}. Logging as unresolved.\")\n",
        "                    # Log as an unresolved position or assume zero PnL\n",
        "\n",
        "                    # Calculate Trade Duration even if closing price is NaN\n",
        "                    trade_duration = (exit_timestamp - position.get('entry_time')).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(position.get('entry_time')) else None\n",
        "\n",
        "                    # Transfer known costs\n",
        "                    entry_slippage = position.get('Slippage_Entry', 0)\n",
        "                    entry_commission = position.get('Commission_Fees_Entry', 0)\n",
        "\n",
        "\n",
        "                    unresolved_trade_record = {\n",
        "                        'open_trade_id': position.get('trade_id'),\n",
        "                        'close_trade_id': None, # No closing trade ID\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'),\n",
        "                        'side': position.get('side'),\n",
        "                        'quantity': position.get('quantity'),\n",
        "                        'entry_price': position.get('entry_price'),\n",
        "                        'entry_time': position.get('entry_time'),\n",
        "                        'exit_price': None, # No exit price\n",
        "                        'exit_time': exit_timestamp, # Use the requested exit timestamp\n",
        "                        'pnl': 0, # Assume zero Gross PnL if cannot close\n",
        "                        'strategy_opened': position.get('strategy'),\n",
        "                        'strategy_closed': 'Backtester_Forced_Close_Error', # Indicate error\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': entry_slippage, # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close_Error', # Indicate forced close error\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': position.get('quantity'), # Shares that were supposed to be exited\n",
        "                        'Exit_cost': 0,\n",
        "                        'Exit_revenue': 0, # Assuming zero revenue if cannot close\n",
        "                        'PnL_trade': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Profit_loss': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Exit_reason': 'Backtester_Forced_Close_Error: No_Last_Price', # Reason for exit\n",
        "                        'Exit_Order_Type': None, # Could not execute exit order\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "                        'Slippage': entry_slippage, # Only entry slippage is known\n",
        "                        'Commission_Fees': entry_commission, # Only entry commission is known\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(unresolved_trade_record)\n",
        "\n",
        "                    # Remove position even if it couldn't be closed properly to prevent it from being processed again\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE_ERROR', 'open_trade_id': position['trade_id'], 'instrument': instrument_key, 'time': exit_timestamp, 'reason': 'Last price not available'})\n",
        "\n",
        "\n",
        "        logger.info(\"All remaining positions closed.\")\n",
        "\n",
        "\n",
        "    def analyze_backtest_results(self):\n",
        "        \"\"\"\n",
        "        Analyzes the completed trades and provides performance metrics.\n",
        "        Returns a DataFrame summarizing the analysis.\n",
        "        \"\"\"\n",
        "        logger.info(\"Analyzing backtest results...\")\n",
        "\n",
        "        if not self.completed_trades:\n",
        "            logger.warning(\"No completed trades to analyze.\")\n",
        "            return pd.DataFrame({'Message': ['No completed trades to analyze.']})\n",
        "\n",
        "        # 1. Access the self.completed_trades list and Create a pandas DataFrame\n",
        "        trades_df = pd.DataFrame(self.completed_trades)\n",
        "\n",
        "        # 3. Ensure that relevant columns are converted to appropriate numeric types\n",
        "        numeric_cols = [\n",
        "            'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "            'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "            'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "            'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "            'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "            'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "            'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "            'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Include other potentially numeric cols\n",
        "        ]\n",
        "        for col in numeric_cols:\n",
        "            if col in trades_df.columns:\n",
        "                trades_df[col] = pd.to_numeric(trades_df[col], errors='coerce')\n",
        "\n",
        "        # Handle potential NaN values during conversion - drop rows where PnL_trade (or pnl) is NaN\n",
        "        pnl_col_for_analysis = 'PnL_trade' if 'PnL_trade' in trades_df.columns else 'pnl'\n",
        "        if pnl_col_for_analysis in trades_df.columns:\n",
        "            # Only consider trades with a valid PnL for core analysis metrics\n",
        "            trades_df_analysis = trades_df.dropna(subset=[pnl_col_for_analysis]).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "        else:\n",
        "            logger.warning(\"Neither 'PnL_trade' nor 'pnl' column found for analysis.\")\n",
        "            return pd.DataFrame({'Message': ['No PnL column found for analysis.']})\n",
        "\n",
        "\n",
        "        if trades_df_analysis.empty:\n",
        "            logger.warning(\"No valid trades after numeric conversion/dropna for analysis. Analysis stopped.\")\n",
        "            return pd.DataFrame({'Message': ['No valid trades after numeric conversion/dropna for analysis.']})\n",
        "\n",
        "\n",
        "        # 4. Update the calculation of basic performance metrics using 'PnL_trade'\n",
        "        total_trades = len(trades_df_analysis)\n",
        "        total_pnl = trades_df_analysis[pnl_col_for_analysis].sum()\n",
        "\n",
        "        winning_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] > 0]\n",
        "        losing_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] < 0]\n",
        "        breakeven_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] == 0]\n",
        "\n",
        "        num_winning = len(winning_trades)\n",
        "        num_losing = len(losing_trades)\n",
        "        num_breakeven = len(breakeven_trades)\n",
        "\n",
        "        win_rate = (num_winning / total_trades) * 100 if total_trades > 0 else 0\n",
        "        avg_win = winning_trades[pnl_col_for_analysis].mean() if num_winning > 0 else 0\n",
        "        avg_loss = losing_trades[pnl_col_for_analysis].mean() if num_losing > 0 else 0\n",
        "        expectancy = (win_rate / 100) * avg_win + ((100 - win_rate) / 100) * avg_loss if total_trades > 0 else 0\n",
        "\n",
        "        # 5. Update Max Drawdown calculation to use 'PnL_trade' and sort by exit time\n",
        "        # Calculate cumulative PnL and then cumulative capital\n",
        "        trades_df_analysis = trades_df_analysis.sort_values(by='exit_time') # Sort by exit time for cumulative calculation\n",
        "\n",
        "        trades_df_analysis['cumulative_pnl'] = trades_df_analysis[pnl_col_for_analysis].cumsum()\n",
        "\n",
        "        # Add initial capital to cumulative PnL\n",
        "        trades_df_analysis['cumulative_capital'] = self.initial_capital + trades_df_analysis['cumulative_pnl']\n",
        "\n",
        "        # Calculate peak capital up to each point\n",
        "        trades_df_analysis['peak_capital'] = trades_df_analysis['cumulative_capital'].cummax()\n",
        "\n",
        "        # Calculate drawdown at each point\n",
        "        trades_df_analysis['drawdown'] = trades_df_analysis['peak_capital'] - trades_df_analysis['cumulative_capital']\n",
        "\n",
        "        # Calculate percentage drawdown\n",
        "        # Avoid division by zero if peak_capital is 0 or None\n",
        "        trades_df_analysis['pct_drawdown'] = trades_df_analysis.apply(\n",
        "            lambda row: (row['drawdown'] / row['peak_capital']) * 100 if row['peak_capital'] > 0 and pd.notna(row['peak_capital']) else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        max_drawdown_amount = trades_df_analysis['drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "        max_drawdown_pct = trades_df_analysis['pct_drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "\n",
        "\n",
        "        # 6. Update analysis summary metric names\n",
        "        analysis_summary = {\n",
        "            'Metric': [\n",
        "                'Initial Capital',\n",
        "                'Final Capital',\n",
        "                'Total PnL (Net)', # Indicate Net PnL\n",
        "                'Total Trades',\n",
        "                'Winning Trades (Net)', # Indicate Net PnL\n",
        "                'Losing Trades (Net)', # Indicate Net PnL\n",
        "                'Breakeven Trades (Net)', # Indicate Net PnL\n",
        "                'Win Rate (%) (Net PnL)', # Indicate Net PnL\n",
        "                'Average Win (Net)', # Indicate Net PnL\n",
        "                'Average Loss (Net)', # Indicate Net PnL\n",
        "                'Expectancy per Trade (Net)', # Indicate Net PnL\n",
        "                'Max Drawdown (Amount)',\n",
        "                'Max Drawdown (%)',\n",
        "            ],\n",
        "            'Value': [\n",
        "                self.initial_capital,\n",
        "                self.current_capital,\n",
        "                round(total_pnl, 2), # Format to 2 decimal places\n",
        "                total_trades,\n",
        "                num_winning,\n",
        "                num_losing,\n",
        "                num_breakeven,\n",
        "                round(win_rate, 2), # Format to 2 decimal places\n",
        "                round(avg_win, 2),\n",
        "                round(avg_loss, 2),\n",
        "                round(expectancy, 2),\n",
        "                round(max_drawdown_amount, 2),\n",
        "                round(max_drawdown_pct, 2),\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        analysis_df = pd.DataFrame(analysis_summary)\n",
        "\n",
        "        logger.info(\"Backtest analysis completed.\")\n",
        "        # You can print the analysis_df here or return it\n",
        "        # print(\"\\n--- Backtest Analysis Summary ---\")\n",
        "        # display(analysis_df) # Use display for notebooks\n",
        "\n",
        "        # 8. Ensure the method returns the updated analysis summary DataFrame\n",
        "        return analysis_df\n",
        "\n",
        "    def get_completed_trades(self):\n",
        "        \"\"\"Returns a DataFrame of completed trades.\"\"\"\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "                    # Ensure numeric columns are numeric\n",
        "                    numeric_cols = [\n",
        "                        'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                        'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                        'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                        'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                        'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                        'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                        'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                        'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                        'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "                    ]\n",
        "                    for col in numeric_cols:\n",
        "                        if col in completed_trades_df.columns:\n",
        "                            completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "                    return completed_trades_df\n",
        "                else:\n",
        "                    return pd.DataFrame() # Return empty DataFrame if no trades"
      ],
      "metadata": {
        "id": "QXzyczIPw3dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#_1113_mainV2.py\n",
        "\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "import logging\n",
        "from IPython.display import display\n",
        "\n",
        "import websockets\n",
        "import os\n",
        "import pytz # Import the pytz library for timezone handling\n",
        "import datetime # Import datetime for timestamp conversions\n",
        "import json # Import json for potentially logging raw message content if not protobuf\n",
        "import json # Import the json library\n",
        "import talib\n",
        "\n",
        "from _1111_1_FnoINELV1 import header_df\n",
        "from _1111_1_market_utils import is_market_open, get_exchange_status  # Import functions\n",
        "from _1111_historical_data_retrievalV1 import get_historical_data\n",
        "from _1111_intraday_data_retrievalV1 import fetch_intraday_data\n",
        "from _1111_web_1clean_and_transform import clean_and_transform, clean_data\n",
        "from _1111_web_4combine_dataV2 import combine_data\n",
        "import MarketDataFeedV3_pb2 as pb2 # Import your generated protobuf file\n",
        "from _1111_websocket_connection3 import connectwebsocket\n",
        "from _1111_web_5socket_connectionresample import RealTimeResampler # Assuming RealTimeResampler is in this file for modification\n",
        "from _1111_web_3clean_and_transform_incremental import IncrementalDataTransformer\n",
        "from _1113_5Trendline import TrendlineDetector\n",
        "from _1113_1BullishCandlestickPatternv1 import BullishCandlestickPatterns\n",
        "from _1113_2BearishCandlestickPatternv1 import BearishCandlestickPatterns\n",
        "from _1113_3BullishChartPatternsV1 import BullishChartPatterns\n",
        "from _1113_4BearishChartPatternsV1 import BearishChartPatterns\n",
        "from _1113_6BacktesterV6 import BacktesterV3\n",
        "from _1113_7strategy_CombinedSignal import CombinedSignalStrategy\n",
        "from _1113_6strategy_TrendFollowing import TrendFollowingStrategy\n",
        "from _1113_6strategy_TrendFollowingV1 import TrendFollowingStrategyV1\n",
        "\n",
        "\n",
        "# from _1113_5Trendline import TrendlineDetector\n",
        "# from _1113_1BullishCandlestickPattern import BullishCandlestickPatterns\n",
        "# from _1113_2BearishCandlestickPattern import BearishCandlestickPatterns\n",
        "# from _1113_3BullishChartPatterns import BullishChartPatterns\n",
        "# from _1113_4BearishChartPatterns import BearishChartPatterns\n",
        "# from _1113_6Backtester import Backtester\n",
        "\n",
        "\n",
        "# Import technical indicator functions - ensure this module exists and is accessible\n",
        "try:\n",
        "    from _1112_technical_indicatorsV2 import (calculate_RSI_MA,\n",
        "        calculate_SMA20, calculate_RSI, calculate_RSI_MA, calculate_EMA,\n",
        "        calculate_pivot_points, calculate_MACD, calculate_ATR, calculate_ADX,\n",
        "        calculate_BollingerBands, calculate_MA, calculate_volatility,\n",
        "        calculate_VWAP, calculate_WMA, calculate_FibonacciRetracement, calculate_MACD_pandas_ta\n",
        "\n",
        "    )\n",
        "    print(\"Successfully imported technical indicator functions.\")\n",
        "except ImportError:\n",
        "    print(\"Warning: Could not import technical indicator functions from _1112_technical_indicators.\")\n",
        "    # Define placeholder functions or handle this error appropriately if needed\n",
        "    def calculate_SMA20(df, window=20): return pd.Series(index=df.index)\n",
        "    def calculate_RSI(series, period=14): return pd.Series(index=series.index)\n",
        "    def calculate_RSI_MA(series, rsi_length=14, ma_length=14): return pd.Series(index=series.index)\n",
        "    def calculate_EMA(df, window=20): return pd.Series(index=df.index)\n",
        "    def calculate_pivot_points(df): return {'Pivot': pd.Series(index=df.index), 'S1': pd.Series(index=df.index), 'S2': pd.Series(index=df.index),'S3': pd.Series(index=df.index), 'R1': pd.Series(index=df.index), 'R2': pd.Series(index=df.index), 'R3': pd.Series(index=df.index)}\n",
        "    def calculate_MACD(df, fastperiod=12, slowperiod=26, signalperiod=9): return (pd.Series(index=df.index), pd.Series(index=df.index), pd.Series(index=df.index))\n",
        "    def calculate_ATR(df, timeperiod=14): return pd.Series(index=df.index)\n",
        "    def calculate_ADX(df, timeperiod=14): return pd.Series(index=df.index)\n",
        "    def calculate_BollingerBands(df, window=20, num_std_dev=2): return (pd.Series(index=df.index), pd.Series(index=df.index), pd.Series(index=df.index))\n",
        "    def calculate_MA(df, window=20): return pd.Series(index=df.index)\n",
        "    def calculate_volatility(df, window=20): return pd.Series(index=df.index)\n",
        "    def calculate_VWAP(df): return pd.Series(index=df.index)\n",
        "    def calculate_WMA(df, window=20): return pd.Series(index=df.index)\n",
        "    def calculate_FibonacciRetracement(high, low): return {} # Return empty dict or similar placeholder\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO) # Configure logging format and handlers\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,  # Set the minimum logging level\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  # Define the log message format\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),  # Log to the console\n",
        "        # logging.FileHandler('app.log')  # Log to a file (optional)\n",
        "    ])\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "nest_asyncio.apply()\n",
        "loop = asyncio.get_event_loop() # Get the event loop globally\n",
        "\n",
        "# Create a global asyncio.Event object for signaling shutdown\n",
        "shutdown_event = asyncio.Event()\n",
        "\n",
        "print(\"Shutdown event created.\")\n",
        "\n",
        "\n",
        "# Extract instrument keys from header_df\n",
        "instrument_keys = header_df['instrument_key'].unique().tolist()\n",
        "\n",
        "\n",
        "# Global variables\n",
        "merged_data = {}\n",
        "paper_trades = []\n",
        "completed_trades = [] # Initialize globally\n",
        "combined_df = None  # Define combined_df outside the function\n",
        "# Create an instance of TrendlineDetector\n",
        "trendline_detector = TrendlineDetector(combined_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# *** PLACE THE HELPER FUNCTION DEFINITIONS HERE ***\n",
        "# These functions should be defined *before* the async def main(): block\n",
        "\n",
        "def get_instrument_type(instrument_key):\n",
        "    \"\"\"Determines instrument type based on key.\"\"\"\n",
        "    # Example implementation - Adapt based on your instrument key format or header_df\n",
        "    if pd.isna(instrument_key): return 'Unknown'\n",
        "    if 'NSE_EQ' in str(instrument_key): return 'Equity'\n",
        "    if 'NSE_FUT' in str(instrument_key): return 'Futures'\n",
        "    if 'NSE_OPT' in str(instrument_key): return 'Options'\n",
        "    if 'NSE_INDEX' in str(instrument_key): return 'Index'\n",
        "    return 'Unknown' # Default\n",
        "\n",
        "\n",
        "def get_instrument_currency(instrument_key):\n",
        "    \"\"\"Determines currency based on key.\"\"\"\n",
        "    if pd.isna(instrument_key):\n",
        "        return 'Unknown'\n",
        "    instrument_key_upper = str(instrument_key).upper()\n",
        "\n",
        "    if 'NSE_CUR' in instrument_key_upper or 'BSE_CUR' in instrument_key_upper:\n",
        "        # Currency derivatives might specify currency pairs, but generally traded in INR\n",
        "        # You might need more complex logic here if dealing with specific currency pairs\n",
        "        return 'INR' # Currency derivatives are settled in INR in India\n",
        "    elif 'MCX' in instrument_key_upper or 'NSE_COM' in instrument_key_upper:\n",
        "        return 'INR' # Commodities in India are traded in INR\n",
        "    elif 'NSE_' in instrument_key_upper or 'BSE_' in instrument_key_upper:\n",
        "        # Assuming all other NSE/BSE instruments (Equity, F&O, Index) are INR\n",
        "        return 'INR'\n",
        "    # Add logic for other currencies if you trade international instruments\n",
        "\n",
        "    return 'Unknown' # Default\n",
        "\n",
        "def determine_entry_order_type(signal):\n",
        "    \"\"\"Determines the intended order type based on the signal.\"\"\"\n",
        "    # Example implementation - Adapt based on your strategy's execution logic\n",
        "    if signal in ['BUY', 'SELL']:\n",
        "        return 'Market' # Assume market execution for entry signals\n",
        "    # Add other conditions if your strategy uses limit or stop orders for entry\n",
        "    return 'N/A_Signal' # Or 'HOLD_Signal' etc.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def main():\n",
        "\n",
        "    global merged_data, paper_trades, combined_df, completed_trades # Add completed_trades here\n",
        "    combined_df = pd.DataFrame()  # Initialize as an empty DataFrame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Read access token\n",
        "    with open(\"accessToken.txt\", \"r\") as file:\n",
        "        access_token = file.read().strip()\n",
        "\n",
        "    # Get instrument details\n",
        "    # Get instrument details\n",
        "    input_data = header_df[['instrument_key', 'name', 'expiry', 'lot_size', 'max_lot_size']]\n",
        "    instrument_keys = input_data['instrument_key'].unique().tolist()  # Use unique() to get unique keys\n",
        "\n",
        "    # Time intervals for historical data\n",
        "    intervals = [\"1minute\", \"day\"]\n",
        "\n",
        "    # Trading Mode (choose one: 'backtest', 'paper', 'live')\n",
        "    # trading_mode =  'paper', 'live' # <--- This is a tuple, should be a single string\n",
        "    trading_mode = 'backtest' # 'paper'   # 'backtest' # 'paper'  Or 'paper' or 'live' or 'backtest'\n",
        "\n",
        "    print(\"Current Trading Mode:\", trading_mode)\n",
        "\n",
        "\n",
        "    # 1. Fetch Historical Data\n",
        "    # Fetch historical data only if needed (e.g., for initial combined_df or backtesting)\n",
        "    historical_data = await get_historical_data(instrument_keys)\n",
        "\n",
        "    # 2. Clean and Transform Historical Data\n",
        "    try:\n",
        "        historical_data_future = loop.run_in_executor(None, clean_and_transform, historical_data, True)\n",
        "        cleaned_historical_data = await historical_data_future\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during clean_and_transform for historical data: {e}\")\n",
        "        cleaned_historical_data = pd.DataFrame()  # Assign empty DataFrame if error\n",
        "\n",
        "\n",
        "    if isinstance(cleaned_historical_data, pd.DataFrame):\n",
        "        logger.info(f\"main: Shape of cleaned_historical_data after clean_and_transform: {cleaned_historical_data.shape}\")\n",
        "        if not cleaned_historical_data.empty:\n",
        "            logger.info(f\"main: Columns in cleaned_historical_data: {cleaned_historical_data.columns.tolist()}\")\n",
        "            if 'close' in cleaned_historical_data.columns:\n",
        "                logger.info(f\"main: 'close' column dtype in cleaned_historical_data: {cleaned_historical_data['close'].dtype}\")\n",
        "                logger.info(f\"main: Count of non-NaN 'close' values in cleaned_historical_data: {cleaned_historical_data['close'].count()}\")\n",
        "            else:\n",
        "                logger.info(f\"main: 'close' column NOT PRESENT in cleaned_historical_data.\")\n",
        "    else:\n",
        "        logger.warning(f\"main: cleaned_historical_data is not a DataFrame after clean_and_transform. Type: {type(cleaned_historical_data)}\")\n",
        "\n",
        "    # 3. Fetch Intraday Data (Needed for backtesting on recent data or initial paper/live context)\n",
        "    intraday_data = await fetch_intraday_data(instrument_keys)\n",
        "\n",
        "    # 4. Clean and Transform Intraday Data (if available)\n",
        "    if intraday_data is not None and not intraday_data.empty:\n",
        "        try:\n",
        "            intraday_data_future = loop.run_in_executor(None, clean_and_transform, intraday_data)\n",
        "            cleaned_intraday_data = await intraday_data_future\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during clean_and_transform for intraday data: {e}\")\n",
        "            cleaned_intraday_data = pd.DataFrame()  # Assign empty DataFrame if error\n",
        "    else:\n",
        "        cleaned_intraday_data = pd.DataFrame(columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'oi', 'instrument_key', 'name', 'interval'])\n",
        "\n",
        "\n",
        "    # 5. Combine Data (Needed for backtesting or providing initial context for paper/live)\n",
        "    print(\"Before combine_data\")\n",
        "    logger.info(\"Before combine_data execution\")\n",
        "    combine_future = loop.run_in_executor(None, combine_data, cleaned_historical_data, cleaned_intraday_data if not cleaned_intraday_data.empty else None, instrument_keys)\n",
        "    try:\n",
        "        merged_data = await combine_future\n",
        "        combined_df = merged_data\n",
        "        if combined_df is not None and isinstance(combined_df, pd.DataFrame) and combined_df.index.name == 'timestamp': # Check if timestamp is the index and combined_df is valid\n",
        "            combined_df = combined_df.reset_index() # Make it a column\n",
        "\n",
        "#####*************************************************************\n",
        "\n",
        "        # Now 'timestamp' will be a column if it was the index and combined_df is valid\n",
        "\n",
        "        # Replaced prints with logger.debug/info\n",
        "        logger.debug(f\"Columns in combined_df after combine_data and potential reset_index: {combined_df.columns.tolist() if isinstance(combined_df, pd.DataFrame) else 'combined_df is None'}\")\n",
        "        if combined_df is not None:\n",
        "            if 'timestamp' in combined_df.columns:\n",
        "                logger.debug(\"'timestamp' column now exists in combined_df\")\n",
        "            else:\n",
        "                logger.debug(\"'timestamp' column still does NOT exist in combined_df\")\n",
        "\n",
        "            logger.info(f\"After combine_data, combined_df shape: {combined_df.shape}\")\n",
        "\n",
        "            # Display head (using display for notebooks) - Removed redundant print labels\n",
        "            print(\"\\nCombined DataFrame Head (first 10 rows):\") # Optional print to label the display\n",
        "            display(combined_df.head(10)) # Using display for Jupyter, showing 10 rows\n",
        "\n",
        "            if 'interval' in combined_df.columns:\n",
        "                # Replaced print with logger.debug\n",
        "                logger.debug(f\"Unique intervals in combined_df: {combined_df['interval'].unique()}\")\n",
        "            else:\n",
        "                # Replaced print with logger.warning\n",
        "                logger.warning(\"'interval' column not found in combined_df.\")\n",
        "        else:\n",
        "             # Replaced print with logger.warning\n",
        "             logger.warning(\"combined_df is None after combine_data.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        # Replaced print with logger.error\n",
        "        logger.error(f\"Error during combine_data: {e}\", exc_info=True)\n",
        "\n",
        "        combined_df = pd.DataFrame() # Ensure combined_df is defined on error\n",
        "\n",
        "\n",
        "    #####****>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***\n",
        "    #####****>>>>>>>>>>>>>>>>> ADD CODE HERE: Filter combined_df to create daily_data_df <<<<<<<<<<<***\n",
        "    #####****>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***\n",
        "\n",
        "\n",
        "    daily_data_df = pd.DataFrame() # Initialize daily_data_df\n",
        "    if combined_df is not None and not combined_df.empty and 'interval' in combined_df.columns:\n",
        "        try:\n",
        "            daily_data_df = combined_df[combined_df['interval'] == 'day'].copy() # Filter for 'day' interval and make a copy\n",
        "            if 'timestamp' in daily_data_df.columns:\n",
        "                 daily_data_df['timestamp'] = pd.to_datetime(daily_data_df['timestamp'], errors='coerce')\n",
        "                 daily_data_df = daily_data_df.dropna(subset=['timestamp'])\n",
        "            print(f\"Successfully filtered daily data from combined_df. Shape: {daily_data_df.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error filtering daily data from combined_df: {e}\")\n",
        "            daily_data_df = pd.DataFrame()\n",
        "    else:\n",
        "        print(\"Warning: combined_df is not available, is empty, or missing 'interval' column. Cannot filter daily data.\")\n",
        "        daily_data_df = pd.DataFrame()\n",
        "\n",
        "    # *** ADD CODE HERE: Calculate actual_backtest_duration_years from the FULL combined_df ***\n",
        "    first_data_timestamp = None\n",
        "    last_data_timestamp = None\n",
        "    actual_backtest_duration_years = 0\n",
        "\n",
        "    if combined_df is not None and not combined_df.empty:\n",
        "        try:\n",
        "            if isinstance(combined_df.index, pd.DatetimeIndex):\n",
        "                first_data_timestamp = combined_df.index.min()\n",
        "                last_data_timestamp = combined_df.index.max()\n",
        "            elif 'timestamp' in combined_df.columns and pd.api.types.is_datetime64_any_dtype(combined_df['timestamp']):\n",
        "                 first_data_timestamp = combined_df['timestamp'].min()\n",
        "                 last_data_timestamp = combined_df['timestamp'].max()\n",
        "\n",
        "            if pd.notna(first_data_timestamp) and pd.notna(last_data_timestamp) and last_data_timestamp > first_data_timestamp:\n",
        "                 time_difference = last_data_timestamp - first_data_timestamp\n",
        "                 actual_backtest_duration_years = time_difference.days / 365.25\n",
        "                 print(f\"Debug: Calculated actual backtest duration from combined_df: {time_difference} ({actual_backtest_duration_years:.2f} years)\")\n",
        "            else:\n",
        "                 print(\"Warning: Calculated data duration from combined_df is zero or negative.\")\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"Error determining actual backtest duration from combined_df: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Warning: combined_df is not available or is empty, cannot calculate actual backtest duration.\")\n",
        "\n",
        "\n",
        "#####*****************************************************************************************#####\n",
        "    # 6.  ADD THE PATTERN DETECTION AND PROCESSING SNIPPET HERE ---\n",
        "    if isinstance(combined_df, pd.DataFrame) and not combined_df.empty: # Use isinstance check as well\n",
        "        print(\"\\nProceeding with pattern detection on combined_df...\")\n",
        "        # Assuming your data for pattern detection is now combined_df\n",
        "        data_for_pattern_detection = combined_df.copy() # Make a copy to be safe\n",
        "\n",
        "        processed_data_list = [] # List to collect DataFrames for each instrument after adding pattern columns\n",
        "\n",
        "        # Group data by instrument\n",
        "        for (instrument_key, name, interval), group_data in data_for_pattern_detection.groupby(['instrument_key', 'name', 'interval']):\n",
        "            # print(f\"Processing patterns for: {instrument_key}, {name}, {interval}\")\n",
        "\n",
        "            # --- Ensure group_data is a copy to avoid SettingWithCopyWarning ---\n",
        "            group_data = group_data.copy()\n",
        "\n",
        "            # --- Calculate Technical Indicators (including Trend) ---\n",
        "\n",
        "            # Recalculate MA, HH, LL for group_data as these are needed for the trend logic\n",
        "            window_size = 20 # Or your chosen window size for trend calculation\n",
        "\n",
        "            # Ensure 'close' column exists before calculations\n",
        "            # Add this print BEFORE the if statement\n",
        "            # print(f\"Debug Check: About to check for 'close' column in group_data for {instrument_key},{name}, {interval}. Columns available: {group_data.columns.tolist()}\")\n",
        "\n",
        "            if 'close' in group_data.columns:\n",
        "                # This is the original line, we can keep it or add more specific prints\n",
        "                # print(f\"Calculating MA, HH, LL, and Trend for {instrument_key},{name} with window {window_size}\")\n",
        "\n",
        "                # Add more prints inside the if block if needed\n",
        "                # print(f\"Debug Check: 'close' column FOUND for {instrument_key},{name}, {interval}. Proceeding with MA, HH, LL, Trend calculation.\")\n",
        "                # You could also print the head of the close column here if you want to see values\n",
        "\n",
        "                # Calculate rolling indicators\n",
        "                group_data['MA'] = group_data['close'].rolling(window=window_size).mean()\n",
        "                group_data['HH'] = group_data['close'].rolling(window=window_size).max()\n",
        "                group_data['LL'] = group_data['close'].rolling(window=window_size).min()\n",
        "                # --- Add debug prints after rolling calculations ---\n",
        "                logger.debug(f\"Debug Rolling: After MA, HH, LL calculation for {group_data.name}. Shape: {group_data.shape}\")\n",
        "\n",
        "                # Ensure 'Trend' column exists with a default value before applying the function\n",
        "                group_data['Trend'] = 'Sideways'\n",
        "\n",
        "                # Define the get_trend_for_row function (keep this inside the loop or define it outside)\n",
        "                # Let's define it inside the loop for now for simplicity, it captures the loop's 'window_size'\n",
        "                def get_trend_for_row(row, df_full_slice, current_window):\n",
        "                    # Use the index within the current slice for relative positioning\n",
        "                    try:\n",
        "                        pos_idx_list = df_full_slice.index.get_indexer([row.name])\n",
        "                        if len(pos_idx_list) == 0 or pos_idx_list[0] == -1:\n",
        "                            # Should not happen if row is from df_full_slice, but safety check\n",
        "                            return \"Calculation Error\"\n",
        "                        pos_idx = pos_idx_list[0]\n",
        "\n",
        "\n",
        "                        if pos_idx < current_window - 1:\n",
        "                            return 'Sideways'\n",
        "\n",
        "                        # Use iloc for positional indexing relative to the start of the slice\n",
        "                        start_window_pos_idx = pos_idx - current_window + 1\n",
        "                        # No need to check < 0 here due to pos_idx < current_window - 1 check above\n",
        "\n",
        "                        # Get the start row of the window using positional index on the slice\n",
        "                        start_window_row = df_full_slice.iloc[start_window_pos_idx]\n",
        "\n",
        "                        # Safely access calculated columns from both the current row and the start-of-window row\n",
        "                        # Access the already calculated MA, HH, LL for the current row and the start_window_row\n",
        "                        current_ma = row.get('MA', np.nan)\n",
        "                        current_hh = row.get('HH', np.nan)\n",
        "                        current_ll = row.get('LL', np.nan)\n",
        "\n",
        "                        start_ma = start_window_row.get('MA', np.nan)\n",
        "                        start_hh = start_window_row.get('HH', np.nan)\n",
        "                        start_ll = start_window_row.get('LL', np.nan)\n",
        "\n",
        "\n",
        "                        # Check if calculated values are valid (not NaN or None) for comparison\n",
        "                        if pd.isna(current_ma) or pd.isna(current_hh) or pd.isna(current_ll) or \\\n",
        "                        pd.isna(start_ma) or pd.isna(start_hh) or pd.isna(start_ll):\n",
        "                            return \"Sideways\" # Cannot determine trend if any value is missing\n",
        "\n",
        "\n",
        "                        # Determine trend based on conditions\n",
        "                        # Compare current MA, HH, LL with those at the start of the rolling window\n",
        "                        if current_ma > start_ma and \\\n",
        "                        current_hh > start_hh and \\\n",
        "                        current_ll > start_ll:\n",
        "                            return 'Uptrend'\n",
        "                        elif current_ma < start_ma and \\\n",
        "                            current_hh < start_hh and \\\n",
        "                            current_ll < start_ll:\n",
        "                            return 'Downtrend'\n",
        "                        else:\n",
        "                            return 'Sideways'\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # This catch is inside the apply function now\n",
        "                        print(f\"Error in get_trend_for_row at index {row.name} for {instrument_key},{name}, {interval}: {e}\")\n",
        "                        return \"Calculation Error\" # Return an error status for this specific row\n",
        "\n",
        "\n",
        "                # Apply the trend logic only to rows where the window is fully available within this slice\n",
        "                try: # Add a try block around the apply for specific error handling\n",
        "                    if len(group_data) >= window_size: # Check for sufficient data length in the slice\n",
        "                            group_data.loc[group_data.index[window_size - 1]:, 'Trend'] = group_data.iloc[window_size - 1:].apply(\n",
        "                            lambda row: get_trend_for_row(row, group_data.iloc[window_size - 1:], window_size), axis=1 # Apply to the sliced part and pass the sliced part\n",
        "                        )\n",
        "\n",
        "                        # The rows before window_size - 1 remain 'Sideways' as initialized\n",
        "                    else:\n",
        "                        # If the total length of group_data is less than the window, all trends are 'Sideways' (already the default)\n",
        "                        pass # No change needed, 'Trend' is already 'Sideways'\n",
        "                    logger.debug(f\"Debug Pattern Check: Successfully added 'Trend' column for {instrument_key},{name}, {interval} using rolling window logic.\") # This logger.debug is good to keep for debugging\n",
        "                    # print(f\"Debug Pattern Check: Successfully added 'Trend' column for {instrument_key},{name}, {interval} using rolling window logic.\")\n",
        "\n",
        "                except Exception as apply_e:\n",
        "                    print(f\"Error applying trend calculation for {instrument_key},{name}, {interval}: {apply_e}\")\n",
        "                    # Add a default 'Trend' column with 'Calculation Error' if apply fails\n",
        "                    group_data['Trend'] = 'Calculation Error' # Overwrite the entire column or just the remaining rows? Let's overwrite for clarity.\n",
        "                    print(f\"Debug Pattern Check: Added 'Trend' column with 'Calculation Error' due to error for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(f\"Warning: 'close' column not found for {instrument_key},{name}, skipping trend calculation.\")\n",
        "                # Ensure columns exist even if 'close' is missing\n",
        "                if 'MA' not in group_data.columns: group_data['MA'] = None\n",
        "                if 'HH' not in group_data.columns: group_data['HH'] = None\n",
        "                if 'LL' not in group_data.columns: group_data['LL'] = None\n",
        "\n",
        "\n",
        "            # Ensure the 'Trend' column exists after calculation attempts\n",
        "            if 'Trend' not in group_data.columns:\n",
        "                group_data['Trend'] = 'Sideways'\n",
        "                logger.warning(f\"Debug: 'Trend' column was missing after calculation attempts, added as 'Sideways' for {instrument_key},{name}.\")\n",
        "            else:\n",
        "                logger.debug(f\"Debug Trend: 'Trend' column found after calculation attempt for {group_data.name}.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # --- Calculate Support and Resistance Levels ---\n",
        "            try:\n",
        "                # Instantiate TrendlineDetector with group_data\n",
        "                # ENSURE THIS LINE IS PRESENT AND EXECUTED BEFORE CALLING METHODS ON trend_detector\n",
        "                trend_detector = TrendlineDetector(group_data.copy()) # Create a new instance here\n",
        "\n",
        "\n",
        "                # Call the find_support_resistance method on the instance\n",
        "                # Use the same window_size or a different one as appropriate\n",
        "                support, resistance = trend_detector.find_support_resistance(window=window_size) # Using window_size here\n",
        "\n",
        "                # Store these levels in new columns\n",
        "                # Storing lists directly in DataFrame columns can sometimes be less performant\n",
        "                # but for backtesting summary or occasional access it might be acceptable.\n",
        "                # Ensure the column names are consistent with how you'll use them later.\n",
        "                group_data['Support_Levels'] = [support] * len(group_data) # Store the same list for all rows\n",
        "                group_data['Resistance_Levels'] = [resistance] * len(group_data) # Store the same list for all rows\n",
        "\n",
        "\n",
        "                # print(f\"Debug: Found Support: {support}, Resistance: {resistance} for {instrument_key},{name}, {interval}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error finding Support/Resistance for {instrument_key},{name}, {interval}: {e}\")\n",
        "                # Add default columns with empty lists on error\n",
        "                group_data['Support_Levels'] = [[]] * len(group_data)\n",
        "                group_data['Resistance_Levels'] = [[]] * len(group_data)\n",
        "\n",
        "\n",
        "            # --- Detect Breakouts and Breakdowns ---\n",
        "            try:\n",
        "                # Reuse the 'trend_detector' instance initialized just above in the Support/Resistance block\n",
        "                # trend_detector = TrendlineDetector(group_data.copy()) # Only create a new instance if not created above\n",
        "\n",
        "                # Detect potential breakouts (price crossing above trendline in an assumed Uptrend context)\n",
        "                # Note: The detect_breakout method calculates its own MA trendline.\n",
        "                # You might want to refine this later to use the 'Trend' column or a different trendline.\n",
        "                breakout_points = trend_detector.detect_breakout(trendline_type='Uptrend', window=window_size) # Use window_size or another window\n",
        "\n",
        "                # Detect potential breakdowns (price crossing below trendline in an assumed Downtrend context)\n",
        "                breakdown_points = trend_detector.detect_breakout(trendline_type='Downtrend', window=window_size) # Use window_size or another window\n",
        "\n",
        "                # Store the breakout/breakdown information in boolean columns\n",
        "                # Initialize boolean columns\n",
        "                group_data['Breakout_Detected'] = False\n",
        "                group_data['Breakdown_Detected'] = False\n",
        "\n",
        "                # Mark the indices where breakouts/breakdowns were detected\n",
        "                # Ensure breakout_points and breakdown_points are lists of indices compatible with .loc\n",
        "                if breakout_points: # Check if list is not empty\n",
        "                    group_data.loc[breakout_points, 'Breakout_Detected'] = True\n",
        "                if breakdown_points: # Check if list is not empty\n",
        "                     group_data.loc[breakdown_points, 'Breakdown_Detected'] = True\n",
        "\n",
        "\n",
        "                print(f\"Debug: Found {len(breakout_points)} Breakouts and {len(breakdown_points)} Breakdowns for {instrument_key},{name}, {interval}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error detecting Breakouts/Breakdowns for {instrument_key},{name}, {interval}: {e}\")\n",
        "                # Add default boolean columns on error\n",
        "                group_data['Breakout_Detected'] = False\n",
        "                group_data['Breakdown_Detected'] = False\n",
        "\n",
        "\n",
        "            # --- Detect Triangle Pattern ---\n",
        "            try:\n",
        "                # Reuse the 'trend_detector' instance initialized earlier in the loop\n",
        "                # trend_detector = TrendlineDetector(group_data.copy()) # Only create a new instance if not created above\n",
        "\n",
        "                # Call the detect_triangle_pattern method on the instance\n",
        "                # Use the same window_size or a different one as appropriate\n",
        "                triangle_pattern = trend_detector.detect_triangle_pattern(window=window_size) # Using window_size here\n",
        "\n",
        "                # Store the detected triangle pattern type in a new column\n",
        "                # Ensure the column name is consistent with how you'll use it later.\n",
        "                group_data['Triangle_Pattern'] = triangle_pattern\n",
        "\n",
        "                print(f\"Debug: Detected Triangle Pattern: '{triangle_pattern}' for {instrument_key},{name}, {interval}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error detecting Triangle Pattern for {instrument_key},{name}, {interval}: {e}\")\n",
        "                # Add a default column with 'Unknown' or None on error\n",
        "                group_data['Triangle_Pattern'] = 'Unknown' # Add default string value\n",
        "                print(f\"Debug: Added 'Triangle_Pattern' column with 'Unknown' due to error for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # --- Chart Pattern Detectors - Instantiate here with group_data ---\n",
        "            # Re-instantiate with the updated group_data that now has Trend, MA, HH, LL\n",
        "            try:\n",
        "                bullish_chart_pattern_detector = BullishChartPatterns(group_data)\n",
        "                bearish_chart_pattern_detector = BearishChartPatterns(group_data)\n",
        "                print(f\"Debug Pattern Check: Chart Pattern Detectors re-instantiated with updated group_data for {instrument_key},{name}, {interval}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error re-instantiating Chart Pattern Detectors for {instrument_key},{name}, {interval}: {e}\")\n",
        "                bullish_chart_pattern_detector = None # Set to None if re-instantiation fails\n",
        "                bearish_chart_pattern_detector = None # Set to None if re-instantiation fails\n",
        "\n",
        "            # --- CALL THE DETECT METHODS AND ADD THE RESULTS AS NEW COLUMNS ---\n",
        "            # Chart Pattern Detection\n",
        "            # Assuming these methods return a Series or list of pattern names, or None/NaN\n",
        "            # Ensure the method names and return types match your actual Chart Pattern classes\n",
        "            if bullish_chart_pattern_detector is not None and bearish_chart_pattern_detector is not None:\n",
        "                try: # <--- Start of inner try block for detection calls\n",
        "                    # Call the detect methods for chart patterns - Corrected method name call\n",
        "                    # Ensure these methods operate on self.df (the group_data passed during instantiation)\n",
        "                    # If they need specific data slices or arguments, adjust here\n",
        "                    bullish_chart_names_series = bullish_chart_pattern_detector.detect_bullish_chart_patterns() # Assuming this returns a Series of names or None\n",
        "                    bearish_chart_names_series = bearish_chart_pattern_detector.detect_bearish_chart_patterns() # Assuming this returns a Series of names or None\n",
        "\n",
        "\n",
        "                    # Add Chart Pattern results as columns to group_data\n",
        "                    # Ensure column names match exactly what your strategy expects ('Detected_Bullish_Chart_Pattern_Name' etc.)\n",
        "                    # Check if the results are Series or lists and handle assignment appropriately\n",
        "                    # Assign the Series directly. If a row has no pattern, the Series should have None/NaN for that index.\n",
        "                    group_data['Detected_Bullish_Chart_Pattern_Name'] = bullish_chart_names_series\n",
        "                    group_data['Detected_Bearish_Chart_Pattern_Name'] = bearish_chart_names_series\n",
        "                    logger.debug(f\"Debug Pattern Check: Successfully added Chart Pattern columns for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "                except AttributeError: # <--- except block aligned with try\n",
        "                    print(f\"Error: Chart Pattern Detector method not found for {instrument_key},{name}, {interval}. Check method name.\") # More generic error message\n",
        "                    # Add dummy columns if method call failed to prevent errors later\n",
        "                    # Ensure column names match what the strategy expects\n",
        "                    if 'Detected_Bullish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                        group_data['Detected_Bullish_Chart_Pattern_Name'] = None # Or False/'' depending on expected type\n",
        "                    if 'Detected_Bearish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                        group_data['Detected_Bearish_Chart_Pattern_Name'] = None # Or False/''\n",
        "                    logger.debug(f\"Debug Pattern Check: Added dummy Chart Pattern columns due to AttributeError for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "                except Exception as e: # <--- except block aligned with try\n",
        "                    print(f\"Error detecting and adding chart patterns for {instrument_key},{name}, {interval}: {e}\")\n",
        "                    # Add dummy columns if detection failed to prevent errors later\n",
        "                    # Ensure column names match what the strategy expects\n",
        "                    if 'Detected_Bullish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                        group_data['Detected_Bullish_Chart_Pattern_Name'] = None # Or False/''\n",
        "                    if 'Detected_Bearish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                        group_data['Detected_Bearish_Chart_Pattern_Name'] = None # Or False/''\n",
        "                    logger.debug(f\"Debug Pattern Check: Added dummy Chart Pattern columns due to error for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "            else: # <--- else block aligned with if\n",
        "                logging.warning(f\"Warning: Chart Pattern Detectors not instantiated or re-instantiated for {instrument_key},{name}, {interval}. Skipping chart pattern detection.\")\n",
        "                # Ensure dummy columns exist even if detectors weren't instantiated/re-instantiated\n",
        "                if 'Detected_Bullish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                    group_data['Detected_Bullish_Chart_Pattern_Name'] = None # Or False/''\n",
        "                if 'Detected_Bearish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                    group_data['Detected_Bearish_Chart_Pattern_Name'] = None # Or False/''\n",
        "                logger.debug(f\"Debug Pattern Check: Added dummy Chart Pattern columns due to not instantiated for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "\n",
        "            # Chart Pattern Detectors - Instantiate here with group_data\n",
        "            try:\n",
        "                # Re-instantiate if needed, or ensure the existing instances are updated with the latest group_data\n",
        "                # If the detectors were instantiated with the initial group_data.copy() before trend calculation,\n",
        "                # they might not have the 'Trend' column. It's better to re-instantiate or pass the updated group_data.\n",
        "                bullish_chart_pattern_detector = BullishChartPatterns(group_data.copy()) # Pass updated group_data\n",
        "                bearish_chart_pattern_detector = BearishChartPatterns(group_data.copy()) # Pass updated group_data\n",
        "                logger.debug(f\"Debug Pattern Check: Chart Pattern Detectors re-instantiated with updated group_data for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error re-instantiating Chart Pattern Detectors for {instrument_key},{name}, {interval}: {e}\")\n",
        "                bullish_chart_pattern_detector = None # Set to None if instantiation fails\n",
        "                bearish_chart_pattern_detector = None # Set to None if instantiation fails\n",
        "\n",
        "            # --- CALL THE DETECT METHODS AND ADD THE RESULTS AS NEW COLUMNS ---\n",
        "            # This part remains the same, operating on the potentially updated group_data\n",
        "            if bullish_chart_pattern_detector is not None and bearish_chart_pattern_detector is not None:\n",
        "                try: # <--- Start of inner try block\n",
        "                    # Call the detect methods for chart patterns\n",
        "                    bullish_chart_names_series = bullish_chart_pattern_detector.detect_bullish_chart_patterns() # Assuming this returns a Series of names or None\n",
        "                    bearish_chart_names_series = bearish_chart_pattern_detector.detect_bearish_chart_patterns() # Assuming this returns a Series of names or None\n",
        "\n",
        "                    # Add Chart Pattern results as columns to group_data\n",
        "                    # Assign the Series directly. If a row has no pattern, the Series should have None/NaN for that index.\n",
        "                    group_data['Detected_Bullish_Chart_Pattern_Name'] = bullish_chart_names_series\n",
        "                    group_data['Detected_Bearish_Chart_Pattern_Name'] = bearish_chart_names_series\n",
        "                    logger.debug(f\"Debug Pattern Check: Successfully added Chart Pattern columns for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "                except AttributeError:\n",
        "                    logger.error(f\"Error: Chart Pattern Detector method not found for {instrument_key},{name}, {interval}. Check method name.\")\n",
        "                    # Add dummy columns if method call failed\n",
        "                    if 'Detected_Bullish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                        group_data['Detected_Bullish_Chart_Pattern_Name'] = None\n",
        "                    if 'Detected_Bearish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                        group_data['Detected_Bearish_Chart_Pattern_Name'] = None\n",
        "                    logger.debug(f\"Debug Pattern Check: Added dummy Chart Pattern columns due to AttributeError.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                     logger.error(f\"Error detecting and adding chart patterns for {instrument_key},{name}, {interval}: {e}\")\n",
        "                     # Add dummy columns if detection failed\n",
        "                     if 'Detected_Bullish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                         group_data['Detected_Bullish_Chart_Pattern_Name'] = None\n",
        "                     if 'Detected_Bearish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                         group_data['Detected_Bearish_Chart_Pattern_Name'] = None\n",
        "                     logger.debug(f\"Debug Pattern Check: Added dummy Chart Pattern columns due to error.\")\n",
        "\n",
        "            else:\n",
        "                 logger.warning(f\"Warning: Chart Pattern Detectors not instantiated for {instrument_key},{name}, {interval}. Skipping chart pattern detection.\")\n",
        "                 # Ensure dummy columns exist even if detectors weren't instantiated\n",
        "                 if 'Detected_Bullish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                     group_data['Detected_Bullish_Chart_Pattern_Name'] = None\n",
        "                 if 'Detected_Bearish_Chart_Pattern_Name' not in group_data.columns:\n",
        "                     group_data['Detected_Bearish_Chart_Pattern_Name'] = None\n",
        "                 logger.debug(f\"Debug Pattern Check: Added dummy Chart Pattern columns due to not instantiated.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # --- Instantiate Pattern Classes with the current instrument's data ---\n",
        "            # Candlestick Pattern Detectors\n",
        "            try:\n",
        "                # Re-instantiate or pass updated group_data\n",
        "                bullish_Candlestick_detector = BullishCandlestickPatterns(group_data.copy()) # Pass updated group_data\n",
        "                bearish_Candlestick_detector = BearishCandlestickPatterns(group_data.copy()) # Pass updated group_data\n",
        "                logger.debug(f\"Debug Pattern Check: Candlestick Pattern Detectors re-instantiated with updated group_data for {instrument_key},{name}, {interval}.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error re-instantiating Candlestick Pattern Detectors for {instrument_key},{name}, {interval}: {e}\")\n",
        "                bullish_Candlestick_detector = None # Set to None if instantiation fails\n",
        "                bearish_Candlestick_detector = None # Set to None if instantiation fails\n",
        "\n",
        "\n",
        "\n",
        "            # Candlestick Pattern Detection\n",
        "            # Assuming these methods return a Series with True/False or 1/0 flags\n",
        "            if bullish_Candlestick_detector is not None:\n",
        "                try:\n",
        "                    # Call detection methods - Ensure they accept the DataFrame as the first argument if needed\n",
        "                    # Or ensure the detector instance was created with the correct DataFrame\n",
        "                    bullish_detected_series = bullish_Candlestick_detector.detect_bullish_candlestick_patterns(instrument_key, name, interval) # Assuming methods use the df passed during instantiation\n",
        "                    group_data['Bullish_Candlestick_Detected'] = bullish_detected_series\n",
        "                    logger.debug(f\"Debug Pattern Check: Successfully added Bullish Candlestick column for {instrument_key},{name}, {interval}.\")\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error detecting bullish candlestick patterns for {instrument_key},{name}, {interval}: {e}\")\n",
        "                    group_data['Bullish_Candlestick_Detected'] = False # Add default column on error\n",
        "                    logger.debug(f\"Debug Pattern Check: Added dummy Bullish Candlestick column due to error.\")\n",
        "\n",
        "            else:\n",
        "                logger.warning(f\"Warning: Bullish Candlestick Detector not instantiated for {instrument_key},{name}, {interval}. Skipping bullish candlestick detection.\")\n",
        "                group_data['Bullish_Candlestick_Detected'] = False # Ensure column exists\n",
        "                logger.debug(f\"Debug Pattern Check: Ensured Bullish Candlestick column exists.\")\n",
        "\n",
        "\n",
        "            if bearish_Candlestick_detector is not None:\n",
        "                try:\n",
        "                    # Call detection methods\n",
        "                    bearish_detected_series = bearish_Candlestick_detector.detect_Bearish_candlestick_patterns(instrument_key, name, interval) # Assuming methods use the df passed during instantiation\n",
        "                    group_data['Bearish_Candlestick_Detected'] = bearish_detected_series\n",
        "                    logger.debug(f\"Debug Pattern Check: Successfully added Bearish Candlestick column for {instrument_key},{name}, {interval}.\")\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error detecting bearish candlestick patterns for {instrument_key},{name}, {interval}: {e}\")\n",
        "                    group_data['Bearish_Candlestick_Detected'] = False # Add default column on error\n",
        "                    logger.debug(f\"Debug Pattern Check: Added dummy Bearish Candlestick column due to error.\")\n",
        "            else:\n",
        "                logger.warning(f\"Warning: Bearish Candlestick Detector not instantiated for {instrument_key},{name}, {interval}. Skipping bearish candlestick detection.\")\n",
        "                group_data['Bearish_Candlestick_Detected'] = False # Ensure column exists\n",
        "                logger.debug(f\"Debug Pattern Check: Ensured Bearish Candlestick column exists.\")\n",
        "\n",
        "            # Append the processed group_data to the list after adding all patterns/indicators\n",
        "            processed_data_list.append(group_data)\n",
        "\n",
        "        # After the loop, concatenate the processed data for all instruments\n",
        "        if processed_data_list:\n",
        "            # Concatenate all the processed DataFrames into df_backtest\n",
        "            df_backtest = pd.concat(processed_data_list, ignore_index=True) # Use ignore_index=True to avoid duplicate indices\n",
        "            print(\"\\nFinal processed DataFrame for backtesting created.\")\n",
        "            print(\"Final processed DataFrame shape:\", df_backtest.shape)\n",
        "            print(\"Final processed DataFrame columns:\", df_backtest.columns.tolist())\n",
        "            print(\"Final processed DataFrame head:\\n\", df_backtest.head(10))\n",
        "\n",
        "                    # Ensure timestamp column is datetime and sorted for the backtester\n",
        "            if 'timestamp' in df_backtest.columns:\n",
        "                df_backtest['timestamp'] = pd.to_datetime(df_backtest['timestamp'])\n",
        "                df_backtest = df_backtest.sort_values('timestamp').reset_index(drop=True)\n",
        "                logger.debug(\"df_backtest sorted by timestamp and index reset for backtester.\")\n",
        "            else:\n",
        "                 logger.error(\"Timestamp column not found in df_backtest. Backtesting might fail.\")\n",
        "\n",
        "\n",
        "            print(\"\\nProcessed data for backtesting head:\")\n",
        "            display(df_backtest.head())\n",
        "\n",
        "        else:\n",
        "            logger.warning(\"No data processed for backtesting.\")\n",
        "            df_backtest = pd.DataFrame() # Ensure it's an empty DataFrame if no data processed\n",
        "\n",
        "\n",
        "    else:\n",
        "        logger.warning(\"combined_df is not available or is empty. Skipping pattern detection and backtesting preparation.\")\n",
        "        df_backtest = pd.DataFrame() # Ensure df_backtest is empty if combined_df is not ready\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "\n",
        "    # --- Define Strategies and Instantiate Them (All Potential Strategies) ---\n",
        "    # Initial capital for backtesting\n",
        "    initial_capital = 200000.0 # Example initial capital\n",
        "\n",
        "    # Create a pool of ALL potential strategy instances\n",
        "    # Instantiating them here means they are available to be activated later\n",
        "    all_strategy = {}\n",
        "\n",
        "#####*****>>>>>>>>>>>>>> 1. Instantiate TrendFollowingStrategy and add to pool\n",
        "    try:\n",
        "        # This line might be failing\n",
        "        trend_following_strategy = TrendFollowingStrategy(window_size=20) # Example parameter\n",
        "        # If the above line fails, the code jumps to the except blocks\n",
        "        # and the next line (adding to the dictionary) is never reached.\n",
        "\n",
        "        all_strategy['TrendFollowing'] = trend_following_strategy # Use a consistent key name\n",
        "        logger.info(\"TrendFollowingStrategy instantiated and added to pool.\") # This log might not be appearing\n",
        "\n",
        "    # >>> Check these except blocks closely <<<\n",
        "    except NameError:\n",
        "        # This catches if the TrendFollowingStrategy class itself isn't found/imported\n",
        "        logger.warning(\"TrendFollowingStrategy class not found. Skipping instantiation.\")\n",
        "        # If this happens, the strategy is not added to the pool.\n",
        "    except Exception as e:\n",
        "        # This catches any other error during the __init__ method of the strategy\n",
        "        logger.error(f\"Error instantiating TrendFollowingStrategy for pool: {e}\")\n",
        "        # If this happens, the strategy is not added to the pool.\n",
        "\n",
        "#####*****>>>>>>>>>>>>>> 2. Instantiate TrendFollowingStrategyV1 and add to pool\n",
        "    try:\n",
        "        # This line might be failing\n",
        "        trend_following_strategyV1 = TrendFollowingStrategyV1(window_size=20) # Example parameter\n",
        "        # If the above line fails, the code jumps to the except blocks\n",
        "        # and the next line (adding to the dictionary) is never reached.\n",
        "\n",
        "        all_strategy['TrendFollowingV1'] = trend_following_strategyV1 # Use a consistent key name\n",
        "        logger.info(\"TrendFollowingStrategyV1 instantiated and added to pool.\") # This log might not be appearing\n",
        "\n",
        "    # >>> Check these except blocks closely <<<\n",
        "    except NameError:\n",
        "        # This catches if the TrendFollowingStrategyV1 class itself isn't found/imported\n",
        "        logger.warning(\"TrendFollowingStrategyV1 class not found. Skipping instantiation.\")\n",
        "        # If this happens, the strategy is not added to the pool.\n",
        "    except Exception as e:\n",
        "        # This catches any other error during the __init__ method of the strategy\n",
        "        logger.error(f\"Error instantiating TrendFollowingStrategyV1 for pool: {e}\")\n",
        "        # If this happens, the strategy is not added to the pool.\n",
        "\n",
        "\n",
        "\n",
        "#####*****>>>>>>>>>>>>>> 3.  Instantiate CombinedSignalStrategy and add to pool\n",
        "    try:\n",
        "        combined_signal_strategy = CombinedSignalStrategy() # Example\n",
        "        all_strategy['CombinedSignal'] = combined_signal_strategy # Use a consistent key name\n",
        "        logger.info(\"CombinedSignalStrategy instantiated and added to pool.\")\n",
        "    except NameError:\n",
        "        logger.warning(\"CombinedSignalStrategy class not found. Skipping instantiation.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error instantiating CombinedSignalStrategy for pool: {e}\")\n",
        "\n",
        "    # Add instantiations for any other strategy classes here, adding them to all_strategy_instances_pool\n",
        "\n",
        "\n",
        "    # --- Backtesting Mode Execution ---\n",
        "    if trading_mode == 'backtest':\n",
        "        print(\"\\nExecuting in Backtest Mode...\")\n",
        "        logger.info(\"Entering Backtest Mode.\")\n",
        "        print(\">>> DEBUG MARKER 1: Entering backtesting mode <<<\")\n",
        "\n",
        "        # >>> DEFINE ACTIVE STRATEGIES FOR THIS RUN HERE <<<\n",
        "        # List the NAMES (keys from all_strategy_instances_pool) of the strategies you want to run\n",
        "        active_strategies_names_to_run = ['TrendFollowing'] # Example: Run only TrendFollowing\n",
        "        # active_strategies_names_to_run = ['TrendFollowingV1'] # Example: Run only TrendFollowing\n",
        "        # active_strategies_names_to_run = ['CombinedSignal'] # Example: Run only CombinedSignal\n",
        "        # active_strategies_names_to_run = ['TrendFollowing', 'CombinedSignal'] # Example: Run both\n",
        "        # active_strategies_names_to_run = [] # Example: Run none (useful for testing data loading)\n",
        "\n",
        "\n",
        "        # >>> BUILD THE DICTIONARY OF ACTIVE STRATEGY INSTANCES FOR THE BACKTESTER <<<\n",
        "        # Filter the pool based on the names in active_strategies_names_to_run\n",
        "        active_strategies_instances_for_backtester = {}\n",
        "        for strategy_name in active_strategies_names_to_run:\n",
        "            if strategy_name in all_strategy:\n",
        "                # Only add strategies whose names are in the list and are in the pool\n",
        "                active_strategies_instances_for_backtester[strategy_name] = all_strategy[strategy_name]\n",
        "            else:\n",
        "                logger.warning(f\"Strategy '{strategy_name}' listed in active_strategies_names_to_run not found in the instantiated pool. Skipping.\")\n",
        "\n",
        "        # Check if any strategies were successfully activated for the backtester\n",
        "        if not active_strategies_instances_for_backtester:\n",
        "            print(\"\\nWarning: No valid active strategies found to run backtest based on your list. Check 'active_strategies_names_to_run'.\")\n",
        "            logger.warning(\"No valid active strategies found for backtest.\")\n",
        "            # You might want to add a 'continue' or 'pass' here if you want to skip the backtest execution\n",
        "            pass # Skip the backtest execution block below if no strategies are active\n",
        "        else:\n",
        "            # --- Proceed with Backtester Instantiation and Execution ONLY if there are active strategies ---\n",
        "            print(f\"Active strategies for this backtest run: {list(active_strategies_instances_for_backtester.keys())}\")\n",
        "\n",
        "            # Ensure df_backtest is defined and not empty before proceeding\n",
        "            # Assuming df_backtest is the combined_df filtered or prepared for backtesting\n",
        "            if 'df_backtest' in locals() and not df_backtest.empty:\n",
        "                try:\n",
        "                    print(\"Starting Backtester instantiation...\")\n",
        "                    # Instantiate the Backtester with the prepared data and the FILTERED strategy instances\n",
        "                    backtester = BacktesterV3(\n",
        "                        data=df_backtest,\n",
        "                        # It's better to get instrument keys from the data actually being used for backtesting\n",
        "                        instrument_keys=df_backtest['instrument_key'].unique().tolist(),\n",
        "                        active_strategies_instances=active_strategies_instances_for_backtester, # Pass the FILTERED dictionary\n",
        "                        initial_capital=initial_capital\n",
        "                        # header_df=header_df # Pass the header_df here\n",
        "                    )\n",
        "                    print(\"Backtester instantiated successfully.\")\n",
        "\n",
        "                    # Run the backtest simulation\n",
        "                    print(\"Running backtest simulation...\")\n",
        "                    completed_trades_df = backtester.run_backtest()\n",
        "                    print(\"Backtest simulation finished.\")\n",
        "\n",
        "                    # Get the completed trades (as a DataFrame)\n",
        "                    # This is already returned by run_backtest(), so no need for get_completed_trades() here\n",
        "                    # completed_trades_df = completed_trades_df # This line is redundant\n",
        "\n",
        "\n",
        "                    # Analyze the backtest results\n",
        "                    if completed_trades_df is not None and not completed_trades_df.empty:\n",
        "                        print(\"\\n--- Backtest Completed Trades Sample ---\")\n",
        "                        display(completed_trades_df.head()) # Display head of trades\n",
        "\n",
        "                        # Perform analysis using the Backtester's method\n",
        "                        print(\"\\nAnalyzing backtest performance...\")\n",
        "                        analysis_results_df = backtester.analyze_backtest_results()\n",
        "\n",
        "                        # Get the names of the active strategies that were run\n",
        "                        strategy_names = list(active_strategies_instances_for_backtester.keys())\n",
        "\n",
        "                        # Create a filename by joining the strategy names\n",
        "                        # Replace potentially problematic characters like spaces and hyphens\n",
        "                        filename_strategy_part = \"_\".join(strategy_names).replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "\n",
        "                        # Add a timestamp to the filename for uniqueness\n",
        "                        from datetime import datetime\n",
        "                        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "                        # Define the folder name and output filename\n",
        "                        folder_name = 'Excel_backtest_result'\n",
        "\n",
        "                        # Construct the full output filename\n",
        "                        output_filename = f\"backtest_results_{filename_strategy_part}_{timestamp_str}.csv\"\n",
        "\n",
        "                        # Construct the full output path\n",
        "                        output_path = os.path.join(folder_name, output_filename)\n",
        "\n",
        "                        # Create the directory if it doesn't exist\n",
        "                        try:\n",
        "                            os.makedirs(folder_name, exist_ok=True)\n",
        "                            print(f\"Ensured directory '{folder_name}' exists.\")\n",
        "                            logger.info(f\"Ensured directory '{folder_name}' exists.\")\n",
        "                        except Exception as e:\n",
        "                            logger.error(f\"Error creating directory '{folder_name}': {e}\")\n",
        "                            print(f\"Error creating directory '{folder_name}': {e}\")\n",
        "\n",
        "                        # Save the DataFrame to a CSV file\n",
        "                        try:\n",
        "                            completed_trades_df.to_csv(output_path, index=False) # Corrected: Pass only output_path\n",
        "                            print(f\"\\nBacktest results saved to {output_path}\") # Corrected print message\n",
        "                            logger.info(f\"Backtest results saved to {output_path}\") # Corrected log message\n",
        "                        except Exception as e:\n",
        "                            logger.error(f\"Error saving backtest results to CSV: {e}\")\n",
        "                            print(f\"\\nError saving backtest results to {output_path}: {e}\") # Corrected print message\n",
        "\n",
        "                        # --- End of code to SAVE results to CSV ---\n",
        "                        # >>> Add the debug display code here <<<\n",
        "                        print(\"--- Debug Data Captured ---\")\n",
        "                        if hasattr(backtester, '_debug_close_values'):\n",
        "                            print(f\"Captured {len(backtester._debug_close_values)} debug points.\")\n",
        "                            # Display the last few captured values to see the issue\n",
        "                            display_count = min(20, len(backtester._debug_close_values)) # Increased display count slightly\n",
        "                            print(f\"Last {display_count} captured Close values and their validity:\")\n",
        "                            for j in range(len(backtester._debug_close_values) - display_count, len(backtester._debug_close_values)):\n",
        "                                ts = backtester._debug_timestamps[j]\n",
        "                                close_val = backtester._debug_close_values[j]\n",
        "                                validity = backtester._debug_validity[j]\n",
        "                                print(f\"Timestamp: {ts}, Close: {close_val}, is_close_valid: {validity}, Type of Close: {type(close_val)}\")\n",
        "                        else:\n",
        "                            print(\"Debug capture lists not found on backtester instance. Please ensure they are added to __init__ and populated in the loop.\")\n",
        "\n",
        "                    else:\n",
        "                        print(\"\\nNo completed trades recorded during backtesting.\")\n",
        "                        logger.info(\"No completed trades recorded during backtesting.\")\n",
        "\n",
        "                except NameError:\n",
        "                    logger.error(\"df_backtest DataFrame is not defined. Cannot run backtest.\")\n",
        "                    print(\"\\nError: Backtesting data (df_backtest) is not defined. Cannot run backtest.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"An error occurred during backtest execution: {e}\", exc_info=True)\n",
        "                    print(f\"\\nAn error occurred during backtest execution: {e}\")\n",
        "\n",
        "            elif not 'df_backtest' in locals() or df_backtest.empty:\n",
        "                print(\"\\nWarning: Backtesting data (df_backtest) is not available or is empty. Cannot run backtest.\")\n",
        "                logger.warning(\"Backtesting data (df_backtest) is not available or is empty. Cannot run backtest.\")\n",
        "\n",
        "         # --- End of backtesting mode execution block ---\n",
        "#####*****************************************************************************************#####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####***>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<***####\n",
        "#####*****************************************************************************************#####\n",
        "\n",
        "\n",
        "    # --- Paper/Live Trading Mode (This part remains separate from backtesting) ---\n",
        "    elif trading_mode in ['paper', 'live']:\n",
        "        print(f\"\\nExecuting in {trading_mode.capitalize()} Mode...\")\n",
        "        logger.info(f\"Entering {trading_mode.capitalize()} Mode.\")\n",
        "\n",
        "        # --- WebSocket Connection ---\n",
        "        try:\n",
        "             # Assuming connectwebsocket handles the connection and keeps it open\n",
        "             # You might need to pass the instantiated strategies to the WebSocket handler\n",
        "             # or a message processing function that can access and use them.\n",
        "             # This part needs significant modification to integrate with strategies and execution.\n",
        "\n",
        "             # Example (Conceptual - Needs Implementation in connectwebsocket or a handler):\n",
        "             # await connectwebsocket(access_token, instrument_keys, data_handler_function, trading_mode, active_strategies_instances, initial_capital)\n",
        "\n",
        "            print(\"WebSocket connection logic would go here...\")\n",
        "            print(f\"In {trading_mode} mode, you would connect to the data feed, process real-time ticks/bars,\")\n",
        "            print(\"generate signals using active_strategies_instances, and execute paper/live trades.\")\n",
        "            print(\"This requires a separate real-time processing loop.\")\n",
        "\n",
        "             # Example of a real-time loop structure (highly simplified)\n",
        "            async def real_time_loop():\n",
        "                 resampler = RealTimeResampler(instrument_keys) # Instantiate Resampler\n",
        "                 # Assume connectwebsocket somehow feeds raw data to resampler\n",
        "                 # Assume resampler yields resampled bars (e.g., 1-minute bars)\n",
        "\n",
        "                 # Needs a way to receive data, process it incrementally,\n",
        "                 # add indicators/patterns to the latest bar, and then run strategies\n",
        "                 # on that latest bar.\n",
        "\n",
        "                 # Example structure within the real-time loop:\n",
        "                 # async for resampled_bar in resampler.get_bars():\n",
        "                 #      processed_bar = incremental_transformer.transform(resampled_bar) # Add latest indicators/patterns\n",
        "                 #      for strategy_name, strategy_instance in active_strategies_instances.items():\n",
        "                 #           signal = strategy_instance.generate_signal(processed_bar)\n",
        "                 #           # Execute trade based on signal and trading_mode ('paper'/'live')\n",
        "                 #           # Update paper_trades or send live order\n",
        "\n",
        "                 print(\"Real-time processing loop placeholder.\")\n",
        "\n",
        "\n",
        "            # You would typically run the real_time_loop here or have connectwebsocket manage it\n",
        "            # await real_time_loop()\n",
        "\n",
        "            # Keep the application running until shutdown is signaled\n",
        "            # await shutdown_event.wait() # Wait for the shutdown signal\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during {trading_mode.capitalize()} mode execution: {e}\", exc_info=True)\n",
        "            print(f\"\\nAn error occurred during {trading_mode.capitalize()} mode: {e}\")\n",
        "\n",
        "\n",
        "    #####*****************************************************************************************#####\n",
        "    # --- Program End ---\n",
        "    print(\"\\nMain execution finished.\")\n",
        "    logger.info(\"Main execution finished.\")\n",
        "\n",
        "    # Display the final completed trades (if any) again for clarity in notebooks\n",
        "    if 'completed_trades_df' in locals() and not completed_trades_df.empty:\n",
        "         print(\"\\nFinal Completed Trades (from Backtester):\")\n",
        "         display(completed_trades_df)\n",
        "    elif trading_mode == 'backtest':\n",
        "         print(\"\\nBacktest ran, but no completed_trades_df available or it is empty.\")\n",
        "    else:\n",
        "         print(\"\\nNot in backtest mode, no completed trades to display from backtester.\")\n",
        "\n",
        "    # You might also display paper_trades or live trade logs here\n",
        "\n",
        "# --- Run the main async function ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize a flag to indicate if we are in a Jupyter/IPython environment\n",
        "    is_jupyter_env = False\n",
        "\n",
        "    # Check if get_ipython is available (means we are in an IPython-like environment)\n",
        "    try:\n",
        "        # Attempt to get the IPython interactive shell\n",
        "        # Add # type: ignore to suppress Pylance warning if desired\n",
        "        ipython_shell = get_ipython() # type: ignore\n",
        "\n",
        "        # If we successfully got the shell, we are in an IPython environment\n",
        "        # Further check if it's specifically the kernel used by Jupyter notebooks\n",
        "        if ipython_shell is not None and 'ipykernel' in ipython_shell.config:\n",
        "             print(\"Running in Jupyter notebook environment.\")\n",
        "             is_jupyter_env = True\n",
        "             # Apply nest_asyncio here specifically for the notebook environment\n",
        "             # if you want to avoid applying it when running as a standard script\n",
        "             # nest_asyncio.apply() # You can move this inside here if preferred\n",
        "        # else:\n",
        "             # Running in a different IPython environment (e.g., terminal IPython)\n",
        "             # is_jupyter_env remains False\n",
        "\n",
        "    except NameError:\n",
        "        # get_ipython is not defined, which means we are in a standard Python environment\n",
        "        print(\"Running in standard Python environment.\")\n",
        "        is_jupyter_env = False\n",
        "        # If nest_asyncio.apply() was outside the try block, it will still run.\n",
        "        # If you move it inside the try block's 'ipykernel' check,\n",
        "        # it won't run in a standard script. Choose based on whether you need\n",
        "        # nested asyncio loops in the standard script as well.\n",
        "        # Given your original imports, it seems nest_asyncio.apply() is\n",
        "        # already being called outside this block, which is fine if needed\n",
        "        # for the standard script as well.\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other potential errors during the check\n",
        "        print(f\"An unexpected error occurred while checking environment: {e}\")\n",
        "        is_jupyter_env = False\n",
        "\n",
        "\n",
        "    # --- Now, call your main async function 'main()' ---\n",
        "    # Make sure the async def main(): function is defined elsewhere in your script\n",
        "\n",
        "    # Get the event loop\n",
        "    try:\n",
        "        # Using asyncio.run() is often simpler for top-level entry points in Python 3.7+\n",
        "        # if you don't need the custom loop returned by get_event_loop().\n",
        "        # However, since you applied nest_asyncio, get_event_loop().run_until_complete()\n",
        "        # is also appropriate and consistent.\n",
        "        # Let's use get_event_loop() as per your previous pattern:\n",
        "        loop = asyncio.get_event_loop()\n",
        "        loop.run_until_complete(main()) # Ensure your 'main' function is async and defined\n",
        "\n",
        "    except Exception as e:\n",
        "         # Handle exceptions that might occur during the execution of main()\n",
        "         print(f\"An error occurred during script execution: {e}\")\n",
        "         logger.error(f\"An error occurred during script execution: {e}\", exc_info=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "ozOqf-wKxE6M",
        "outputId": "0df99a9f-0965-4399-c9d2-549f1e056705"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'talib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-4266597999.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m \u001b[0;31m# Import json for potentially logging raw message content if not protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m \u001b[0;31m# Import the json library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtalib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_1111_1_FnoINELV1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mheader_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'talib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8272326d"
      },
      "source": [
        "# Task\n",
        "Modify the provided Python code for the `BacktesterV3` class to capture and store the names of detected bullish and bearish candlestick and chart patterns at the time of trade entry and exit. Ensure these pattern names are included in the output CSV file. The relevant columns in the CSV are `Entry_Bullish_Candlestick_Name`, `Entry_Bearish_Candlestick_Name`, `Entry_Bullish_Chart_Pattern_Name`, `Entry_Bearish_Chart_Pattern_Name`, `Exit_Bullish_Candlestick_Name`, `Exit_Bearish_Candlestick_Name`, `Exit_Bullish_Chart_Pattern_Detected`, and `Exit_Bearish_Chart_Pattern_Detected`. The debug output indicates that pattern detection is occurring, but the names are not being stored. The goal is to store the actual pattern names as strings in the CSV output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27ea5942"
      },
      "source": [
        "## Refine data capture in `execute trade`\n",
        "\n",
        "### Subtask:\n",
        "Ensure all relevant entry data points (indicators, patterns, etc.) are correctly captured and stored when a position is opened.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21b0c701"
      },
      "source": [
        "**Reasoning**:\n",
        "Review and confirm that the entry-specific data points are correctly captured from the `data_point` Series within the `execute_trade` method, ensuring the use of `.get()` for safety and verifying the assignment of `Entry_signal_type`, `Entry_order_type`, and `Position_type`. Also, check and update the debug logging for entry columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4547dd23",
        "outputId": "12d825ce-3250-4feb-df11-23b5e8bea7ad"
      },
      "source": [
        "# _1113_6BacktesterV6.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime # Import datetime for timestamp IDs\n",
        "import uuid  # Keep uuid import in case it's used elsewhere, although not for generate_trade_id now\n",
        "import sys # Import sys to check for handlers\n",
        "# from _012_instruments import get_instrument_type # Removed unused import\n",
        "# --- Logging Configuration ---\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Also ensure the root logger has a handler and is set to DEBUG,\n",
        "# in case basicConfig was called elsewhere previously.\n",
        "if not logging.root.handlers:\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "else:\n",
        "    # If handlers exist, ensure at least one handler's level is DEBUG\n",
        "    # and the root logger's level is DEBUG\n",
        "    logging.root.setLevel(logging.DEBUG)\n",
        "    handler_found = False\n",
        "    for handler in logging.root.handlers:\n",
        "        if isinstance(handler, logging.StreamHandler) and handler.stream in [sys.stdout, sys.stderr]:\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler_found = True\n",
        "    # If no suitable handler is found (e.g., only file handlers), add a StreamHandler\n",
        "    if not handler_found:\n",
        "         stream_handler = logging.StreamHandler(sys.stdout)\n",
        "         stream_handler.setLevel(logging.DEBUG)\n",
        "         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "         stream_handler.setFormatter(formatter)\n",
        "         logging.root.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "print(\"Logging level set to DEBUG for test.\")\n",
        "\n",
        "# Examine the __init__ method for data validation logic\n",
        "# Check for the existence of the required_columns and log warnings for potential entry/exit data columns.\n",
        "\n",
        "# required_columns check\n",
        "# missing_required = [col for col in required_columns if col not in data.columns]\n",
        "# if missing_required:\n",
        "#      raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "# entry_columns_to_check and exit_data_columns_to_check check\n",
        "# missing_data_cols = [col for col in entry_columns_to_check + exit_data_columns_to_check if col not in data.columns]\n",
        "# if missing_data_cols:\n",
        "#      logger.warning(f\"Input data is missing potential indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records.\")\n",
        "\n",
        "# The current code already performs these checks.\n",
        "# required_columns are checked and raise a ValueError if missing.\n",
        "# entry_columns_to_check and exit_data_columns_to_check are checked and log a warning if missing.\n",
        "\n",
        "# Add comments to clarify assumptions about columns expected in input data.\n",
        "\n",
        "class BacktesterV3:\n",
        "    \"\"\"\n",
        "    A simple backtesting engine for evaluating trading strategies.\n",
        "    Processes historical data bar by bar, generates signals, and simulates trades.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, instrument_keys: list, active_strategies_instances: dict, initial_capital: float):\n",
        "        \"\"\"\n",
        "        Includes the same parameters as the original __init__\n",
        "\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            data: A pandas DataFrame containing historical market data for all instruments,\n",
        "                expected to have columns like 'timestamp', 'instrument_key',\n",
        "                'open', 'high', 'low', 'close', 'volume', etc. It is also expected\n",
        "                to contain pre-calculated indicator and pattern columns used by\n",
        "                the strategies and for recording trade details.\n",
        "            instrument_keys: A list of unique instrument keys present in the data.\n",
        "            active_strategies_instances: A dictionary where keys are strategy names\n",
        "                                        (strings) and values are instantiated strategy\n",
        "                                        objects with a `generate_signal(data_point)` method.\n",
        "            initial_capital: The starting capital for the backtest simulation.\n",
        "        \"\"\"\n",
        "        if data is None or data.empty:\n",
        "            raise ValueError(\"Input data DataFrame is None or empty.\")\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n",
        "        if data.index.name is not None:\n",
        "            logger.warning(\"Input data index is not None. Consider resetting the index before passing to Backtester.\")\n",
        "\n",
        "\n",
        "        # Ensure essential columns are present and sorted\n",
        "        required_columns = ['timestamp', 'instrument_key', 'open', 'high', 'low', 'close']\n",
        "        # Define columns expected to be in the input data for recording trade details.\n",
        "        # These are typically pre-calculated indicators or pattern detection results.\n",
        "        entry_exit_data_columns_expected = [\n",
        "            'Trend', 'SMA20', 'RSI', 'RSIMA', 'ATR', 'ADX', 'Volatility',\n",
        "            'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "            'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "            'name', 'interval', 'Currency',\n",
        "            'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "            'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price'\n",
        "        ]\n",
        "\n",
        "        # The backtester expects these columns to be pre-calculated and provided in the input data.\n",
        "        # Strategies generate signals based on these columns, and their values at the time of\n",
        "        # entry and exit are recorded in the completed_trades DataFrame.\n",
        "\n",
        "\n",
        "        # Perform a relaxed check: log a warning if potential entry/exit columns from data are missing\n",
        "        missing_data_cols = [col for col in entry_exit_data_columns_expected if col not in data.columns]\n",
        "        if missing_data_cols:\n",
        "            logger.warning(f\"Input data is missing expected indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records. Ensure your data preparation includes these columns if strategies or analysis depend on them.\")\n",
        "\n",
        "\n",
        "        # Ensure mandatory required columns are present\n",
        "        missing_required = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_required:\n",
        "            raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "\n",
        "        # Ensure timestamp is datetime and sorted\n",
        "        try:\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
        "                data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True) # Convert to UTC\n",
        "            # Drop rows where timestamp conversion failed\n",
        "            data = data.dropna(subset=['timestamp'])\n",
        "            # Sort by timestamp and then instrument_key to process bars chronologically per instrument\n",
        "            self.data = data.sort_values(by=['timestamp', 'instrument_key']).reset_index(drop=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing timestamp column in data: {e}\")\n",
        "\n",
        "\n",
        "        self.instrument_keys = instrument_keys\n",
        "        self.active_strategies_instances = active_strategies_instances\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # --- Backtesting State Variables ---\n",
        "        self.current_capital = initial_capital\n",
        "        self.positions = {}  # Dictionary to track open positions {instrument_key: {...entry details...}}\n",
        "        self.completed_trades = [] # List to store completed trades\n",
        "        self.trade_id_counter = 0 # Simple counter for trade IDs\n",
        "        self.debug_log = [] # List to store debug information\n",
        "\n",
        "        # Debug lists to capture values\n",
        "        self._debug_timestamps = []\n",
        "        self._debug_close_values = []\n",
        "        self._debug_validity = []\n",
        "\n",
        "        # Simple Slippage and Commission model (can be customized)\n",
        "        self.slippage_pct = 0.001  # 0.1% slippage per trade\n",
        "        self.commission_per_trade = 0.01 # $0.01 fixed commission per trade\n",
        "\n",
        "\n",
        "        logger.info(f\"BacktesterV2 initialized with {len(self.instrument_keys)} instruments and {len(self.active_strategies_instances)} active strategies.\")\n",
        "        logger.info(f\"Initial Capital: {self.initial_capital}\")\n",
        "        logger.info(f\"Data shape for backtesting: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def generate_trade_id(self, timestamp: datetime):\n",
        "        \"\"\"Generates a unique trade ID using a provided timestamp.\"\"\"\n",
        "        # Using microseconds to increase the chance of uniqueness\n",
        "        return timestamp.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    def execute_trade(self, trade_id: str, instrument_key: str, timestamp: datetime, signal: str, strategy_name: str, price: float, data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Simulates executing a trade based on a signal.\n",
        "\n",
        "        Args:\n",
        "            trade_id: Unique identifier for the trade.\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the trade execution (bar close time).\n",
        "            signal: The trading signal ('BUY' or 'SELL').\n",
        "            strategy_name: The name of the strategy generating the signal.\n",
        "            price: The execution price (typically the close price of the bar).\n",
        "            data_point: The pandas Series representing the data row for this bar. This Series\n",
        "                        is expected to contain pre-calculated indicators and pattern data\n",
        "                        used for entry/exit conditions and recording.\n",
        "        \"\"\"\n",
        "        # Determine instrument type to handle lot size/quantity logic\n",
        "        # instrument_type = get_instrument_type(instrument_key) # Removed due to import error\n",
        "        instrument_type = 'Unknown' # Placeholder\n",
        "\n",
        "\n",
        "        # Simple fixed quantity logic (can be replaced with dynamic position sizing)\n",
        "        quantity_to_trade = 1 # Example: trade 1 unit/lot\n",
        "\n",
        "        if signal == 'BUY':\n",
        "            # Check if we already have a position in this instrument (optional, depending on strategy)\n",
        "            if instrument_key not in self.positions:\n",
        "                # Simulate buying\n",
        "                cost = quantity_to_trade * price\n",
        "                # Check if we have enough capital\n",
        "                if self.current_capital >= cost:\n",
        "                    self.current_capital -= cost\n",
        "\n",
        "                    # Calculate entry costs (slippage and commission on entry)\n",
        "                    entry_slippage = cost * self.slippage_pct\n",
        "                    entry_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (entry_slippage + entry_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Capture entry-specific details from the data_point and other variables\n",
        "                    self.positions[instrument_key] = {\n",
        "                        'quantity': quantity_to_trade,\n",
        "                        'entry_price': price, # This is the execution price for this simple model\n",
        "                        'entry_time': timestamp,\n",
        "                        'strategy': strategy_name,\n",
        "                        'trade_id': trade_id,\n",
        "                        'instrument_type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'side': 'BUY', # Store trade side\n",
        "\n",
        "                        # --- Entry-Specific Columns (Populated from data_point at Entry) ---\n",
        "                        'Strategy_name': strategy_name,\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'name': data_point.get('name'), # Use .get() to avoid errors if column is missing\n",
        "                        'interval': data_point.get('interval'),\n",
        "                        'Position_type': 'Long', # Assuming BUY means Long position\n",
        "                        'Entry_order_type': 'Market', # Assuming market order execution on close\n",
        "                        'Entry_timestamp': timestamp,\n",
        "                        'Entry_price_trigger': None, # Not explicitly handled in this simple model\n",
        "                        'Entry_price_execution': price,\n",
        "                        'Entry_shares': quantity_to_trade, # Using quantity_to_trade as shares\n",
        "                        'Entry_cost': cost, # Gross cost before fees\n",
        "                        'Entry_signal_type': signal, # Ensure signal is captured\n",
        "                        'Entry_Trend': data_point.get('Trend'), # Capture Trend at Entry\n",
        "                        'Entry_SMA20': data_point.get('SMA20'), # Capture SMA20 at Entry\n",
        "                        'Entry_RSI': data_point.get('RSI'), # Capture RSI at Entry\n",
        "                        'Entry_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Entry\n",
        "                        'Entry_ATR': data_point.get('ATR'), # Capture ATR at Entry\n",
        "                        'Entry_ADX': data_point.get('ADX'), # Capture ADX at Entry\n",
        "                        'Entry_Volatility': data_point.get('Volatility'), # Capture Volatility at Entry\n",
        "                        'Entry_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Entry\n",
        "                        'Entry_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Entry\n",
        "                        # Corrected column names to match expected input data\n",
        "                        'Entry_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Entry\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Entry\n",
        "                        'Instrument_Type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'Currency': data_point.get('Currency'),\n",
        "                        'Slippage_Entry': entry_slippage, # Store entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Store entry commission\n",
        "\n",
        "                        # Placeholder for other entry-specific details that might be calculated by strategy (e.g., initial stop/target)\n",
        "                        'Initial_Stop_Loss_Distance (%)': data_point.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': data_point.get('Risk_Amount'),\n",
        "                        'Reward_Amount': data_point.get('Reward_Amount'),\n",
        "\n",
        "\n",
        "                        # Placeholders for exit/other info that will be filled on close\n",
        "                        # These fields are included here so the structure is consistent for retrieval on exit,\n",
        "                        # even though their values are None at the time of entry.\n",
        "                         'Max_Favorable_Excursion_MFE': None, # Will be calculated on exit\n",
        "                         'Max_Adverse_Excursion_MAE': None, # Will be calculated on exit\n",
        "                        'Current_trailing_stop': None, # Need logic for trailing stops\n",
        "                        'Trailing_stop_method': None,\n",
        "                        'Trailing_stop_value': None,\n",
        "                        'Stop_loss_price': None,\n",
        "\n",
        "\n",
        "                        'Exit_Trend': None, 'Exit_signal_type': None, 'Exit_SMA20': None,\n",
        "                        'Exit_RSI': None, 'Exit_RSI_MA': None, 'Exit_ATR': None, 'Exit_ADX': None,\n",
        "                        'Exit_Volatility': None, 'Exit_Breakout_Detected': None,\n",
        "                        'Exit_Breakdown_Detected': None, 'Exit_Bullish_Candlestick_Name': None,\n",
        "                        'Exit_Bearish_Candlestick_Name': None, 'Exit_Bullish_Chart_Pattern_Detected': None,\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': None, 'Exit_shares': None,\n",
        "                        'Exit_cost': None, 'Exit_revenue': None, 'PnL_trade': None,\n",
        "                        'Trade_type': None, 'Profit_loss': None, 'Exit_reason': None,\n",
        "                        'Slippage': None, 'Commission_Fees': None, 'Trade_Duration': None,\n",
        "                        'Exit_Order_Type': None\n",
        "                    }\n",
        "\n",
        "                    # --- Add debug logging for Entry columns here ---\n",
        "                    logger.debug(f\"DEBUG Entry Data Point for {instrument_key} at {timestamp}:\")\n",
        "                    debug_cols_to_check = [\n",
        "                        'Trend', 'SMA20', 'RSI', 'RSI_MA', 'ATR', 'ADX', 'Volatility',\n",
        "                        'Breakout_Detected', 'Breakdown_Detected',\n",
        "                        # Corrected debug column names to match expected input data\n",
        "                        'Bullish_Candlestick_Detected', 'Bearish_Candlestick_Detected',\n",
        "                        'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "                        'Currency', 'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "                        'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE', 'Current_trailing_stop',\n",
        "                        'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price', 'Exit_Trend',\n",
        "                        'Exit_signal_type', 'Exit_SMA20', 'Exit_RSI', 'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX',\n",
        "                        'Exit_Volatility', 'Exit_Breakout_Detected', 'Exit_Breakdown_Detected',\n",
        "                        'Exit_Bullish_Candlestick_Name', 'Exit_Bearish_Candlestick_Name',\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected', 'Exit_Bearish_Chart_Pattern_Detected',\n",
        "                        'Exit_cost'\n",
        "                    ]\n",
        "                    for col in debug_cols_to_check:\n",
        "                         logger.debug(f\"  {col}: {data_point.get(col, 'Column Not Found or None')}\")\n",
        "                    # --- End Debug Logging ---\n",
        "\n",
        "\n",
        "                    logger.info(f\"Executed BUY trade {trade_id} for {instrument_key} at {timestamp} @ {price} (Qty: {quantity_to_trade}). Costs: Slippage={entry_slippage:.4f}, Commission={entry_commission:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'BUY', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'slippage': entry_slippage, 'commission': entry_commission})\n",
        "                else:\n",
        "                    logger.warning(f\"Insufficient capital ({self.current_capital:.2f}) to BUY {instrument_key} at {price} (Cost: {cost:.2f}). Skipping trade {trade_id}.\")\n",
        "                    self.debug_log.append({'type': 'SKIP_BUY_CAPITAL', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Insufficient Capital'})\n",
        "\n",
        "            else:\n",
        "                # Already in a position, maybe add to it or skip depending on strategy rules\n",
        "                logger.debug(f\"Skipping BUY signal for {instrument_key} at {timestamp}. Already in a position.\")\n",
        "                self.debug_log.append({'type': 'SKIP_BUY_POSITION', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Already in Position'})\n",
        "\n",
        "\n",
        "        elif signal == 'SELL':\n",
        "            # For backtesting, a 'SELL' signal usually means closing a long position or opening a short position\n",
        "            # Let's assume 'SELL' means closing a long position if one exists for simplicity in this example.\n",
        "            # For a shorting strategy, you'd need different logic.\n",
        "            if instrument_key in self.positions and self.positions[instrument_key]['side'] == 'BUY':\n",
        "                # Simulate selling to close a long position\n",
        "                position = self.positions[instrument_key]\n",
        "                quantity_to_sell = position['quantity']\n",
        "                entry_price = position['entry_price']\n",
        "                entry_time = position['entry_time']\n",
        "                strategy_opened = position['strategy']\n",
        "                open_trade_id = position['trade_id']\n",
        "\n",
        "\n",
        "                revenue = quantity_to_sell * price\n",
        "                self.current_capital += revenue\n",
        "\n",
        "                # Calculate Profit/Loss (Gross PnL)\n",
        "                gross_pnl = (price - entry_price) * quantity_to_sell # For long position\n",
        "\n",
        "                # Calculate exit costs (slippage and commission on exit)\n",
        "                exit_slippage = revenue * self.slippage_pct\n",
        "                exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "                # Calculate Net PnL\n",
        "                total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "                total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "                pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "                # Calculate Trade Duration\n",
        "                trade_duration = (timestamp - entry_time).total_seconds() if pd.notnull(timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "                # Record completed trade - Populate all desired columns\n",
        "                trade_record = {\n",
        "                    'open_trade_id': open_trade_id,\n",
        "                    'close_trade_id': trade_id,\n",
        "                    'instrument_key': instrument_key,\n",
        "                    'instrument_type': position.get('instrument_type'), # Assuming this key is correct in position\n",
        "                    'side': position.get('side'), # Side of the position being closed (BUY/LONG)\n",
        "                    'quantity': quantity_to_sell, # Quantity closed\n",
        "                    'entry_price': entry_price,\n",
        "                    'entry_time': entry_time,\n",
        "                    'exit_price': price,\n",
        "                    'exit_time': timestamp,\n",
        "                    'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "                    'strategy_opened': strategy_opened,\n",
        "                    'strategy_closed': strategy_name, # Record which strategy/signal closed it\n",
        "\n",
        "                    # --- Transfer Entry Details from Position ---\n",
        "                    'Strategy_name': position.get('Strategy_name'),\n",
        "                    'instrument_key': position.get('instrument_key'),\n",
        "                    'name': position.get('name'),\n",
        "                    'interval': position.get('interval'),\n",
        "                    'Position_type': position.get('Position_type'),\n",
        "                    'Entry_order_type': position.get('Entry_order_type'),\n",
        "                    'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                    'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                    'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                    'Entry_shares': position.get('Entry_shares'),\n",
        "                    'Entry_cost': position.get('Entry_cost'),\n",
        "                    'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                    'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                    'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                    'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                    'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                    'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                    'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                    'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                    'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                    'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                    # Corrected keys to match the expected format\n",
        "                    'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                    'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                    'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                    'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                    'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                    'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                    'Slippage_Entry': position.get('Slippage_Entry'), # Transfer entry slippage\n",
        "                    'Commission_Fees_Entry': position.get('Commission_Fees_Entry'), # Transfer entry commission\n",
        "                    'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                    'Risk_Amount': position.get('Risk_Amount'),\n",
        "                    'Reward_Amount': position.get('Reward_Amount'),\n",
        "                    'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                    'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                    # --- Exit-Specific Columns (Populated from data_point at Exit) ---\n",
        "                    'Exit_Trend': data_point.get('Exit_Trend'), # Capture Trend at Exit\n",
        "                    'Exit_signal_type': signal, # Signal that triggered the exit\n",
        "                    'Exit_SMA20': data_point.get('Exit_SMA20'), # Capture SMA20 at Exit\n",
        "                    'Exit_RSI': data_point.get('Exit_RSI'), # Capture RSI at Exit\n",
        "                    'Exit_RSI_MA': data_point.get('Exit_RSI_MA'), # Capture RSI_MA at Exit\n",
        "                    'Exit_ATR': data_point.get('Exit_ATR'), # Capture ATR at Exit\n",
        "                    'Exit_ADX': data_point.get('Exit_ADX'), # Capture ADX at Exit\n",
        "                    'Exit_Volatility': data_point.get('Exit_Volatility'), # Capture Volatility at Exit\n",
        "                    'Exit_Breakout_Detected': data_point.get('Exit_Breakout_Detected'), # Capture Breakout_Detected at Exit\n",
        "                    'Exit_Breakdown_Detected': data_point.get('Exit_Breakdown_Detected'), # Capture Breakdown_Detected at Exit\n",
        "                    # Corrected keys to match the expected format\n",
        "                    'Exit_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Exit\n",
        "                    'Exit_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Exit\n",
        "                    'Exit_Bullish_Chart_Pattern_Detected': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Exit\n",
        "                    'Exit_Bearish_Chart_Pattern_Detected': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Exit\n",
        "                    'Exit_shares': quantity_to_sell, # Shares exited\n",
        "                    'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "                    'Exit_revenue': revenue, # Gross revenue before fees\n",
        "                    'PnL_trade': pnl_trade, # Net PnL after costs\n",
        "                    'Trade_type': 'Long Close (Signal)', # Or 'Long' if trade refers to the full cycle\n",
        "                    'Profit_loss': pnl_trade, # Update Profit_loss to net PnL\n",
        "                    'Exit_reason': f'Signal_{signal}', # Reason for exit\n",
        "                    'Exit_Order_Type': 'Market', # Set Exit_Order_Type to 'Market'\n",
        "\n",
        "                    # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                    'Current_trailing_stop': data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                    'Trailing_stop_method': data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                    'Trailing_stop_value': data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                    'Stop_loss_price': data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "\n",
        "                    'Slippage': total_slippage, # Total slippage for the round trip\n",
        "                    'Commission_Fees': total_commission, # Total commission for the round trip\n",
        "                    'Trade_Duration': trade_duration,\n",
        "\n",
        "                }\n",
        "                self.completed_trades.append(trade_record)\n",
        "\n",
        "\n",
        "                # Remove position\n",
        "                del self.positions[instrument_key]\n",
        "\n",
        "                logger.info(f\"Executed SELL trade {trade_id} for {instrument_key} at {timestamp} @ {price} to CLOSE long position {open_trade_id}. Gross PnL: {gross_pnl:.2f}. Costs: Slippage={total_slippage:.4f}, Commission={total_commission:.2f}. Net PnL: {pnl_trade:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                self.debug_log.append({'type': 'SELL_CLOSE_LONG', 'open_trade_id': open_trade_id, 'close_trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_sell, 'gross_pnl': gross_pnl, 'net_pnl': pnl_trade, 'strategy_closed': strategy_name})\n",
        "\n",
        "\n",
        "            else:\n",
        "                # No matching long position to close, or maybe a shorting signal\n",
        "                # For this simple backtester, we'll just log and skip if no long position\n",
        "                logger.debug(f\"Skipping SELL signal for {instrument_key} at {timestamp}. No matching long position to close.\")\n",
        "                self.debug_log.append({'type': 'SKIP_SELL_NO_LONG', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'strategy': strategy_name, 'reason': 'No Long Position'})\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the backtesting simulation bar by bar through the data.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting backtest simulation...\")\n",
        "\n",
        "        # Group data by timestamp first, then iterate through timestamps\n",
        "        # This processes all instruments available at a given time before moving to the next time.\n",
        "        grouped_by_time = self.data.groupby('timestamp')\n",
        "\n",
        "        for timestamp, time_slice_df in grouped_by_time:\n",
        "            # Process data for all instruments available at this timestamp\n",
        "            for index, data_point in time_slice_df.iterrows():\n",
        "                instrument_key = data_point['instrument_key']\n",
        "                current_price = data_point['close'] # Assume close price for execution\n",
        "\n",
        "                # Debug capture\n",
        "                self._debug_timestamps.append(timestamp)\n",
        "                self._debug_close_values.append(current_price)\n",
        "                self._debug_validity.append(pd.notna(current_price))\n",
        "\n",
        "                # Ensure current_price is valid for trading\n",
        "                if pd.isna(current_price):\n",
        "                    logger.debug(f\"Skipping signal generation for {instrument_key} at {timestamp} due to invalid close price ({current_price}).\")\n",
        "                    self.debug_log.append({'type': 'SKIP_SIGNAL_PRICE_NAN', 'instrument': instrument_key, 'time': timestamp, 'reason': 'Invalid Price'})\n",
        "                    continue # Skip this data point if price is invalid\n",
        "\n",
        "                # Check for signals from all active strategies for this data point\n",
        "                # Pass the single data_point (as a Series) to the strategy\n",
        "                # The strategy is expected to handle a single row/Series or convert it internally\n",
        "                # For the backtester's execute_trade, we need the Series directly.\n",
        "\n",
        "                for strategy_name, strategy_instance in self.active_strategies_instances.items():\n",
        "                    try:\n",
        "                        # Pass the single data_point Series to the strategy's generate_signal\n",
        "                        # Ensure data_point is passed as a DataFrame slice if strategy expects DataFrame\n",
        "                        signal = strategy_instance.generate_signal(pd.DataFrame([data_point]))\n",
        "                        # Ensure signal is a string, handle potential None returns gracefully\n",
        "                        signal = str(signal).upper() if signal is not None else 'HOLD'\n",
        "\n",
        "                        if signal in ['BUY', 'SELL']:\n",
        "                            # Generate a unique trade ID for this potential trade using the bar's timestamp\n",
        "                            trade_id = self.generate_trade_id(timestamp) # Pass the historical timestamp\n",
        "                            # Pass the original data_point Series to execute_trade\n",
        "                            self.execute_trade(trade_id, instrument_key, timestamp, signal, strategy_name, current_price, data_point)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error generating signal for {instrument_key} at {timestamp} using strategy '{strategy_name}': {e}\", exc_info=True)\n",
        "                        self.debug_log.append({'type': 'STRATEGY_ERROR', 'instrument': instrument_key, 'time': timestamp, 'strategy': strategy_name, 'error': str(e)})\n",
        "\n",
        "\n",
        "        # After iterating through all data, close any remaining open positions\n",
        "        self.close_all_positions(self.data['timestamp'].max()) # Use the timestamp of the last data point as exit time\n",
        "\n",
        "        logger.info(\"Backtest simulation completed.\")\n",
        "        logger.info(f\"Final Capital: {self.current_capital:.2f}\")\n",
        "        logger.info(f\"Number of completed trades: {len(self.completed_trades)}\")\n",
        "        logger.info(f\"Number of open positions remaining: {len(self.positions)}\")\n",
        "\n",
        "        # Return completed trades as a DataFrame for analysis\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "            # Ensure numeric columns are numeric\n",
        "            numeric_cols = [\n",
        "                'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "            ]\n",
        "            for col in numeric_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "            return completed_trades_df\n",
        "        else:\n",
        "            logger.warning(\"No completed trades recorded. Returning empty DataFrame.\")\n",
        "            return pd.DataFrame() # Return empty DataFrame if no trades\n",
        "\n",
        "\n",
        "    def close_all_positions(self, exit_timestamp: datetime):\n",
        "        \"\"\"\n",
        "        Closes all remaining open positions at the specified exit timestamp.\n",
        "        Assumes closing at the price of the last available bar for each instrument.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Closing all remaining {len(self.positions)} open positions at {exit_timestamp}...\")\n",
        "\n",
        "        # Get the last known price and data point for each instrument with an open position\n",
        "        last_data_points = self.data.groupby('instrument_key').tail(1).set_index('instrument_key')\n",
        "        last_prices = last_data_points['close'].to_dict()\n",
        "\n",
        "\n",
        "        positions_to_close = list(self.positions.keys()) # Iterate over a copy\n",
        "\n",
        "        for instrument_key in positions_to_close:\n",
        "            if instrument_key in self.positions: # Check if position still exists (wasn't closed by a signal just before the end)\n",
        "                position = self.positions[instrument_key]\n",
        "                closing_price = last_prices.get(instrument_key, np.nan) # Get last price, default to NaN if instrument not found\n",
        "\n",
        "                # Get the last data point for the instrument to capture exit conditions\n",
        "                last_data_point = last_data_points.get(instrument_key, pd.Series({})) # Use empty Series if no data found\n",
        "\n",
        "\n",
        "                if pd.notna(closing_price):\n",
        "                    trade_id = self.generate_trade_id(exit_timestamp) # Generate a new trade ID for the closing trade using exit_timestamp\n",
        "                    # Simulate selling to close a long position\n",
        "                    quantity_to_sell = position['quantity']\n",
        "                    entry_price = position['entry_price']\n",
        "                    entry_time = position['entry_time']\n",
        "                    strategy_opened = position['strategy']\n",
        "                    open_trade_id = position['trade_id']\n",
        "\n",
        "\n",
        "                    revenue = quantity_to_sell * closing_price\n",
        "                    self.current_capital += revenue\n",
        "\n",
        "                    # Calculate Profit/Loss (Gross PnL)\n",
        "                    gross_pnl = (closing_price - entry_price) * quantity_to_sell # For long position\n",
        "\n",
        "                    # Calculate exit costs (slippage and commission on exit)\n",
        "                    exit_slippage = revenue * self.slippage_pct\n",
        "                    exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Calculate Net PnL\n",
        "                    total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "                    total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "                    pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "\n",
        "                    # Calculate Trade Duration\n",
        "                    trade_duration = (exit_timestamp - entry_time).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "\n",
        "                    # Record completed trade - Populate all desired columns\n",
        "                    trade_record = {\n",
        "                        'open_trade_id': open_trade_id,\n",
        "                        'close_trade_id': trade_id, # New ID for closing\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'), # Use .get() for safety\n",
        "                        'side': position.get('side'), # Side of the position being closed (BUY/LONG)\n",
        "                        'quantity': quantity_to_sell, # Quantity closed\n",
        "                        'entry_price': entry_price,\n",
        "                        'entry_time': entry_time,\n",
        "                        'exit_price': closing_price,\n",
        "                        'exit_time': exit_timestamp, # Use the provided exit timestamp\n",
        "                        'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "                        'strategy_opened': strategy_opened,\n",
        "                        'strategy_closed': 'Backtester_Forced_Close', # Indicate it was closed by the backtester\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': position.get('Slippage_Entry'), # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': position.get('Commission_Fees_Entry'), # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close', # Indicate forced close\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': quantity_to_sell, # Shares exited\n",
        "                        'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "                        'Exit_revenue': revenue, # Gross revenue before fees\n",
        "                        'PnL_trade': pnl_trade, # Net PnL after costs\n",
        "                        'Trade_type': 'Long Close (Forced)', # Or 'Long' if trade refers to the full cycle\n",
        "                        'Profit_loss': pnl_trade, # Update Profit_loss to net PnL\n",
        "                        'Exit_reason': 'Backtester_Forced_Close', # Reason for exit\n",
        "                        'Exit_Order_Type': 'Market', # Set Exit_Order_Type to 'Market' or 'Forced'\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "\n",
        "                        'Slippage': total_slippage, # Total slippage for the round trip\n",
        "                        'Commission_Fees': total_commission, # Total commission for the round trip\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(trade_record)\n",
        "\n",
        "                    # Remove position\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "                    logger.info(f\"Closed remaining position {open_trade_id} for {instrument_key} at {exit_timestamp} @ {closing_price}. Gross PnL: {gross_pnl:.2f}. Costs: Slippage={total_slippage:.4f}, Commission={total_commission:.2f}. Net PnL: {pnl_trade:.2f}. Capital: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE', 'open_trade_id': open_trade_id, 'close_trade_id': trade_id, 'instrument': instrument_key, 'time': exit_timestamp, 'price': closing_price, 'quantity': quantity_to_sell, 'gross_pnl': gross_pnl, 'net_pnl': pnl_trade, 'strategy_closed': 'Backtester_Forced_Close'})\n",
        "\n",
        "                else:\n",
        "                    logger.warning(f\"Could not find last price for {instrument_key}. Cannot close position {position['trade_id']}. Logging as unresolved.\")\n",
        "                    # Log as an unresolved position or assume zero PnL\n",
        "\n",
        "                    # Calculate Trade Duration even if closing price is NaN\n",
        "                    trade_duration = (exit_timestamp - position.get('entry_time')).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(position.get('entry_time')) else None\n",
        "\n",
        "                    # Transfer known costs\n",
        "                    entry_slippage = position.get('Slippage_Entry', 0)\n",
        "                    entry_commission = position.get('Commission_Fees_Entry', 0)\n",
        "\n",
        "\n",
        "                    unresolved_trade_record = {\n",
        "                        'open_trade_id': position.get('trade_id'),\n",
        "                        'close_trade_id': None, # No closing trade ID\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'),\n",
        "                        'side': position.get('side'),\n",
        "                        'quantity': position.get('quantity'),\n",
        "                        'entry_price': position.get('entry_price'),\n",
        "                        'entry_time': position.get('entry_time'),\n",
        "                        'exit_price': None, # No exit price\n",
        "                        'exit_time': exit_timestamp, # Use the requested exit timestamp\n",
        "                        'pnl': 0, # Assume zero Gross PnL if cannot close\n",
        "                        'strategy_opened': position.get('strategy'),\n",
        "                        'strategy_closed': 'Backtester_Forced_Close_Error', # Indicate error\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': entry_slippage, # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close_Error', # Indicate forced close error\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': position.get('quantity'), # Shares that were supposed to be exited\n",
        "                        'Exit_cost': 0,\n",
        "                        'Exit_revenue': 0, # Assuming zero revenue if cannot close\n",
        "                        'PnL_trade': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Profit_loss': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Exit_reason': 'Backtester_Forced_Close_Error: No_Last_Price', # Reason for exit\n",
        "                        'Exit_Order_Type': None, # Could not execute exit order\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "                        'Slippage': entry_slippage, # Only entry slippage is known\n",
        "                        'Commission_Fees': entry_commission, # Only entry commission is known\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(unresolved_trade_record)\n",
        "\n",
        "                    # Remove position even if it couldn't be closed properly to prevent it from being processed again\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE_ERROR', 'open_trade_id': position['trade_id'], 'instrument': instrument_key, 'time': exit_timestamp, 'reason': 'Last price not available'})\n",
        "\n",
        "\n",
        "        logger.info(\"All remaining positions closed.\")\n",
        "\n",
        "\n",
        "    def analyze_backtest_results(self):\n",
        "        \"\"\"\n",
        "        Analyzes the completed trades and provides performance metrics.\n",
        "        Returns a DataFrame summarizing the analysis.\n",
        "        \"\"\"\n",
        "        logger.info(\"Analyzing backtest results...\")\n",
        "\n",
        "        if not self.completed_trades:\n",
        "            logger.warning(\"No completed trades to analyze.\")\n",
        "            return pd.DataFrame({'Message': ['No completed trades to analyze.']})\n",
        "\n",
        "        # 1. Access the self.completed_trades list and Create a pandas DataFrame\n",
        "        trades_df = pd.DataFrame(self.completed_trades)\n",
        "\n",
        "        # 3. Ensure that relevant columns are converted to appropriate numeric types\n",
        "        numeric_cols = [\n",
        "            'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "            'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "            'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "            'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "            'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "            'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "            'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "            'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Include other potentially numeric cols\n",
        "        ]\n",
        "        for col in numeric_cols:\n",
        "            if col in trades_df.columns:\n",
        "                trades_df[col] = pd.to_numeric(trades_df[col], errors='coerce')\n",
        "\n",
        "        # Handle potential NaN values during conversion - drop rows where PnL_trade (or pnl) is NaN\n",
        "        pnl_col_for_analysis = 'PnL_trade' if 'PnL_trade' in trades_df.columns else 'pnl'\n",
        "        if pnl_col_for_analysis in trades_df.columns:\n",
        "            # Only consider trades with a valid PnL for core analysis metrics\n",
        "            trades_df_analysis = trades_df.dropna(subset=[pnl_col_for_analysis]).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "        else:\n",
        "            logger.warning(\"Neither 'PnL_trade' nor 'pnl' column found for analysis.\")\n",
        "            return pd.DataFrame({'Message': ['No PnL column found for analysis.']})\n",
        "\n",
        "\n",
        "        if trades_df_analysis.empty:\n",
        "            logger.warning(\"No valid trades after numeric conversion/dropna for analysis. Analysis stopped.\")\n",
        "            return pd.DataFrame({'Message': ['No valid trades after numeric conversion/dropna for analysis.']})\n",
        "\n",
        "\n",
        "        # 4. Update the calculation of basic performance metrics using 'PnL_trade'\n",
        "        total_trades = len(trades_df_analysis)\n",
        "        total_pnl = trades_df_analysis[pnl_col_for_analysis].sum()\n",
        "\n",
        "        winning_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] > 0]\n",
        "        losing_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] < 0]\n",
        "        breakeven_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] == 0]\n",
        "\n",
        "        num_winning = len(winning_trades)\n",
        "        num_losing = len(losing_trades)\n",
        "        num_breakeven = len(breakeven_trades)\n",
        "\n",
        "        win_rate = (num_winning / total_trades) * 100 if total_trades > 0 else 0\n",
        "        avg_win = winning_trades[pnl_col_for_analysis].mean() if num_winning > 0 else 0\n",
        "        avg_loss = losing_trades[pnl_col_for_analysis].mean() if num_losing > 0 else 0\n",
        "        expectancy = (win_rate / 100) * avg_win + ((100 - win_rate) / 100) * avg_loss if total_trades > 0 else 0\n",
        "\n",
        "        # 5. Update Max Drawdown calculation to use 'PnL_trade' and sort by exit time\n",
        "        # Calculate cumulative PnL and then cumulative capital\n",
        "        trades_df_analysis = trades_df_analysis.sort_values(by='exit_time') # Sort by exit time for cumulative calculation\n",
        "\n",
        "        trades_df_analysis['cumulative_pnl'] = trades_df_analysis[pnl_col_for_analysis].cumsum()\n",
        "\n",
        "        # Add initial capital to cumulative PnL\n",
        "        trades_df_analysis['cumulative_capital'] = self.initial_capital + trades_df_analysis['cumulative_pnl']\n",
        "\n",
        "        # Calculate peak capital up to each point\n",
        "        trades_df_analysis['peak_capital'] = trades_df_analysis['cumulative_capital'].cummax()\n",
        "\n",
        "        # Calculate drawdown at each point\n",
        "        trades_df_analysis['drawdown'] = trades_df_analysis['peak_capital'] - trades_df_analysis['cumulative_capital']\n",
        "\n",
        "        # Calculate percentage drawdown\n",
        "        # Avoid division by zero if peak_capital is 0 or None\n",
        "        trades_df_analysis['pct_drawdown'] = trades_df_analysis.apply(\n",
        "            lambda row: (row['drawdown'] / row['peak_capital']) * 100 if row['peak_capital'] > 0 and pd.notna(row['peak_capital']) else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        max_drawdown_amount = trades_df_analysis['drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "        max_drawdown_pct = trades_df_analysis['pct_drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "\n",
        "\n",
        "        # 6. Update analysis summary metric names\n",
        "        analysis_summary = {\n",
        "            'Metric': [\n",
        "                'Initial Capital',\n",
        "                'Final Capital',\n",
        "                'Total PnL (Net)', # Indicate Net PnL\n",
        "                'Total Trades',\n",
        "                'Winning Trades (Net)', # Indicate Net PnL\n",
        "                'Losing Trades (Net)', # Indicate Net PnL\n",
        "                'Breakeven Trades (Net)', # Indicate Net PnL\n",
        "                'Win Rate (%) (Net PnL)', # Indicate Net PnL\n",
        "                'Average Win (Net)', # Indicate Net PnL\n",
        "                'Average Loss (Net)', # Indicate Net PnL\n",
        "                'Expectancy per Trade (Net)', # Indicate Net PnL\n",
        "                'Max Drawdown (Amount)',\n",
        "                'Max Drawdown (%)',\n",
        "            ],\n",
        "            'Value': [\n",
        "                self.initial_capital,\n",
        "                self.current_capital,\n",
        "                round(total_pnl, 2), # Format to 2 decimal places\n",
        "                total_trades,\n",
        "                num_winning,\n",
        "                num_losing,\n",
        "                num_breakeven,\n",
        "                round(win_rate, 2), # Format to 2 decimal places\n",
        "                round(avg_win, 2),\n",
        "                round(avg_loss, 2),\n",
        "                round(expectancy, 2),\n",
        "                round(max_drawdown_amount, 2),\n",
        "                round(max_drawdown_pct, 2),\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        analysis_df = pd.DataFrame(analysis_summary)\n",
        "\n",
        "        logger.info(\"Backtest analysis completed.\")\n",
        "        # You can print the analysis_df here or return it\n",
        "        # print(\"\\n--- Backtest Analysis Summary ---\")\n",
        "        # display(analysis_df) # Use display for notebooks\n",
        "\n",
        "        # 8. Ensure the method returns the updated analysis summary DataFrame\n",
        "        return analysis_df\n",
        "\n",
        "    def get_completed_trades(self):\n",
        "        \"\"\"Returns a DataFrame of completed trades.\"\"\"\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "                    # Ensure numeric columns are numeric\n",
        "                    numeric_cols = [\n",
        "                        'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                        'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                        'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                        'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                        'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                        'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                        'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                        'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                        'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "                    ]\n",
        "                    for col in numeric_cols:\n",
        "                        if col in completed_trades_df.columns:\n",
        "                            completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "                    return completed_trades_df\n",
        "                else:\n",
        "                    return pd.DataFrame() # Return empty DataFrame if no trades"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging level set to DEBUG for test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "113db150"
      },
      "source": [
        "**Reasoning**:\n",
        "Review and confirm that the exit-specific data points are correctly captured from the `data_point` Series within the `execute_trade` and `close_all_positions` methods when closing a position, ensuring the use of `.get()` for safety and verifying the assignment of `Exit_signal_type` and `Exit_order_type`. Also, check and update the debug logging for exit columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41921f6a",
        "outputId": "7542f793-b0c8-46fc-a12a-18d71c6a1ab4"
      },
      "source": [
        "# _1113_6BacktesterV6.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime # Import datetime for timestamp IDs\n",
        "import uuid  # Keep uuid import in case it's used elsewhere, although not for generate_trade_id now\n",
        "import sys # Import sys to check for handlers\n",
        "# from _012_instruments import get_instrument_type # Removed unused import\n",
        "# --- Logging Configuration ---\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Also ensure the root logger has a handler and is set to DEBUG,\n",
        "# in case basicConfig was called elsewhere previously.\n",
        "if not logging.root.handlers:\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "else:\n",
        "    # If handlers exist, ensure at least one handler's level is DEBUG\n",
        "    # and the root logger's level is DEBUG\n",
        "    logging.root.setLevel(logging.DEBUG)\n",
        "    handler_found = False\n",
        "    for handler in logging.root.handlers:\n",
        "        if isinstance(handler, logging.StreamHandler) and handler.stream in [sys.stdout, sys.stderr]:\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler_found = True\n",
        "    # If no suitable handler is found (e.g., only file handlers), add a StreamHandler\n",
        "    if not handler_found:\n",
        "         stream_handler = logging.StreamHandler(sys.stdout)\n",
        "         stream_handler.setLevel(logging.DEBUG)\n",
        "         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "         stream_handler.setFormatter(formatter)\n",
        "         logging.root.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "print(\"Logging level set to DEBUG for test.\")\n",
        "\n",
        "# Examine the __init__ method for data validation logic\n",
        "# Check for the existence of the required_columns and log warnings for potential entry/exit data columns.\n",
        "\n",
        "# required_columns check\n",
        "# missing_required = [col for col in required_columns if col not in data.columns]\n",
        "# if missing_required:\n",
        "#      raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "# entry_columns_to_check and exit_data_columns_to_check check\n",
        "# missing_data_cols = [col for col in entry_columns_to_check + exit_data_columns_to_check if col not in data.columns]\n",
        "# if missing_data_cols:\n",
        "#      logger.warning(f\"Input data is missing potential indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records.\")\n",
        "\n",
        "# The current code already performs these checks.\n",
        "# required_columns are checked and raise a ValueError if missing.\n",
        "# entry_columns_to_check and exit_data_columns_to_check are checked and log a warning if missing.\n",
        "\n",
        "# Add comments to clarify assumptions about columns expected in input data.\n",
        "\n",
        "class BacktesterV3:\n",
        "    \"\"\"\n",
        "    A simple backtesting engine for evaluating trading strategies.\n",
        "    Processes historical data bar by bar, generates signals, and simulates trades.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, instrument_keys: list, active_strategies_instances: dict, initial_capital: float):\n",
        "        \"\"\"\n",
        "        Includes the same parameters as the original __init__\n",
        "\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            data: A pandas DataFrame containing historical market data for all instruments,\n",
        "                expected to have columns like 'timestamp', 'instrument_key',\n",
        "                'open', 'high', 'low', 'close', 'volume', etc. It is also expected\n",
        "                to contain pre-calculated indicator and pattern columns used by\n",
        "                the strategies and for recording trade details.\n",
        "            instrument_keys: A list of unique instrument keys present in the data.\n",
        "            active_strategies_instances: A dictionary where keys are strategy names\n",
        "                                        (strings) and values are instantiated strategy\n",
        "                                        objects with a `generate_signal(data_point)` method.\n",
        "            initial_capital: The starting capital for the backtest simulation.\n",
        "        \"\"\"\n",
        "        if data is None or data.empty:\n",
        "            raise ValueError(\"Input data DataFrame is None or empty.\")\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n",
        "        if data.index.name is not None:\n",
        "            logger.warning(\"Input data index is not None. Consider resetting the index before passing to Backtester.\")\n",
        "\n",
        "\n",
        "        # Ensure essential columns are present and sorted\n",
        "        required_columns = ['timestamp', 'instrument_key', 'open', 'high', 'low', 'close']\n",
        "        # Define columns expected to be in the input data for recording trade details.\n",
        "        # These are typically pre-calculated indicators or pattern detection results.\n",
        "        entry_exit_data_columns_expected = [\n",
        "            'Trend', 'SMA20', 'RSI', 'RSIMA', 'ATR', 'ADX', 'Volatility',\n",
        "            'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "            'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "            'name', 'interval', 'Currency',\n",
        "            'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "            'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price'\n",
        "        ]\n",
        "\n",
        "        # The backtester expects these columns to be pre-calculated and provided in the input data.\n",
        "        # Strategies generate signals based on these columns, and their values at the time of\n",
        "        # entry and exit are recorded in the completed_trades DataFrame.\n",
        "\n",
        "\n",
        "        # Perform a relaxed check: log a warning if potential entry/exit columns from data are missing\n",
        "        missing_data_cols = [col for col in entry_exit_data_columns_expected if col not in data.columns]\n",
        "        if missing_data_cols:\n",
        "            logger.warning(f\"Input data is missing expected indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records. Ensure your data preparation includes these columns if strategies or analysis depend on them.\")\n",
        "\n",
        "\n",
        "        # Ensure mandatory required columns are present\n",
        "        missing_required = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_required:\n",
        "            raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "\n",
        "        # Ensure timestamp is datetime and sorted\n",
        "        try:\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
        "                data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True) # Convert to UTC\n",
        "            # Drop rows where timestamp conversion failed\n",
        "            data = data.dropna(subset=['timestamp'])\n",
        "            # Sort by timestamp and then instrument_key to process bars chronologically per instrument\n",
        "            self.data = data.sort_values(by=['timestamp', 'instrument_key']).reset_index(drop=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing timestamp column in data: {e}\")\n",
        "\n",
        "\n",
        "        self.instrument_keys = instrument_keys\n",
        "        self.active_strategies_instances = active_strategies_instances\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # --- Backtesting State Variables ---\n",
        "        self.current_capital = initial_capital\n",
        "        self.positions = {}  # Dictionary to track open positions {instrument_key: {...entry details...}}\n",
        "        self.completed_trades = [] # List to store completed trades\n",
        "        self.trade_id_counter = 0 # Simple counter for trade IDs\n",
        "        self.debug_log = [] # List to store debug information\n",
        "\n",
        "        # Debug lists to capture values\n",
        "        self._debug_timestamps = []\n",
        "        self._debug_close_values = []\n",
        "        self._debug_validity = []\n",
        "\n",
        "        # Simple Slippage and Commission model (can be customized)\n",
        "        self.slippage_pct = 0.001  # 0.1% slippage per trade\n",
        "        self.commission_per_trade = 0.01 # $0.01 fixed commission per trade\n",
        "\n",
        "\n",
        "        logger.info(f\"BacktesterV2 initialized with {len(self.instrument_keys)} instruments and {len(self.active_strategies_instances)} active strategies.\")\n",
        "        logger.info(f\"Initial Capital: {self.initial_capital}\")\n",
        "        logger.info(f\"Data shape for backtesting: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def generate_trade_id(self, timestamp: datetime):\n",
        "        \"\"\"Generates a unique trade ID using a provided timestamp.\"\"\"\n",
        "        # Using microseconds to increase the chance of uniqueness\n",
        "        return timestamp.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    def execute_trade(self, trade_id: str, instrument_key: str, timestamp: datetime, signal: str, strategy_name: str, price: float, data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Simulates executing a trade based on a signal.\n",
        "\n",
        "        Args:\n",
        "            trade_id: Unique identifier for the trade.\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the trade execution (bar close time).\n",
        "            signal: The trading signal ('BUY' or 'SELL').\n",
        "            strategy_name: The name of the strategy generating the signal.\n",
        "            price: The execution price (typically the close price of the bar).\n",
        "            data_point: The pandas Series representing the data row for this bar. This Series\n",
        "                        is expected to contain pre-calculated indicator and pattern data\n",
        "                        used for entry/exit conditions and recording.\n",
        "        \"\"\"\n",
        "        # Determine instrument type to handle lot size/quantity logic\n",
        "        # instrument_type = get_instrument_type(instrument_key) # Removed due to import error\n",
        "        instrument_type = 'Unknown' # Placeholder\n",
        "\n",
        "\n",
        "        # Simple fixed quantity logic (can be replaced with dynamic position sizing)\n",
        "        quantity_to_trade = 1 # Example: trade 1 unit/lot\n",
        "\n",
        "        if signal == 'BUY':\n",
        "            # Check if we already have a position in this instrument (optional, depending on strategy)\n",
        "            if instrument_key not in self.positions:\n",
        "                # Simulate buying\n",
        "                cost = quantity_to_trade * price\n",
        "                # Check if we have enough capital\n",
        "                if self.current_capital >= cost:\n",
        "                    self.current_capital -= cost\n",
        "\n",
        "                    # Calculate entry costs (slippage and commission on entry)\n",
        "                    entry_slippage = cost * self.slippage_pct\n",
        "                    entry_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (entry_slippage + entry_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Capture entry-specific details from the data_point and other variables\n",
        "                    self.positions[instrument_key] = {\n",
        "                        'quantity': quantity_to_trade,\n",
        "                        'entry_price': price, # This is the execution price for this simple model\n",
        "                        'entry_time': timestamp,\n",
        "                        'strategy': strategy_name,\n",
        "                        'trade_id': trade_id,\n",
        "                        'instrument_type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'side': 'BUY', # Store trade side\n",
        "\n",
        "                        # --- Entry-Specific Columns (Populated from data_point at Entry) ---\n",
        "                        'Strategy_name': strategy_name,\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'name': data_point.get('name'), # Use .get() to avoid errors if column is missing\n",
        "                        'interval': data_point.get('interval'),\n",
        "                        'Position_type': 'Long', # Assuming BUY means Long position\n",
        "                        'Entry_order_type': 'Market', # Assuming market order execution on close\n",
        "                        'Entry_timestamp': timestamp,\n",
        "                        'Entry_price_trigger': None, # Not explicitly handled in this simple model\n",
        "                        'Entry_price_execution': price,\n",
        "                        'Entry_shares': quantity_to_trade, # Using quantity_to_trade as shares\n",
        "                        'Entry_cost': cost, # Gross cost before fees\n",
        "                        'Entry_signal_type': signal, # Ensure signal is captured\n",
        "                        'Entry_Trend': data_point.get('Trend'), # Capture Trend at Entry\n",
        "                        'Entry_SMA20': data_point.get('SMA20'), # Capture SMA20 at Entry\n",
        "                        'Entry_RSI': data_point.get('RSI'), # Capture RSI at Entry\n",
        "                        'Entry_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Entry\n",
        "                        'Entry_ATR': data_point.get('ATR'), # Capture ATR at Entry\n",
        "                        'Entry_ADX': data_point.get('ADX'), # Capture ADX at Entry\n",
        "                        'Entry_Volatility': data_point.get('Volatility'), # Capture Volatility at Entry\n",
        "                        'Entry_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Entry\n",
        "                        'Entry_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Entry\n",
        "                        # Corrected column names to match expected input data\n",
        "                        'Entry_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Entry\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Entry\n",
        "                        'Instrument_Type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'Currency': data_point.get('Currency'),\n",
        "                        'Slippage_Entry': entry_slippage, # Store entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Store entry commission\n",
        "\n",
        "                        # Placeholder for other entry-specific details that might be calculated by strategy (e.g., initial stop/target)\n",
        "                        'Initial_Stop_Loss_Distance (%)': data_point.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': data_point.get('Risk_Amount'),\n",
        "                        'Reward_Amount': data_point.get('Reward_Amount'),\n",
        "\n",
        "\n",
        "                        # Placeholders for exit/other info that will be filled on close\n",
        "                        # These fields are included here so the structure is consistent for retrieval on exit,\n",
        "                        # even though their values are None at the time of entry.\n",
        "                         'Max_Favorable_Excursion_MFE': None, # Will be calculated on exit\n",
        "                         'Max_Adverse_Excursion_MAE': None, # Will be calculated on exit\n",
        "                        'Current_trailing_stop': None, # Need logic for trailing stops\n",
        "                        'Trailing_stop_method': None,\n",
        "                        'Trailing_stop_value': None,\n",
        "                        'Stop_loss_price': None,\n",
        "\n",
        "\n",
        "                        'Exit_Trend': None, 'Exit_signal_type': None, 'Exit_SMA20': None,\n",
        "                        'Exit_RSI': None, 'Exit_RSI_MA': None, 'Exit_ATR': None, 'Exit_ADX': None,\n",
        "                        'Exit_Volatility': None, 'Exit_Breakout_Detected': None,\n",
        "                        'Exit_Breakdown_Detected': None, 'Exit_Bullish_Candlestick_Name': None,\n",
        "                        'Exit_Bearish_Candlestick_Name': None, 'Exit_Bullish_Chart_Pattern_Detected': None,\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': None, 'Exit_shares': None,\n",
        "                        'Exit_cost': None, 'Exit_revenue': None, 'PnL_trade': None,\n",
        "                        'Trade_type': None, 'Profit_loss': None, 'Exit_reason': None,\n",
        "                        'Slippage': None, 'Commission_Fees': None, 'Trade_Duration': None,\n",
        "                        'Exit_Order_Type': None\n",
        "                    }\n",
        "\n",
        "                    # --- Add debug logging for Entry columns here ---\n",
        "                    logger.debug(f\"DEBUG Entry Data Point for {instrument_key} at {timestamp}:\")\n",
        "                    debug_cols_to_check = [\n",
        "                        'Trend', 'SMA20', 'RSI', 'RSI_MA', 'ATR', 'ADX', 'Volatility',\n",
        "                        'Breakout_Detected', 'Breakdown_Detected',\n",
        "                        # Corrected debug column names to match expected input data\n",
        "                        'Bullish_Candlestick_Detected', 'Bearish_Candlestick_Detected',\n",
        "                        'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "                        'Currency', 'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "                        'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE', 'Current_trailing_stop',\n",
        "                        'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price', 'Exit_Trend',\n",
        "                        'Exit_signal_type', 'Exit_SMA20', 'Exit_RSI', 'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX',\n",
        "                        'Exit_Volatility', 'Exit_Breakout_Detected', 'Exit_Breakdown_Detected',\n",
        "                        'Exit_Bullish_Candlestick_Name', 'Exit_Bearish_Candlestick_Name',\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected', 'Exit_Bearish_Chart_Pattern_Detected',\n",
        "                        'Exit_cost'\n",
        "                    ]\n",
        "                    for col in debug_cols_to_check:\n",
        "                         logger.debug(f\"  {col}: {data_point.get(col, 'Column Not Found or None')}\")\n",
        "                    # --- End Debug Logging ---\n",
        "\n",
        "\n",
        "                    logger.info(f\"Executed BUY trade {trade_id} for {instrument_key} at {timestamp} @ {price} (Qty: {quantity_to_trade}). Costs: Slippage={entry_slippage:.4f}, Commission={entry_commission:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'BUY', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'slippage': entry_slippage, 'commission': entry_commission})\n",
        "                else:\n",
        "                    logger.warning(f\"Insufficient capital ({self.current_capital:.2f}) to BUY {instrument_key} at {price} (Cost: {cost:.2f}). Skipping trade {trade_id}.\")\n",
        "                    self.debug_log.append({'type': 'SKIP_BUY_CAPITAL', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Insufficient Capital'})\n",
        "\n",
        "            else:\n",
        "                # Already in a position, maybe add to it or skip depending on strategy rules\n",
        "                logger.debug(f\"Skipping BUY signal for {instrument_key} at {timestamp}. Already in a position.\")\n",
        "                self.debug_log.append({'type': 'SKIP_BUY_POSITION', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Already in Position'})\n",
        "\n",
        "\n",
        "        elif signal == 'SELL':\n",
        "            # For backtesting, a 'SELL' signal usually means closing a long position or opening a short position\n",
        "            # Let's assume 'SELL' means closing a long position if one exists for simplicity in this example.\n",
        "            # For a shorting strategy, you'd need different logic.\n",
        "            if instrument_key in self.positions and self.positions[instrument_key]['side'] == 'BUY':\n",
        "                # Simulate selling to close a long position\n",
        "                position = self.positions[instrument_key]\n",
        "                quantity_to_sell = position['quantity']\n",
        "                entry_price = position['entry_price']\n",
        "                entry_time = position['entry_time']\n",
        "                strategy_opened = position['strategy']\n",
        "                open_trade_id = position['trade_id']\n",
        "\n",
        "\n",
        "                revenue = quantity_to_sell * price\n",
        "                self.current_capital += revenue\n",
        "\n",
        "                # Calculate Profit/Loss (Gross PnL)\n",
        "                gross_pnl = (price - entry_price) * quantity_to_sell # For long position\n",
        "\n",
        "                # Calculate exit costs (slippage and commission on exit)\n",
        "                exit_slippage = revenue * self.slippage_pct\n",
        "                exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "                # Calculate Net PnL\n",
        "                total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "                total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "                pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "                # Calculate Trade Duration\n",
        "                trade_duration = (timestamp - entry_time).total_seconds() if pd.notnull(timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "                # Record completed trade - Populate all desired columns\n",
        "                trade_record = {\n",
        "                    'open_trade_id': open_trade_id,\n",
        "                    'close_trade_id': trade_id,\n",
        "                    'instrument_key': instrument_key,\n",
        "                    'instrument_type': position.get('instrument_type'), # Assuming this key is correct in position\n",
        "                    'side': position.get('side'), # Side of the position being closed (BUY/LONG)\n",
        "                    'quantity': quantity_to_sell, # Quantity closed\n",
        "                    'entry_price': entry_price,\n",
        "                    'entry_time': entry_time,\n",
        "                    'exit_price': price,\n",
        "                    'exit_time': timestamp,\n",
        "                    'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "                    'strategy_opened': strategy_opened,\n",
        "                    'strategy_closed': strategy_name, # Record which strategy/signal closed it\n",
        "\n",
        "                    # --- Transfer Entry Details from Position ---\n",
        "                    'Strategy_name': position.get('Strategy_name'),\n",
        "                    'instrument_key': position.get('instrument_key'),\n",
        "                    'name': position.get('name'),\n",
        "                    'interval': position.get('interval'),\n",
        "                    'Position_type': position.get('Position_type'),\n",
        "                    'Entry_order_type': position.get('Entry_order_type'),\n",
        "                    'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                    'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                    'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                    'Entry_shares': position.get('Entry_shares'),\n",
        "                    'Entry_cost': position.get('Entry_cost'),\n",
        "                    'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                    'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                    'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                    'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                    'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                    'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                    'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                    'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                    'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                    'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                    # Corrected keys to match the expected format\n",
        "                    'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                    'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                    'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                    'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                    'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                    'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                    'Slippage_Entry': position.get('Slippage_Entry'), # Transfer entry slippage\n",
        "                    'Commission_Fees_Entry': position.get('Commission_Fees_Entry'), # Transfer entry commission\n",
        "                    'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                    'Risk_Amount': position.get('Risk_Amount'),\n",
        "                    'Reward_Amount': position.get('Reward_Amount'),\n",
        "                    'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                    'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                    # --- Exit-Specific Columns (Populated from data_point at Exit) ---\n",
        "                    'Exit_Trend': data_point.get('Trend'), # Capture Trend at Exit\n",
        "                    'Exit_signal_type': signal, # Signal that triggered the exit\n",
        "                    'Exit_SMA20': data_point.get('SMA20'), # Capture SMA20 at Exit\n",
        "                    'Exit_RSI': data_point.get('RSI'), # Capture RSI at Exit\n",
        "                    'Exit_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Exit\n",
        "                    'Exit_ATR': data_point.get('ATR'), # Capture ATR at Exit\n",
        "                    'Exit_ADX': data_point.get('ADX'), # Capture ADX at Exit\n",
        "                    'Exit_Volatility': data_point.get('Volatility'), # Capture Volatility at Exit\n",
        "                    'Exit_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Exit\n",
        "                    'Exit_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Exit\n",
        "                    # Corrected keys to match the expected format\n",
        "                    'Exit_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Exit\n",
        "                    'Exit_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Exit\n",
        "                    'Exit_Bullish_Chart_Pattern_Detected': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Exit\n",
        "                    'Exit_Bearish_Chart_Pattern_Detected': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Exit\n",
        "                    'Exit_shares': quantity_to_sell, # Shares exited\n",
        "                    'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "                    'Exit_revenue': revenue, # Gross revenue before fees\n",
        "                    'PnL_trade': pnl_trade, # Net PnL after costs\n",
        "                    'Trade_type': 'Long Close (Signal)', # Or 'Long' if trade refers to the full cycle\n",
        "                    'Profit_loss': pnl_trade, # Update Profit_loss to net PnL\n",
        "                    'Exit_reason': f'Signal_{signal}', # Reason for exit\n",
        "                    'Exit_Order_Type': 'Market', # Set Exit_Order_Type to 'Market'\n",
        "\n",
        "                    # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                    'Current_trailing_stop': data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                    'Trailing_stop_method': data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                    'Trailing_stop_value': data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                    'Stop_loss_price': data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "\n",
        "                    'Slippage': total_slippage, # Total slippage for the round trip\n",
        "                    'Commission_Fees': total_commission, # Total commission for the round trip\n",
        "                    'Trade_Duration': trade_duration,\n",
        "\n",
        "                }\n",
        "                self.completed_trades.append(trade_record)\n",
        "\n",
        "\n",
        "                # Remove position\n",
        "                del self.positions[instrument_key]\n",
        "\n",
        "                logger.info(f\"Executed SELL trade {trade_id} for {instrument_key} at {timestamp} @ {price} to CLOSE long position {open_trade_id}. Gross PnL: {gross_pnl:.2f}. Costs: Slippage={total_slippage:.4f}, Commission={total_commission:.2f}. Net PnL: {pnl_trade:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                self.debug_log.append({'type': 'SELL_CLOSE_LONG', 'open_trade_id': open_trade_id, 'close_trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_sell, 'gross_pnl': gross_pnl, 'net_pnl': pnl_trade, 'strategy_closed': strategy_name})\n",
        "\n",
        "\n",
        "            else:\n",
        "                # No matching long position to close, or maybe a shorting signal\n",
        "                # For this simple backtester, we'll just log and skip if no long position\n",
        "                logger.debug(f\"Skipping SELL signal for {instrument_key} at {timestamp}. No matching long position to close.\")\n",
        "                self.debug_log.append({'type': 'SKIP_SELL_NO_LONG', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'strategy': strategy_name, 'reason': 'No Long Position'})\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the backtesting simulation bar by bar through the data.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting backtest simulation...\")\n",
        "\n",
        "        # Group data by timestamp first, then iterate through timestamps\n",
        "        # This processes all instruments available at a given time before moving to the next time.\n",
        "        grouped_by_time = self.data.groupby('timestamp')\n",
        "\n",
        "        for timestamp, time_slice_df in grouped_by_time:\n",
        "            # Process data for all instruments available at this timestamp\n",
        "            for index, data_point in time_slice_df.iterrows():\n",
        "                instrument_key = data_point['instrument_key']\n",
        "                current_price = data_point['close'] # Assume close price for execution\n",
        "\n",
        "                # Debug capture\n",
        "                self._debug_timestamps.append(timestamp)\n",
        "                self._debug_close_values.append(current_price)\n",
        "                self._debug_validity.append(pd.notna(current_price))\n",
        "\n",
        "                # Ensure current_price is valid for trading\n",
        "                if pd.isna(current_price):\n",
        "                    logger.debug(f\"Skipping signal generation for {instrument_key} at {timestamp} due to invalid close price ({current_price}).\")\n",
        "                    self.debug_log.append({'type': 'SKIP_SIGNAL_PRICE_NAN', 'instrument': instrument_key, 'time': timestamp, 'reason': 'Invalid Price'})\n",
        "                    continue # Skip this data point if price is invalid\n",
        "\n",
        "                # Check for signals from all active strategies for this data point\n",
        "                # Pass the single data_point (as a Series) to the strategy\n",
        "                # The strategy is expected to handle a single row/Series or convert it internally\n",
        "                # For the backtester's execute_trade, we need the Series directly.\n",
        "\n",
        "                for strategy_name, strategy_instance in self.active_strategies_instances.items():\n",
        "                    try:\n",
        "                        # Pass the single data_point Series to the strategy's generate_signal\n",
        "                        # Ensure data_point is passed as a DataFrame slice if strategy expects DataFrame\n",
        "                        signal = strategy_instance.generate_signal(pd.DataFrame([data_point]))\n",
        "                        # Ensure signal is a string, handle potential None returns gracefully\n",
        "                        signal = str(signal).upper() if signal is not None else 'HOLD'\n",
        "\n",
        "                        if signal in ['BUY', 'SELL']:\n",
        "                            # Generate a unique trade ID for this potential trade using the bar's timestamp\n",
        "                            trade_id = self.generate_trade_id(timestamp) # Pass the historical timestamp\n",
        "                            # Pass the original data_point Series to execute_trade\n",
        "                            self.execute_trade(trade_id, instrument_key, timestamp, signal, strategy_name, current_price, data_point)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error generating signal for {instrument_key} at {timestamp} using strategy '{strategy_name}': {e}\", exc_info=True)\n",
        "                        self.debug_log.append({'type': 'STRATEGY_ERROR', 'instrument': instrument_key, 'time': timestamp, 'strategy': strategy_name, 'error': str(e)})\n",
        "\n",
        "\n",
        "        # After iterating through all data, close any remaining open positions\n",
        "        self.close_all_positions(self.data['timestamp'].max()) # Use the timestamp of the last data point as exit time\n",
        "\n",
        "        logger.info(\"Backtest simulation completed.\")\n",
        "        logger.info(f\"Final Capital: {self.current_capital:.2f}\")\n",
        "        logger.info(f\"Number of completed trades: {len(self.completed_trades)}\")\n",
        "        logger.info(f\"Number of open positions remaining: {len(self.positions)}\")\n",
        "\n",
        "        # Return completed trades as a DataFrame for analysis\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_df.columns:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "            # Ensure numeric columns are numeric\n",
        "            numeric_cols = [\n",
        "                'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "            ]\n",
        "            for col in numeric_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "            return completed_trades_df\n",
        "        else:\n",
        "            logger.warning(\"No completed trades recorded. Returning empty DataFrame.\")\n",
        "            return pd.DataFrame() # Return empty DataFrame if no trades\n",
        "\n",
        "\n",
        "    def close_all_positions(self, exit_timestamp: datetime):\n",
        "        \"\"\"\n",
        "        Closes all remaining open positions at the specified exit timestamp.\n",
        "        Assumes closing at the price of the last available bar for each instrument.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Closing all remaining {len(self.positions)} open positions at {exit_timestamp}...\")\n",
        "\n",
        "        # Get the last known price and data point for each instrument with an open position\n",
        "        last_data_points = self.data.groupby('instrument_key').tail(1).set_index('instrument_key')\n",
        "        last_prices = last_data_points['close'].to_dict()\n",
        "\n",
        "\n",
        "        positions_to_close = list(self.positions.keys()) # Iterate over a copy\n",
        "\n",
        "        for instrument_key in positions_to_close:\n",
        "            if instrument_key in self.positions: # Check if position still exists (wasn't closed by a signal just before the end)\n",
        "                position = self.positions[instrument_key]\n",
        "                closing_price = last_prices.get(instrument_key, np.nan) # Get last price, default to NaN if instrument not found\n",
        "\n",
        "                # Get the last data point for the instrument to capture exit conditions\n",
        "                last_data_point = last_data_points.get(instrument_key, pd.Series({})) # Use empty Series if no data found\n",
        "\n",
        "\n",
        "                if pd.notna(closing_price):\n",
        "                    trade_id = self.generate_trade_id(exit_timestamp) # Generate a new trade ID for the closing trade using exit_timestamp\n",
        "                    # Simulate selling to close a long position\n",
        "                    quantity_to_sell = position['quantity']\n",
        "                    entry_price = position['entry_price']\n",
        "                    entry_time = position['entry_time']\n",
        "                    strategy_opened = position['strategy']\n",
        "                    open_trade_id = position['trade_id']\n",
        "\n",
        "\n",
        "                    revenue = quantity_to_sell * closing_price\n",
        "                    self.current_capital += revenue\n",
        "\n",
        "                    # Calculate Profit/Loss (Gross PnL)\n",
        "                    gross_pnl = (closing_price - entry_price) * quantity_to_sell # For long position\n",
        "\n",
        "                    # Calculate exit costs (slippage and commission on exit)\n",
        "                    exit_slippage = revenue * self.slippage_pct\n",
        "                    exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Calculate Net PnL\n",
        "                    total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "                    total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "                    pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "\n",
        "                    # Calculate Trade Duration\n",
        "                    trade_duration = (exit_timestamp - entry_time).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "\n",
        "                    # Record completed trade - Populate all desired columns\n",
        "                    trade_record = {\n",
        "                        'open_trade_id': open_trade_id,\n",
        "                        'close_trade_id': trade_id, # New ID for closing\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'), # Use .get() for safety\n",
        "                        'side': position.get('side'), # Side of the position being closed (BUY/LONG)\n",
        "                        'quantity': quantity_to_sell, # Quantity closed\n",
        "                        'entry_price': entry_price,\n",
        "                        'entry_time': entry_time,\n",
        "                        'exit_price': closing_price,\n",
        "                        'exit_time': exit_timestamp, # Use the provided exit timestamp\n",
        "                        'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "                        'strategy_opened': strategy_opened,\n",
        "                        'strategy_closed': 'Backtester_Forced_Close', # Indicate it was closed by the backtester\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': position.get('Slippage_Entry'), # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': position.get('Commission_Fees_Entry'), # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close', # Indicate forced close\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': quantity_to_sell, # Shares exited\n",
        "                        'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "                        'Exit_revenue': revenue, # Gross revenue before fees\n",
        "                        'PnL_trade': pnl_trade, # Net PnL after costs\n",
        "                        'Trade_type': 'Long Close (Forced)', # Or 'Long' if trade refers to the full cycle\n",
        "                        'Profit_loss': pnl_trade, # Update Profit_loss to net PnL\n",
        "                        'Exit_reason': 'Backtester_Forced_Close', # Reason for exit\n",
        "                        'Exit_Order_Type': 'Market', # Set Exit_Order_Type to 'Market' or 'Forced'\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "\n",
        "                        'Slippage': total_slippage, # Total slippage for the round trip\n",
        "                        'Commission_Fees': total_commission, # Total commission for the round trip\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(trade_record)\n",
        "\n",
        "                    # Remove position\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "                    logger.info(f\"Closed remaining position {open_trade_id} for {instrument_key} at {exit_timestamp} @ {closing_price}. Gross PnL: {gross_pnl:.2f}. Costs: Slippage={total_slippage:.4f}, Commission={total_commission:.2f}. Net PnL: {pnl_trade:.2f}. Capital: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE', 'open_trade_id': open_trade_id, 'close_trade_id': trade_id, 'instrument': instrument_key, 'time': exit_timestamp, 'price': closing_price, 'quantity': quantity_to_sell, 'gross_pnl': gross_pnl, 'net_pnl': pnl_trade, 'strategy_closed': 'Backtester_Forced_Close'})\n",
        "\n",
        "                else:\n",
        "                    logger.warning(f\"Could not find last price for {instrument_key}. Cannot close position {position['trade_id']}. Logging as unresolved.\")\n",
        "                    # Log as an unresolved position or assume zero PnL\n",
        "\n",
        "                    # Calculate Trade Duration even if closing price is NaN\n",
        "                    trade_duration = (exit_timestamp - position.get('entry_time')).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(position.get('entry_time')) else None\n",
        "\n",
        "                    # Transfer known costs\n",
        "                    entry_slippage = position.get('Slippage_Entry', 0)\n",
        "                    entry_commission = position.get('Commission_Fees_Entry', 0)\n",
        "\n",
        "\n",
        "                    unresolved_trade_record = {\n",
        "                        'open_trade_id': position.get('trade_id'),\n",
        "                        'close_trade_id': None, # No closing trade ID\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'),\n",
        "                        'side': position.get('side'),\n",
        "                        'quantity': position.get('quantity'),\n",
        "                        'entry_price': position.get('entry_price'),\n",
        "                        'entry_time': position.get('entry_time'),\n",
        "                        'exit_price': None, # No exit price\n",
        "                        'exit_time': exit_timestamp, # Use the requested exit timestamp\n",
        "                        'pnl': 0, # Assume zero Gross PnL if cannot close\n",
        "                        'strategy_opened': position.get('strategy'),\n",
        "                        'strategy_closed': 'Backtester_Forced_Close_Error', # Indicate error\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': entry_slippage, # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close_Error', # Indicate forced close error\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        # Corrected keys to match the expected format\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': position.get('quantity'), # Shares that were supposed to be exited\n",
        "                        'Exit_cost': 0,\n",
        "                        'Exit_revenue': 0, # Assuming zero revenue if cannot close\n",
        "                        'PnL_trade': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Profit_loss': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Exit_reason': 'Backtester_Forced_Close_Error: No_Last_Price', # Reason for exit\n",
        "                        'Exit_Order_Type': None, # Could not execute exit order\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "                        'Slippage': entry_slippage, # Only entry slippage is known\n",
        "                        'Commission_Fees': entry_commission, # Only entry commission is known\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(unresolved_trade_record)\n",
        "\n",
        "                    # Remove position even if it couldn't be closed properly to prevent it from being processed again\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE_ERROR', 'open_trade_id': position['trade_id'], 'instrument': instrument_key, 'time': exit_timestamp, 'reason': 'Last price not available'})\n",
        "\n",
        "\n",
        "        logger.info(\"All remaining positions closed.\")\n",
        "\n",
        "\n",
        "    def analyze_backtest_results(self):\n",
        "        \"\"\"\n",
        "        Analyzes the completed trades and provides performance metrics.\n",
        "        Returns a DataFrame summarizing the analysis.\n",
        "        \"\"\"\n",
        "        logger.info(\"Analyzing backtest results...\")\n",
        "\n",
        "        if not self.completed_trades:\n",
        "            logger.warning(\"No completed trades to analyze.\")\n",
        "            return pd.DataFrame({'Message': ['No completed trades to analyze.']})\n",
        "\n",
        "        # 1. Access the self.completed_trades list and Create a pandas DataFrame\n",
        "        trades_df = pd.DataFrame(self.completed_trades)\n",
        "\n",
        "        # 3. Ensure that relevant columns are converted to appropriate numeric types\n",
        "        numeric_cols = [\n",
        "            'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "            'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "            'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "            'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "            'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "            'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "            'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "            'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Include other potentially numeric cols\n",
        "        ]\n",
        "        for col in numeric_cols:\n",
        "            if col in trades_df.columns:\n",
        "                trades_df[col] = pd.to_numeric(trades_df[col], errors='coerce')\n",
        "\n",
        "        # Handle potential NaN values during conversion - drop rows where PnL_trade (or pnl) is NaN\n",
        "        pnl_col_for_analysis = 'PnL_trade' if 'PnL_trade' in trades_df.columns else 'pnl'\n",
        "        if pnl_col_for_analysis in trades_df.columns:\n",
        "            # Only consider trades with a valid PnL for core analysis metrics\n",
        "            trades_df_analysis = trades_df.dropna(subset=[pnl_col_for_analysis]).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "        else:\n",
        "            logger.warning(\"Neither 'PnL_trade' nor 'pnl' column found for analysis.\")\n",
        "            return pd.DataFrame({'Message': ['No PnL column found for analysis.']})\n",
        "\n",
        "\n",
        "        if trades_df_analysis.empty:\n",
        "            logger.warning(\"No valid trades after numeric conversion/dropna for analysis. Analysis stopped.\")\n",
        "            return pd.DataFrame({'Message': ['No valid trades after numeric conversion/dropna for analysis.']})\n",
        "\n",
        "\n",
        "        # 4. Update the calculation of basic performance metrics using 'PnL_trade'\n",
        "        total_trades = len(trades_df_analysis)\n",
        "        total_pnl = trades_df_analysis[pnl_col_for_analysis].sum()\n",
        "\n",
        "        winning_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] > 0]\n",
        "        losing_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] < 0]\n",
        "        breakeven_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] == 0]\n",
        "\n",
        "        num_winning = len(winning_trades)\n",
        "        num_losing = len(losing_trades)\n",
        "        num_breakeven = len(breakeven_trades)\n",
        "\n",
        "        win_rate = (num_winning / total_trades) * 100 if total_trades > 0 else 0\n",
        "        avg_win = winning_trades[pnl_col_for_analysis].mean() if num_winning > 0 else 0\n",
        "        avg_loss = losing_trades[pnl_col_for_analysis].mean() if num_losing > 0 else 0\n",
        "        expectancy = (win_rate / 100) * avg_win + ((100 - win_rate) / 100) * avg_loss if total_trades > 0 else 0\n",
        "\n",
        "        # 5. Update Max Drawdown calculation to use 'PnL_trade' and sort by exit time\n",
        "        # Calculate cumulative PnL and then cumulative capital\n",
        "        trades_df_analysis = trades_df_analysis.sort_values(by='exit_time') # Sort by exit time for cumulative calculation\n",
        "\n",
        "        trades_df_analysis['cumulative_pnl'] = trades_df_analysis[pnl_col_for_analysis].cumsum()\n",
        "\n",
        "        # Add initial capital to cumulative PnL\n",
        "        trades_df_analysis['cumulative_capital'] = self.initial_capital + trades_df_analysis['cumulative_pnl']\n",
        "\n",
        "        # Calculate peak capital up to each point\n",
        "        trades_df_analysis['peak_capital'] = trades_df_analysis['cumulative_capital'].cummax()\n",
        "\n",
        "        # Calculate drawdown at each point\n",
        "        trades_df_analysis['drawdown'] = trades_df_analysis['peak_capital'] - trades_df_analysis['cumulative_capital']\n",
        "\n",
        "        # Calculate percentage drawdown\n",
        "        # Avoid division by zero if peak_capital is 0 or None\n",
        "        trades_df_analysis['pct_drawdown'] = trades_df_analysis.apply(\n",
        "            lambda row: (row['drawdown'] / row['peak_capital']) * 100 if row['peak_capital'] > 0 and pd.notna(row['peak_capital']) else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        max_drawdown_amount = trades_df_analysis['drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "        max_drawdown_pct = trades_df_analysis['pct_drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "\n",
        "\n",
        "        # 6. Update analysis summary metric names\n",
        "        analysis_summary = {\n",
        "            'Metric': [\n",
        "                'Initial Capital',\n",
        "                'Final Capital',\n",
        "                'Total PnL (Net)', # Indicate Net PnL\n",
        "                'Total Trades',\n",
        "                'Winning Trades (Net)', # Indicate Net PnL\n",
        "                'Losing Trades (Net)', # Indicate Net PnL\n",
        "                'Breakeven Trades (Net)', # Indicate Net PnL\n",
        "                'Win Rate (%) (Net PnL)', # Indicate Net PnL\n",
        "                'Average Win (Net)', # Indicate Net PnL\n",
        "                'Average Loss (Net)', # Indicate Net PnL\n",
        "                'Expectancy per Trade (Net)', # Indicate Net PnL\n",
        "                'Max Drawdown (Amount)',\n",
        "                'Max Drawdown (%)',\n",
        "            ],\n",
        "            'Value': [\n",
        "                self.initial_capital,\n",
        "                self.current_capital,\n",
        "                round(total_pnl, 2), # Format to 2 decimal places\n",
        "                total_trades,\n",
        "                num_winning,\n",
        "                num_losing,\n",
        "                num_breakeven,\n",
        "                round(win_rate, 2), # Format to 2 decimal places\n",
        "                round(avg_win, 2),\n",
        "                round(avg_loss, 2),\n",
        "                round(expectancy, 2),\n",
        "                round(max_drawdown_amount, 2),\n",
        "                round(max_drawdown_pct, 2),\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        analysis_df = pd.DataFrame(analysis_summary)\n",
        "\n",
        "        logger.info(\"Backtest analysis completed.\")\n",
        "        # You can print the analysis_df here or return it\n",
        "        # print(\"\\n--- Backtest Analysis Summary ---\")\n",
        "        # display(analysis_df) # Use display for notebooks\n",
        "\n",
        "        # 8. Ensure the method returns the updated analysis summary DataFrame\n",
        "        return analysis_df\n",
        "\n",
        "    def get_completed_trades(self):\n",
        "        \"\"\"Returns a DataFrame of completed trades.\"\"\"\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "                    # Ensure numeric columns are numeric\n",
        "                    numeric_cols = [\n",
        "                        'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                        'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                        'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                        'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                        'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                        'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                        'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                        'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                        'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "                    ]\n",
        "                    for col in numeric_cols:\n",
        "                        if col in completed_trades_df.columns:\n",
        "                            completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "                    return completed_trades_df\n",
        "                else:\n",
        "                    return pd.DataFrame() # Return empty DataFrame if no trades"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging level set to DEBUG for test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c8c6929"
      },
      "source": [
        "## Implement stop-loss/take-profit check\n",
        "\n",
        "### Subtask:\n",
        "Add a loop or check within `run_backtest` to evaluate stop-loss and take-profit conditions for open positions on each bar before processing new signals.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feb55b26"
      },
      "source": [
        "**Reasoning**:\n",
        "Add the `close_position_on_trigger` method to handle closing trades based on stop-loss or take-profit triggers. This method consolidates the logic for updating capital and recording completed trades, similar to the existing closing logic in `execute_trade`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73e43a0e",
        "outputId": "fc9cf5f8-849d-42e6-c6d3-b5f8621f7404"
      },
      "source": [
        "# _1113_6BacktesterV6.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "import sys\n",
        "# from _012_instruments import get_instrument_type\n",
        "# --- Logging Configuration ---\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Also ensure the root logger has a handler and is set to DEBUG,\n",
        "# in case basicConfig was called elsewhere previously.\n",
        "if not logging.root.handlers:\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "else:\n",
        "    # If handlers exist, ensure at least one handler's level is DEBUG\n",
        "    # and the root logger's level is DEBUG\n",
        "    logging.root.setLevel(logging.DEBUG)\n",
        "    handler_found = False\n",
        "    for handler in logging.root.handlers:\n",
        "        if isinstance(handler, logging.StreamHandler) and handler.stream in [sys.stdout, sys.stderr]:\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler_found = True\n",
        "    # If no suitable handler is found (e.g., only file handlers), add a StreamHandler\n",
        "    if not handler_found:\n",
        "         stream_handler = logging.StreamHandler(sys.stdout)\n",
        "         stream_handler.setLevel(logging.DEBUG)\n",
        "         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "         stream_handler.setFormatter(formatter)\n",
        "         logging.root.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "print(\"Logging level set to DEBUG for test.\")\n",
        "\n",
        "\n",
        "class BacktesterV3:\n",
        "    \"\"\"\n",
        "    A simple backtesting engine for evaluating trading strategies.\n",
        "    Processes historical data bar by bar, generates signals, and simulates trades.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, instrument_keys: list, active_strategies_instances: dict, initial_capital: float):\n",
        "        \"\"\"\n",
        "        Includes the same parameters as the original __init__\n",
        "\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            data: A pandas DataFrame containing historical market data for all instruments,\n",
        "                expected to have columns like 'timestamp', 'instrument_key',\n",
        "                'open', 'high', 'low', 'close', 'volume', etc. It is also expected\n",
        "                to contain pre-calculated indicator and pattern columns used by\n",
        "                the strategies and for recording trade details.\n",
        "            instrument_keys: A list of unique instrument keys present in the data.\n",
        "            active_strategies_instances: A dictionary where keys are strategy names\n",
        "                                        (strings) and values are instantiated strategy\n",
        "                                        objects with a `generate_signal(data_point)` method.\n",
        "            initial_capital: The starting capital for the backtest simulation.\n",
        "        \"\"\"\n",
        "        if data is None or data.empty:\n",
        "            raise ValueError(\"Input data DataFrame is None or empty.\")\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n",
        "        if data.index.name is not None:\n",
        "            logger.warning(\"Input data index is not None. Consider resetting the index before passing to Backtester.\")\n",
        "\n",
        "\n",
        "        # Ensure essential columns are present and sorted\n",
        "        required_columns = ['timestamp', 'instrument_key', 'open', 'high', 'low', 'close']\n",
        "        # Define columns expected to be in the input data for recording trade details.\n",
        "        # These are typically pre-calculated indicators or pattern detection results.\n",
        "        entry_exit_data_columns_expected = [\n",
        "            'Trend', 'SMA20', 'RSI', 'RSIMA', 'ATR', 'ADX', 'Volatility',\n",
        "            'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "            'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "            'name', 'interval', 'Currency',\n",
        "            'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "            'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price'\n",
        "        ]\n",
        "\n",
        "        # The backtester expects these columns to be pre-calculated and provided in the input data.\n",
        "        # Strategies generate signals based on these columns, and their values at the time of\n",
        "        # entry and exit are recorded in the completed_trades DataFrame.\n",
        "\n",
        "\n",
        "        # Perform a relaxed check: log a warning if potential entry/exit columns from data are missing\n",
        "        missing_data_cols = [col for col in entry_exit_data_columns_expected if col not in data.columns]\n",
        "        if missing_data_cols:\n",
        "            logger.warning(f\"Input data is missing expected indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records. Ensure your data preparation includes these columns if strategies or analysis depend on them.\")\n",
        "\n",
        "\n",
        "        # Ensure mandatory required columns are present\n",
        "        missing_required = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_required:\n",
        "            raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "\n",
        "        # Ensure timestamp is datetime and sorted\n",
        "        try:\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
        "                data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True) # Convert to UTC\n",
        "            # Drop rows where timestamp conversion failed\n",
        "            data = data.dropna(subset=['timestamp'])\n",
        "            # Sort by timestamp and then instrument_key to process bars chronologically per instrument\n",
        "            self.data = data.sort_values(by=['timestamp', 'instrument_key']).reset_index(drop=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing timestamp column in data: {e}\")\n",
        "\n",
        "\n",
        "        self.instrument_keys = instrument_keys\n",
        "        self.active_strategies_instances = active_strategies_instances\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # --- Backtesting State Variables ---\n",
        "        self.current_capital = initial_capital\n",
        "        self.positions = {}  # Dictionary to track open positions {instrument_key: {...entry details...}}\n",
        "        self.completed_trades = [] # List to store completed trades\n",
        "        self.trade_id_counter = 0 # Simple counter for trade IDs\n",
        "        self.debug_log = [] # List to store debug information\n",
        "\n",
        "        # Debug lists to capture values\n",
        "        self._debug_timestamps = []\n",
        "        self._debug_close_values = []\n",
        "        self._debug_validity = []\n",
        "\n",
        "        # Simple Slippage and Commission model (can be customized)\n",
        "        self.slippage_pct = 0.001  # 0.1% slippage per trade\n",
        "        self.commission_per_trade = 0.01 # $0.01 fixed commission per trade\n",
        "\n",
        "\n",
        "        logger.info(f\"BacktesterV2 initialized with {len(self.instrument_keys)} instruments and {len(self.active_strategies_instances)} active strategies.\")\n",
        "        logger.info(f\"Initial Capital: {self.initial_capital}\")\n",
        "        logger.info(f\"Data shape for backtesting: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def generate_trade_id(self, timestamp: datetime):\n",
        "        \"\"\"Generates a unique trade ID using a provided timestamp.\"\"\"\n",
        "        # Using microseconds to increase the chance of uniqueness\n",
        "        return timestamp.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    def execute_trade(self, trade_id: str, instrument_key: str, timestamp: datetime, signal: str, strategy_name: str, price: float, data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Simulates executing a trade based on a signal.\n",
        "\n",
        "        Args:\n",
        "            trade_id: Unique identifier for the trade.\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the trade execution (bar close time).\n",
        "            signal: The trading signal ('BUY' or 'SELL').\n",
        "            strategy_name: The name of the strategy generating the signal.\n",
        "            price: The execution price (typically the close price of the bar).\n",
        "            data_point: The pandas Series representing the data row for this bar. This Series\n",
        "                        is expected to contain pre-calculated indicator and pattern data\n",
        "                        used for entry/exit conditions and recording.\n",
        "        \"\"\"\n",
        "        # Determine instrument type to handle lot size/quantity logic\n",
        "        # instrument_type = get_instrument_type(instrument_key) # Removed due to import error\n",
        "        instrument_type = 'Unknown' # Placeholder\n",
        "\n",
        "\n",
        "        # Simple fixed quantity logic (can be replaced with dynamic position sizing)\n",
        "        quantity_to_trade = 1 # Example: trade 1 unit/lot\n",
        "\n",
        "        if signal == 'BUY':\n",
        "            # Check if we already have a position in this instrument (optional, depending on strategy)\n",
        "            if instrument_key not in self.positions:\n",
        "                # Simulate buying\n",
        "                cost = quantity_to_trade * price\n",
        "                # Check if we have enough capital\n",
        "                if self.current_capital >= cost:\n",
        "                    self.current_capital -= cost\n",
        "\n",
        "                    # Calculate entry costs (slippage and commission on entry)\n",
        "                    entry_slippage = cost * self.slippage_pct\n",
        "                    entry_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (entry_slippage + entry_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Capture entry-specific details from the data_point and other variables\n",
        "                    self.positions[instrument_key] = {\n",
        "                        'quantity': quantity_to_trade,\n",
        "                        'entry_price': price, # This is the execution price for this simple model\n",
        "                        'entry_time': timestamp,\n",
        "                        'strategy': strategy_name,\n",
        "                        'trade_id': trade_id,\n",
        "                        'instrument_type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'side': 'BUY', # Store trade side\n",
        "\n",
        "                        # --- Entry-Specific Columns (Populated from data_point at Entry) ---\n",
        "                        'Strategy_name': strategy_name,\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'name': data_point.get('name'), # Use .get() to avoid errors if column is missing\n",
        "                        'interval': data_point.get('interval'),\n",
        "                        'Position_type': 'Long', # Assuming BUY means Long position\n",
        "                        'Entry_order_type': 'Market', # Assuming market order execution on close\n",
        "                        'Entry_timestamp': timestamp,\n",
        "                        'Entry_price_trigger': None, # Not explicitly handled in this simple model\n",
        "                        'Entry_price_execution': price,\n",
        "                        'Entry_shares': quantity_to_trade, # Using quantity_to_trade as shares\n",
        "                        'Entry_cost': cost, # Gross cost before fees\n",
        "                        'Entry_signal_type': signal, # Ensure signal is captured\n",
        "                        'Entry_Trend': data_point.get('Trend'), # Capture Trend at Entry\n",
        "                        'Entry_SMA20': data_point.get('SMA20'), # Capture SMA20 at Entry\n",
        "                        'Entry_RSI': data_point.get('RSI'), # Capture RSI at Entry\n",
        "                        'Entry_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Entry\n",
        "                        'Entry_ATR': data_point.get('ATR'), # Capture ATR at Entry\n",
        "                        'Entry_ADX': data_point.get('ADX'), # Capture ADX at Entry\n",
        "                        'Entry_Volatility': data_point.get('Volatility'), # Capture Volatility at Entry\n",
        "                        'Entry_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Entry\n",
        "                        'Entry_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Entry\n",
        "                        # Corrected column names to match expected input data\n",
        "                        'Entry_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Entry\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Entry\n",
        "                        'Instrument_Type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'Currency': data_point.get('Currency'),\n",
        "                        'Slippage_Entry': entry_slippage, # Store entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Store entry commission\n",
        "\n",
        "                        # Placeholder for other entry-specific details that might be calculated by strategy (e.g., initial stop/target)\n",
        "                        'Initial_Stop_Loss_Distance (%)': data_point.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': data_point.get('Risk_Amount'),\n",
        "                        'Reward_Amount': data_point.get('Reward_Amount'),\n",
        "\n",
        "\n",
        "                        # Placeholders for exit/other info that will be filled on close\n",
        "                        # These fields are included here so the structure is consistent for retrieval on exit,\n",
        "                        # even though their values are None at the time of entry.\n",
        "                         'Max_Favorable_Excursion_MFE': None, # Will be calculated on exit\n",
        "                         'Max_Adverse_Excursion_MAE': None, # Will be calculated on exit\n",
        "                        'Current_trailing_stop': None, # Need logic for trailing stops\n",
        "                        'Trailing_stop_method': None,\n",
        "                        'Trailing_stop_value': None,\n",
        "                        'Stop_loss_price': None,\n",
        "\n",
        "\n",
        "                        'Exit_Trend': None, 'Exit_signal_type': None, 'Exit_SMA20': None,\n",
        "                        'Exit_RSI': None, 'Exit_RSI_MA': None, 'Exit_ATR': None, 'Exit_ADX': None,\n",
        "                        'Exit_Volatility': None, 'Exit_Breakout_Detected': None,\n",
        "                        'Exit_Breakdown_Detected': None, 'Exit_Bullish_Candlestick_Name': None,\n",
        "                        'Exit_Bearish_Candlestick_Name': None, 'Exit_Bullish_Chart_Pattern_Detected': None,\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': None, 'Exit_shares': None,\n",
        "                        'Exit_cost': None, 'Exit_revenue': None, 'PnL_trade': None,\n",
        "                        'Trade_type': None, 'Profit_loss': None, 'Exit_reason': None,\n",
        "                        'Slippage': None, 'Commission_Fees': None, 'Trade_Duration': None,\n",
        "                        'Exit_Order_Type': None\n",
        "                    }\n",
        "\n",
        "                    # --- Add debug logging for Entry columns here ---\n",
        "                    logger.debug(f\"DEBUG Entry Data Point for {instrument_key} at {timestamp}:\")\n",
        "                    debug_cols_to_check = [\n",
        "                        'Trend', 'SMA20', 'RSI', 'RSI_MA', 'ATR', 'ADX', 'Volatility',\n",
        "                        'Breakout_Detected', 'Breakdown_Detected',\n",
        "                        # Corrected debug column names to match expected input data\n",
        "                        'Bullish_Candlestick_Detected', 'Bearish_Candlestick_Detected',\n",
        "                        'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "                        'Currency', 'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "                        'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE', 'Current_trailing_stop',\n",
        "                        'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price', 'Exit_Trend',\n",
        "                        'Exit_signal_type', 'Exit_SMA20', 'Exit_RSI', 'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX',\n",
        "                        'Exit_Volatility', 'Exit_Breakout_Detected', 'Exit_Breakdown_Detected',\n",
        "                        'Exit_Bullish_Candlestick_Name', 'Exit_Bearish_Candlestick_Name',\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected', 'Exit_Bearish_Chart_Pattern_Detected',\n",
        "                        'Exit_cost'\n",
        "                    ]\n",
        "                    for col in debug_cols_to_check:\n",
        "                         logger.debug(f\"  {col}: {data_point.get(col, 'Column Not Found or None')}\")\n",
        "                    # --- End Debug Logging ---\n",
        "\n",
        "\n",
        "                    logger.info(f\"Executed BUY trade {trade_id} for {instrument_key} at {timestamp} @ {price} (Qty: {quantity_to_trade}). Costs: Slippage={entry_slippage:.4f}, Commission={entry_commission:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'BUY', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'slippage': entry_slippage, 'commission': entry_commission})\n",
        "                else:\n",
        "                    logger.warning(f\"Insufficient capital ({self.current_capital:.2f}) to BUY {instrument_key} at {price} (Cost: {cost:.2f}). Skipping trade {trade_id}.\")\n",
        "                    self.debug_log.append({'type': 'SKIP_BUY_CAPITAL', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Insufficient Capital'})\n",
        "\n",
        "            else:\n",
        "                # Already in a position, maybe add to it or skip depending on strategy rules\n",
        "                logger.debug(f\"Skipping BUY signal for {instrument_key} at {timestamp}. Already in a position.\")\n",
        "                self.debug_log.append({'type': 'SKIP_BUY_POSITION', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Already in Position'})\n",
        "\n",
        "\n",
        "        elif signal == 'SELL':\n",
        "            # For backtesting, a 'SELL' signal usually means closing a long position or opening a short position\n",
        "            # Let's assume 'SELL' means closing a long position if one exists for simplicity in this example.\n",
        "            # For a shorting strategy, you'd need different logic.\n",
        "            if instrument_key in self.positions and self.positions[instrument_key]['side'] == 'BUY':\n",
        "                # Use the dedicated close method\n",
        "                self.close_position_on_trigger(instrument_key, timestamp, price, 'Signal_SELL', data_point)\n",
        "\n",
        "            else:\n",
        "                # No matching long position to close, or maybe a shorting signal\n",
        "                # For this simple backtester, we'll just log and skip if no long position\n",
        "                logger.debug(f\"Skipping SELL signal for {instrument_key} at {timestamp}. No matching long position to close.\")\n",
        "                self.debug_log.append({'type': 'SKIP_SELL_NO_LONG', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'strategy': strategy_name, 'reason': 'No Long Position'})\n",
        "\n",
        "    def close_position_on_trigger(self, instrument_key: str, timestamp: datetime, closing_price: float, reason: str, exit_data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Closes an open position for a specific instrument due to a trigger (SL, TP, etc.).\n",
        "\n",
        "        Args:\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the closure (bar close time).\n",
        "            closing_price: The price at which the position is closed.\n",
        "            reason: The reason for closing ('Stop Loss', 'Take Profit', 'Signal_SELL', 'Forced_Close').\n",
        "            exit_data_point: The pandas Series representing the data row for this bar at exit.\n",
        "        \"\"\"\n",
        "        if instrument_key not in self.positions:\n",
        "            logger.warning(f\"Attempted to close non-existent position for {instrument_key} at {timestamp} (Reason: {reason}).\")\n",
        "            return\n",
        "\n",
        "        position = self.positions[instrument_key]\n",
        "\n",
        "        quantity_to_sell = position['quantity']\n",
        "        entry_price = position['entry_price']\n",
        "        entry_time = position['entry_time']\n",
        "        strategy_opened = position['strategy']\n",
        "        open_trade_id = position['trade_id']\n",
        "        side = position['side']\n",
        "\n",
        "        # Ensure side is 'BUY' for long position closure logic\n",
        "        if side != 'BUY':\n",
        "             logger.warning(f\"Attempted to close non-long position for {instrument_key} at {timestamp} (Side: {side}). Skipping.\")\n",
        "             return\n",
        "\n",
        "        revenue = quantity_to_sell * closing_price\n",
        "        self.current_capital += revenue\n",
        "\n",
        "        # Calculate Profit/Loss (Gross PnL) - For long positions\n",
        "        gross_pnl = (closing_price - entry_price) * quantity_to_sell\n",
        "\n",
        "        # Calculate exit costs (slippage and commission on exit)\n",
        "        exit_slippage = revenue * self.slippage_pct\n",
        "        exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "        self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "        # Calculate Net PnL\n",
        "        total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "        total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "        pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "        # Calculate Trade Duration\n",
        "        trade_duration = (timestamp - entry_time).total_seconds() if pd.notnull(timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "        # Generate a unique trade ID for the closing trade\n",
        "        close_trade_id = self.generate_trade_id(timestamp)\n",
        "\n",
        "        # Record completed trade - Populate all desired columns\n",
        "        trade_record = {\n",
        "            'open_trade_id': open_trade_id,\n",
        "            'close_trade_id': close_trade_id,\n",
        "            'instrument_key': instrument_key,\n",
        "            'instrument_type': position.get('instrument_type'),\n",
        "            'side': side,\n",
        "            'quantity': quantity_to_sell,\n",
        "            'entry_price': entry_price,\n",
        "            'entry_time': entry_time,\n",
        "            'exit_price': closing_price,\n",
        "            'exit_time': timestamp,\n",
        "            'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "            'strategy_opened': strategy_opened,\n",
        "            'strategy_closed': 'Backtester_Trigger' if reason not in ['Signal_SELL', 'Forced_Close'] else reason, # Indicate trigger closure or signal close\n",
        "            'Position_type': position.get('Position_type'),\n",
        "            'Entry_order_type': position.get('Entry_order_type'),\n",
        "            'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "            'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "            'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "            'Entry_shares': position.get('Entry_shares'),\n",
        "            'Entry_cost': position.get('Entry_cost'),\n",
        "            'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "            'Entry_Trend': position.get('Entry_Trend'),\n",
        "            'Entry_SMA20': position.get('Entry_SMA20'),\n",
        "            'Entry_RSI': position.get('Entry_RSI'),\n",
        "            'Entry_RSI_MA': position.get('Entry_RSI_MA'),\n",
        "            'Entry_ATR': position.get('Entry_ATR'),\n",
        "            'Entry_ADX': position.get('Entry_ADX'),\n",
        "            'Entry_Volatility': position.get('Entry_Volatility'),\n",
        "            'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'),\n",
        "            'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'),\n",
        "            'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'),\n",
        "            'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'),\n",
        "            'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'),\n",
        "            'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'),\n",
        "            'Instrument_Type': position.get('Instrument_Type'),\n",
        "            'Currency': position.get('Currency'),\n",
        "            'Slippage_Entry': position.get('Slippage_Entry'),\n",
        "            'Commission_Fees_Entry': position.get('Commission_Fees_Entry'),\n",
        "            'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "            'Risk_Amount': position.get('Risk_Amount'),\n",
        "            'Reward_Amount': position.get('Reward_Amount'),\n",
        "            'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "            'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "            # --- Exit-Specific Columns (Populated from exit_data_point) ---\n",
        "            'Exit_Trend': exit_data_point.get('Trend'),\n",
        "            'Exit_signal_type': reason, # The reason is the \"signal\" for exit\n",
        "            'Exit_SMA20': exit_data_point.get('SMA20'),\n",
        "            'Exit_RSI': exit_data_point.get('RSI'),\n",
        "            'Exit_RSI_MA': exit_data_point.get('RSI_MA'),\n",
        "            'Exit_ATR': exit_data_point.get('ATR'),\n",
        "            'Exit_ADX': exit_data_point.get('ADX'),\n",
        "            'Exit_Volatility': exit_data_point.get('Volatility'),\n",
        "            'Exit_Breakout_Detected': exit_data_point.get('Breakout_Detected'),\n",
        "            'Exit_Breakdown_Detected': exit_data_point.get('Breakdown_Detected'),\n",
        "            'Exit_Bullish_Candlestick_Name': exit_data_point.get('Bullish_Candlestick_Detected'),\n",
        "            'Exit_Bearish_Candlestick_Name': exit_data_point.get('Bearish_Candlestick_Detected'),\n",
        "            'Exit_Bullish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bullish_Chart_Pattern_Name'),\n",
        "            'Exit_Bearish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bearish_Chart_Pattern_Name'),\n",
        "            'Exit_shares': quantity_to_sell,\n",
        "            'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "            'Exit_revenue': revenue,\n",
        "            'PnL_trade': pnl_trade,\n",
        "            'Trade_type': f'Long Close ({reason})', # Indicate the closure type\n",
        "            'Profit_loss': pnl_trade,\n",
        "            'Exit_reason': reason,\n",
        "            'Exit_Order_Type': 'Market' if reason != 'Forced_Close_Error: No_Last_Price' else None, # Assume market order unless error\n",
        "\n",
        "            # Placeholder for other exit-specific details\n",
        "            'Current_trailing_stop': exit_data_point.get('Current_trailing_stop'),\n",
        "            'Trailing_stop_method': exit_data_point.get('Trailing_stop_method'),\n",
        "            'Trailing_stop_value': exit_data_point.get('Trailing_stop_value'),\n",
        "            'Stop_loss_price': exit_data_point.get('Stop_loss_price'),\n",
        "\n",
        "            'Slippage': total_slippage,\n",
        "            'Commission_Fees': total_commission,\n",
        "            'Trade_Duration': trade_duration,\n",
        "        }\n",
        "        self.completed_trades.append(trade_record)\n",
        "\n",
        "        # Remove position\n",
        "        del self.positions[instrument_key]\n",
        "\n",
        "        logger.info(f\"Closed position {open_trade_id} for {instrument_key} at {timestamp} @ {closing_price} (Reason: {reason}). Net PnL: {pnl_trade:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "        self.debug_log.append({'type': 'CLOSE_TRIGGER', 'open_trade_id': open_trade_id, 'close_trade_id': close_trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': closing_price, 'quantity': quantity_to_sell, 'net_pnl': pnl_trade, 'reason': reason})\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the backtesting simulation bar by bar through the data.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting backtest simulation...\")\n",
        "\n",
        "        # Group data by timestamp first, then iterate through timestamps\n",
        "        grouped_by_time = self.data.groupby('timestamp')\n",
        "\n",
        "        for timestamp, time_slice_df in grouped_by_time:\n",
        "            logger.debug(f\"Processing timestamp: {timestamp}\")\n",
        "\n",
        "            # --- Check for Stop Loss and Take Profit triggers BEFORE signal generation ---\n",
        "            # Iterate over a copy of the positions dictionary\n",
        "            positions_to_check = list(self.positions.keys())\n",
        "            for instrument_key in positions_to_check:\n",
        "                # Ensure the position still exists in case it was closed by another trigger\n",
        "                # for a different instrument in the same time slice (unlikely with current structure, but safe)\n",
        "                if instrument_key in self.positions:\n",
        "                    position = self.positions[instrument_key]\n",
        "                    entry_price = position.get('entry_price')\n",
        "                    stop_loss_price = position.get('Stop_loss_price') # Get SL from position details\n",
        "                    reward_amount = position.get('Reward_Amount') # Get Reward from position details\n",
        "                    position_side = position.get('side') # Get side from position details\n",
        "\n",
        "                    # Find the current price for this instrument in the current time slice\n",
        "                    current_bar_data = time_slice_df[time_slice_df['instrument_key'] == instrument_key]\n",
        "\n",
        "                    if current_bar_data.empty:\n",
        "                        logger.warning(f\"No data found for instrument {instrument_key} at timestamp {timestamp}. Cannot check triggers.\")\n",
        "                        continue # Skip trigger check for this instrument at this timestamp\n",
        "\n",
        "                    # Assuming we check triggers against the close price of the current bar\n",
        "                    # You might want to check against low for SL and high for TP for more realism\n",
        "                    current_price = current_bar_data['close'].iloc[0] # Get the close price (assuming one row per instrument per timestamp)\n",
        "\n",
        "                    # Also get the full data point for passing to close method\n",
        "                    current_data_point = current_bar_data.iloc[0]\n",
        "\n",
        "\n",
        "                    if pd.isna(current_price):\n",
        "                        logger.debug(f\"Invalid current price for {instrument_key} at {timestamp}. Cannot check triggers.\")\n",
        "                        continue # Cannot check triggers with invalid price\n",
        "\n",
        "                    # Check Stop Loss for Long Positions\n",
        "                    if position_side == 'BUY' and pd.notna(stop_loss_price) and current_price <= stop_loss_price:\n",
        "                        logger.info(f\"Stop Loss triggered for {instrument_key} at {timestamp} @ {current_price} (SL: {stop_loss_price}).\")\n",
        "                        self.close_position_on_trigger(instrument_key, timestamp, current_price, 'Stop Loss', current_data_point)\n",
        "                        # Position is removed inside close_position_on_trigger, so no need to re-check or process signals for it\n",
        "\n",
        "                    # Check Take Profit for Long Positions\n",
        "                    # Calculate TP price: Entry Price + Reward Amount (assuming Reward Amount is an absolute value)\n",
        "                    # If Reward_Amount is a percentage, calculate accordingly. Assuming absolute for now.\n",
        "                    take_profit_price = None\n",
        "                    if pd.notna(entry_price) and pd.notna(reward_amount):\n",
        "                        take_profit_price = entry_price + reward_amount\n",
        "\n",
        "\n",
        "                    if position_side == 'BUY' and pd.notna(take_profit_price) and current_price >= take_profit_price:\n",
        "                        logger.info(f\"Take Profit triggered for {instrument_key} at {timestamp} @ {current_price} (TP: {take_profit_price}).\")\n",
        "                        self.close_position_on_trigger(instrument_key, timestamp, current_price, 'Take Profit', current_data_point)\n",
        "                        # Position is removed inside close_position_on_trigger\n",
        "\n",
        "\n",
        "            # --- Process data for all instruments available at this timestamp for signals ---\n",
        "            # Filter out instruments for which positions were just closed by triggers\n",
        "            instruments_for_signal = time_slice_df[~time_slice_df['instrument_key'].isin(self.positions.keys())].copy()\n",
        "            # Add back instruments for which positions are still open (though they won't generate new signals of the same type usually)\n",
        "            # This might not be strictly necessary if your strategy logic correctly handles existing positions,\n",
        "            # but ensures all instrument data points are iterated through for potential trailing stop updates, MFE/MAE calculation, etc.\n",
        "            instruments_for_signal = pd.concat([instruments_for_signal, time_slice_df[time_slice_df['instrument_key'].isin(self.positions.keys())].copy()])\n",
        "            instruments_for_signal = instruments_for_signal.drop_duplicates(subset=['instrument_key']).reset_index(drop=True) # Remove duplicates if any\n",
        "\n",
        "            for index, data_point in instruments_for_signal.iterrows():\n",
        "                 instrument_key = data_point['instrument_key']\n",
        "                 current_price = data_point['close'] # Assume close price for execution\n",
        "\n",
        "                 # Debug capture (already done above, can be kept or moved)\n",
        "                 # self._debug_timestamps.append(timestamp)\n",
        "                 # self._debug_close_values.append(current_price)\n",
        "                 # self._debug_validity.append(pd.notna(current_price))\n",
        "\n",
        "\n",
        "                 # Ensure current_price is valid for trading (already checked above, but good redundancy)\n",
        "                 if pd.isna(current_price):\n",
        "                     logger.debug(f\"Skipping signal generation for {instrument_key} at {timestamp} due to invalid close price ({current_price}).\")\n",
        "                     self.debug_log.append({'type': 'SKIP_SIGNAL_PRICE_NAN', 'instrument': instrument_key, 'time': timestamp, 'reason': 'Invalid Price'})\n",
        "                     continue # Skip this data point if price is invalid\n",
        "\n",
        "\n",
        "                 # Check for signals from all active strategies for this data point\n",
        "                 for strategy_name, strategy_instance in self.active_strategies_instances.items():\n",
        "                     try:\n",
        "                         # Pass the single data_point (as a Series converted to DataFrame) to the strategy\n",
        "                         signal = strategy_instance.generate_signal(pd.DataFrame([data_point]))\n",
        "                         # Ensure signal is a string, handle potential None returns gracefully\n",
        "                         signal = str(signal).upper() if signal is not None else 'HOLD'\n",
        "\n",
        "                         if signal in ['BUY', 'SELL']:\n",
        "                             # Generate a unique trade ID for this potential trade using the bar's timestamp\n",
        "                             trade_id = self.generate_trade_id(timestamp) # Pass the historical timestamp\n",
        "                             # Pass the original data_point Series to execute_trade\n",
        "                             self.execute_trade(trade_id, instrument_key, timestamp, signal, strategy_name, current_price, data_point)\n",
        "\n",
        "                     except Exception as e:\n",
        "                         logger.error(f\"Error generating signal for {instrument_key} at {timestamp} using strategy '{strategy_name}': {e}\", exc_info=True)\n",
        "                         self.debug_log.append({'type': 'STRATEGY_ERROR', 'instrument': instrument_key, 'time': timestamp, 'strategy': strategy_name, 'error': str(e)})\n",
        "\n",
        "\n",
        "        # After iterating through all data, close any remaining open positions\n",
        "        self.close_all_positions(self.data['timestamp'].max()) # Use the timestamp of the last data point as exit time\n",
        "\n",
        "        logger.info(\"Backtest simulation completed.\")\n",
        "        logger.info(f\"Final Capital: {self.current_capital:.2f}\")\n",
        "        logger.info(f\"Number of completed trades: {len(self.completed_trades)}\")\n",
        "        logger.info(f\"Number of open positions remaining: {len(self.positions)}\")\n",
        "\n",
        "        # Return completed trades as a DataFrame for analysis\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "            # Ensure numeric columns are numeric\n",
        "            numeric_cols = [\n",
        "                'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "            ]\n",
        "            for col in numeric_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "            return completed_trades_df\n",
        "        else:\n",
        "            logger.warning(\"No completed trades recorded. Returning empty DataFrame.\")\n",
        "            return pd.DataFrame() # Return empty DataFrame if no trades\n",
        "\n",
        "\n",
        "    def close_all_positions(self, exit_timestamp: datetime):\n",
        "        \"\"\"\n",
        "        Closes all remaining open positions at the specified exit timestamp.\n",
        "        Assumes closing at the price of the last available bar for each instrument.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Closing all remaining {len(self.positions)} open positions at {exit_timestamp}...\")\n",
        "\n",
        "        # Get the last known price and data point for each instrument with an open position\n",
        "        last_data_points = self.data.groupby('instrument_key').tail(1).set_index('instrument_key')\n",
        "        last_prices = last_data_points['close'].to_dict()\n",
        "\n",
        "\n",
        "        positions_to_close = list(self.positions.keys()) # Iterate over a copy\n",
        "\n",
        "        for instrument_key in positions_to_close:\n",
        "            # Check if position still exists (wasn't closed by a trigger just before the end)\n",
        "            if instrument_key in self.positions:\n",
        "                position = self.positions[instrument_key]\n",
        "                closing_price = last_prices.get(instrument_key, np.nan) # Get last price, default to NaN if instrument not found\n",
        "\n",
        "                # Get the last data point for the instrument to capture exit conditions\n",
        "                last_data_point = last_data_points.get(instrument_key, pd.Series({})) # Use empty Series if no data found\n",
        "\n",
        "\n",
        "                if pd.notna(closing_price):\n",
        "                    # Use the dedicated close method for forced closure\n",
        "                    self.close_position_on_trigger(instrument_key, exit_timestamp, closing_price, 'Forced_Close', last_data_point)\n",
        "\n",
        "                else:\n",
        "                    logger.warning(f\"Could not find last price for {instrument_key}. Cannot close position {position['trade_id']}. Logging as unresolved.\")\n",
        "                    # Log as an unresolved position or assume zero PnL\n",
        "\n",
        "                    # Calculate Trade Duration even if closing price is NaN\n",
        "                    trade_duration = (exit_timestamp - position.get('entry_time')).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(position.get('entry_time')) else None\n",
        "\n",
        "                    # Transfer known costs\n",
        "                    entry_slippage = position.get('Slippage_Entry', 0)\n",
        "                    entry_commission = position.get('Commission_Fees_Entry', 0)\n",
        "\n",
        "                    unresolved_trade_record = {\n",
        "                        'open_trade_id': position.get('trade_id'),\n",
        "                        'close_trade_id': None, # No closing trade ID\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'),\n",
        "                        'side': position.get('side'),\n",
        "                        'quantity': position.get('quantity'),\n",
        "                        'entry_price': position.get('entry_price'),\n",
        "                        'entry_time': position.get('entry_time'),\n",
        "                        'exit_price': None, # No exit price\n",
        "                        'exit_time': exit_timestamp, # Use the requested exit timestamp\n",
        "                        'pnl': 0, # Assume zero Gross PnL if cannot close\n",
        "                        'strategy_opened': position.get('strategy'),\n",
        "                        'strategy_closed': 'Backtester_Forced_Close_Error', # Indicate error\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': entry_slippage, # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close_Error', # Indicate forced close error\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': position.get('quantity'), # Shares that were supposed to be exited\n",
        "                        'Exit_cost': 0,\n",
        "                        'Exit_revenue': 0, # Assuming zero revenue if cannot close\n",
        "                        'PnL_trade': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Profit_loss': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Exit_reason': 'Backtester_Forced_Close_Error: No_Last_Price', # Reason for exit\n",
        "                        'Exit_Order_Type': None, # Could not execute exit order\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "\n",
        "                        'Slippage': entry_slippage, # Only entry slippage is known\n",
        "                        'Commission_Fees': entry_commission, # Only entry commission is known\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(unresolved_trade_record)\n",
        "\n",
        "                    # Remove position even if it couldn't be closed properly to prevent it from being processed again\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE_ERROR', 'open_trade_id': position['trade_id'], 'instrument': instrument_key, 'time': exit_timestamp, 'reason': 'Last price not available'})\n",
        "\n",
        "\n",
        "        logger.info(\"All remaining positions closed.\")\n",
        "\n",
        "\n",
        "    def analyze_backtest_results(self):\n",
        "        \"\"\"\n",
        "        Analyzes the completed trades and provides performance metrics.\n",
        "        Returns a DataFrame summarizing the analysis.\n",
        "        \"\"\"\n",
        "        logger.info(\"Analyzing backtest results...\")\n",
        "\n",
        "        if not self.completed_trades:\n",
        "            logger.warning(\"No completed trades to analyze.\")\n",
        "            return pd.DataFrame({'Message': ['No completed trades to analyze.']})\n",
        "\n",
        "        # 1. Access the self.completed_trades list and Create a pandas DataFrame\n",
        "        trades_df = pd.DataFrame(self.completed_trades)\n",
        "\n",
        "        # 3. Ensure that relevant columns are converted to appropriate numeric types\n",
        "        numeric_cols = [\n",
        "            'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "            'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "            'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "            'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "            'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "            'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "            'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "            'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Include other potentially numeric cols\n",
        "        ]\n",
        "        for col in numeric_cols:\n",
        "            if col in trades_df.columns:\n",
        "                trades_df[col] = pd.to_numeric(trades_df[col], errors='coerce')\n",
        "\n",
        "        # Handle potential NaN values during conversion - drop rows where PnL_trade (or pnl) is NaN\n",
        "        pnl_col_for_analysis = 'PnL_trade' if 'PnL_trade' in trades_df.columns else 'pnl'\n",
        "        if pnl_col_for_analysis in trades_df.columns:\n",
        "            # Only consider trades with a valid PnL for core analysis metrics\n",
        "            trades_df_analysis = trades_df.dropna(subset=[pnl_col_for_analysis]).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "        else:\n",
        "            logger.warning(\"Neither 'PnL_trade' nor 'pnl' column found for analysis.\")\n",
        "            return pd.DataFrame({'Message': ['No PnL column found for analysis.']})\n",
        "\n",
        "\n",
        "        if trades_df_analysis.empty:\n",
        "            logger.warning(\"No valid trades after numeric conversion/dropna for analysis. Analysis stopped.\")\n",
        "            return pd.DataFrame({'Message': ['No valid trades after numeric conversion/dropna for analysis.']})\n",
        "\n",
        "\n",
        "        # 4. Update the calculation of basic performance metrics using 'PnL_trade'\n",
        "        total_trades = len(trades_df_analysis)\n",
        "        total_pnl = trades_df_analysis[pnl_col_for_analysis].sum()\n",
        "\n",
        "        winning_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] > 0]\n",
        "        losing_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] < 0]\n",
        "        breakeven_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] == 0]\n",
        "\n",
        "        num_winning = len(winning_trades)\n",
        "        num_losing = len(losing_trades)\n",
        "        num_breakeven = len(breakeven_trades)\n",
        "\n",
        "        win_rate = (num_winning / total_trades) * 100 if total_trades > 0 else 0\n",
        "        avg_win = winning_trades[pnl_col_for_analysis].mean() if num_winning > 0 else 0\n",
        "        avg_loss = losing_trades[pnl_col_for_analysis].mean() if num_losing > 0 else 0\n",
        "        expectancy = (win_rate / 100) * avg_win + ((100 - win_rate) / 100) * avg_loss if total_trades > 0 else 0\n",
        "\n",
        "        # 5. Update Max Drawdown calculation to use 'PnL_trade' and sort by exit time\n",
        "        # Calculate cumulative PnL and then cumulative capital\n",
        "        trades_df_analysis = trades_df_analysis.sort_values(by='exit_time') # Sort by exit time for cumulative calculation\n",
        "\n",
        "        trades_df_analysis['cumulative_pnl'] = trades_df_analysis[pnl_col_for_analysis].cumsum()\n",
        "\n",
        "        # Add initial capital to cumulative PnL\n",
        "        trades_df_analysis['cumulative_capital'] = self.initial_capital + trades_df_analysis['cumulative_pnl']\n",
        "\n",
        "        # Calculate peak capital up to each point\n",
        "        trades_df_analysis['peak_capital'] = trades_df_analysis['cumulative_capital'].cummax()\n",
        "\n",
        "        # Calculate drawdown at each point\n",
        "        trades_df_analysis['drawdown'] = trades_df_analysis['peak_capital'] - trades_df_analysis['cumulative_capital']\n",
        "\n",
        "        # Calculate percentage drawdown\n",
        "        # Avoid division by zero if peak_capital is 0 or None\n",
        "        trades_df_analysis['pct_drawdown'] = trades_df_analysis.apply(\n",
        "            lambda row: (row['drawdown'] / row['peak_capital']) * 100 if row['peak_capital'] > 0 and pd.notna(row['peak_capital']) else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        max_drawdown_amount = trades_df_analysis['drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "        max_drawdown_pct = trades_df_analysis['pct_drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "\n",
        "\n",
        "        # 6. Update analysis summary metric names\n",
        "        analysis_summary = {\n",
        "            'Metric': [\n",
        "                'Initial Capital',\n",
        "                'Final Capital',\n",
        "                'Total PnL (Net)', # Indicate Net PnL\n",
        "                'Total Trades',\n",
        "                'Winning Trades (Net)', # Indicate Net PnL\n",
        "                'Losing Trades (Net)', # Indicate Net PnL\n",
        "                'Breakeven Trades (Net)', # Indicate Net PnL\n",
        "                'Win Rate (%) (Net PnL)', # Indicate Net PnL\n",
        "                'Average Win (Net)', # Indicate Net PnL\n",
        "                'Average Loss (Net)', # Indicate Net PnL\n",
        "                'Expectancy per Trade (Net)', # Indicate Net PnL\n",
        "                'Max Drawdown (Amount)',\n",
        "                'Max Drawdown (%)',\n",
        "            ],\n",
        "            'Value': [\n",
        "                self.initial_capital,\n",
        "                self.current_capital,\n",
        "                round(total_pnl, 2), # Format to 2 decimal places\n",
        "                total_trades,\n",
        "                num_winning,\n",
        "                num_losing,\n",
        "                num_breakeven,\n",
        "                round(win_rate, 2), # Format to 2 decimal places\n",
        "                round(avg_win, 2),\n",
        "                round(avg_loss, 2),\n",
        "                round(expectancy, 2),\n",
        "                round(max_drawdown_amount, 2),\n",
        "                round(max_drawdown_pct, 2),\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        analysis_df = pd.DataFrame(analysis_summary)\n",
        "\n",
        "        logger.info(\"Backtest analysis completed.\")\n",
        "        # You can print the analysis_df here or return it\n",
        "        # print(\"\\n--- Backtest Analysis Summary ---\")\n",
        "        # display(analysis_df) # Use display for notebooks\n",
        "\n",
        "        # 8. Ensure the method returns the updated analysis summary DataFrame\n",
        "        return analysis_df\n",
        "\n",
        "    def get_completed_trades(self):\n",
        "        \"\"\"Returns a DataFrame of completed trades.\"\"\"\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "                    # Ensure numeric columns are numeric\n",
        "                    numeric_cols = [\n",
        "                        'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                        'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                        'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                        'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                        'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                        'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                        'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                        'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                        'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "                    ]\n",
        "                    for col in numeric_cols:\n",
        "                        if col in completed_trades_df.columns:\n",
        "                            completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "                    return completed_trades_df\n",
        "                else:\n",
        "                    return pd.DataFrame() # Return empty DataFrame if no trades"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging level set to DEBUG for test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dcdd23e"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the logic within the `run_backtest` method to iterate through open positions and check for stop-loss and take-profit triggers using the current price from the time slice DataFrame. Call the `close_position_on_trigger` method if a trigger is detected.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c17bd88b",
        "outputId": "45f40c95-4122-4807-d742-fa1a9e16d91c"
      },
      "source": [
        "# _1113_6BacktesterV6.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "import sys\n",
        "# from _012_instruments import get_instrument_type\n",
        "# --- Logging Configuration ---\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Also ensure the root logger has a handler and is set to DEBUG,\n",
        "# in case basicConfig was called elsewhere previously.\n",
        "if not logging.root.handlers:\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "else:\n",
        "    # If handlers exist, ensure at least one handler's level is DEBUG\n",
        "    # and the root logger's level is DEBUG\n",
        "    logging.root.setLevel(logging.DEBUG)\n",
        "    handler_found = False\n",
        "    for handler in logging.root.handlers:\n",
        "        if isinstance(handler, logging.StreamHandler) and handler.stream in [sys.stdout, sys.stderr]:\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler_found = True\n",
        "    # If no suitable handler is found (e.g., only file handlers), add a StreamHandler\n",
        "    if not handler_found:\n",
        "         stream_handler = logging.StreamHandler(sys.stdout)\n",
        "         stream_handler.setLevel(logging.DEBUG)\n",
        "         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "         stream_handler.setFormatter(formatter)\n",
        "         logging.root.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "print(\"Logging level set to DEBUG for test.\")\n",
        "\n",
        "\n",
        "class BacktesterV3:\n",
        "    \"\"\"\n",
        "    A simple backtesting engine for evaluating trading strategies.\n",
        "    Processes historical data bar by bar, generates signals, and simulates trades.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, instrument_keys: list, active_strategies_instances: dict, initial_capital: float):\n",
        "        \"\"\"\n",
        "        Includes the same parameters as the original __init__\n",
        "\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            data: A pandas DataFrame containing historical market data for all instruments,\n",
        "                expected to have columns like 'timestamp', 'instrument_key',\n",
        "                'open', 'high', 'low', 'close', 'volume', etc. It is also expected\n",
        "                to contain pre-calculated indicator and pattern columns used by\n",
        "                the strategies and for recording trade details.\n",
        "            instrument_keys: A list of unique instrument keys present in the data.\n",
        "            active_strategies_instances: A dictionary where keys are strategy names\n",
        "                                        (strings) and values are instantiated strategy\n",
        "                                        objects with a `generate_signal(data_point)` method.\n",
        "            initial_capital: The starting capital for the backtest simulation.\n",
        "        \"\"\"\n",
        "        if data is None or data.empty:\n",
        "            raise ValueError(\"Input data DataFrame is None or empty.\")\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n",
        "        if data.index.name is not None:\n",
        "            logger.warning(\"Input data index is not None. Consider resetting the index before passing to Backtester.\")\n",
        "\n",
        "\n",
        "        # Ensure essential columns are present and sorted\n",
        "        required_columns = ['timestamp', 'instrument_key', 'open', 'high', 'low', 'close']\n",
        "        # Define columns expected to be in the input data for recording trade details.\n",
        "        # These are typically pre-calculated indicators or pattern detection results.\n",
        "        entry_exit_data_columns_expected = [\n",
        "            'Trend', 'SMA20', 'RSI', 'RSIMA', 'ATR', 'ADX', 'Volatility',\n",
        "            'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "            'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "            'name', 'interval', 'Currency',\n",
        "            'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "            'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price'\n",
        "        ]\n",
        "\n",
        "        # The backtester expects these columns to be pre-calculated and provided in the input data.\n",
        "        # Strategies generate signals based on these columns, and their values at the time of\n",
        "        # entry and exit are recorded in the completed_trades DataFrame.\n",
        "\n",
        "\n",
        "        # Perform a relaxed check: log a warning if potential entry/exit columns from data are missing\n",
        "        missing_data_cols = [col for col in entry_exit_data_columns_expected if col not in data.columns]\n",
        "        if missing_data_cols:\n",
        "            logger.warning(f\"Input data is missing expected indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records. Ensure your data preparation includes these columns if strategies or analysis depend on them.\")\n",
        "\n",
        "\n",
        "        # Ensure mandatory required columns are present\n",
        "        missing_required = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_required:\n",
        "            raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "\n",
        "        # Ensure timestamp is datetime and sorted\n",
        "        try:\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
        "                data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True) # Convert to UTC\n",
        "            # Drop rows where timestamp conversion failed\n",
        "            data = data.dropna(subset=['timestamp'])\n",
        "            # Sort by timestamp and then instrument_key to process bars chronologically per instrument\n",
        "            self.data = data.sort_values(by=['timestamp', 'instrument_key']).reset_index(drop=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing timestamp column in data: {e}\")\n",
        "\n",
        "\n",
        "        self.instrument_keys = instrument_keys\n",
        "        self.active_strategies_instances = active_strategies_instances\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # --- Backtesting State Variables ---\n",
        "        self.current_capital = initial_capital\n",
        "        self.positions = {}  # Dictionary to track open positions {instrument_key: {...entry details...}}\n",
        "        self.completed_trades = [] # List to store completed trades\n",
        "        self.trade_id_counter = 0 # Simple counter for trade IDs\n",
        "        self.debug_log = [] # List to store debug information\n",
        "\n",
        "        # Debug lists to capture values\n",
        "        self._debug_timestamps = []\n",
        "        self._debug_close_values = []\n",
        "        self._debug_validity = []\n",
        "\n",
        "        # Simple Slippage and Commission model (can be customized)\n",
        "        self.slippage_pct = 0.001  # 0.1% slippage per trade\n",
        "        self.commission_per_trade = 0.01 # $0.01 fixed commission per trade\n",
        "\n",
        "\n",
        "        logger.info(f\"BacktesterV2 initialized with {len(self.instrument_keys)} instruments and {len(self.active_strategies_instances)} active strategies.\")\n",
        "        logger.info(f\"Initial Capital: {self.initial_capital}\")\n",
        "        logger.info(f\"Data shape for backtesting: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def generate_trade_id(self, timestamp: datetime):\n",
        "        \"\"\"Generates a unique trade ID using a provided timestamp.\"\"\"\n",
        "        # Using microseconds to increase the chance of uniqueness\n",
        "        return timestamp.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    def execute_trade(self, trade_id: str, instrument_key: str, timestamp: datetime, signal: str, strategy_name: str, price: float, data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Simulates executing a trade based on a signal.\n",
        "\n",
        "        Args:\n",
        "            trade_id: Unique identifier for the trade.\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the trade execution (bar close time).\n",
        "            signal: The trading signal ('BUY' or 'SELL').\n",
        "            strategy_name: The name of the strategy generating the signal.\n",
        "            price: The execution price (typically the close price of the bar).\n",
        "            data_point: The pandas Series representing the data row for this bar. This Series\n",
        "                        is expected to contain pre-calculated indicator and pattern data\n",
        "                        used for entry/exit conditions and recording.\n",
        "        \"\"\"\n",
        "        # Determine instrument type to handle lot size/quantity logic\n",
        "        # instrument_type = get_instrument_type(instrument_key) # Removed due to import error\n",
        "        instrument_type = 'Unknown' # Placeholder\n",
        "\n",
        "\n",
        "        # Simple fixed quantity logic (can be replaced with dynamic position sizing)\n",
        "        quantity_to_trade = 1 # Example: trade 1 unit/lot\n",
        "\n",
        "        if signal == 'BUY':\n",
        "            # Check if we already have a position in this instrument (optional, depending on strategy)\n",
        "            if instrument_key not in self.positions:\n",
        "                # Simulate buying\n",
        "                cost = quantity_to_trade * price\n",
        "                # Check if we have enough capital\n",
        "                if self.current_capital >= cost:\n",
        "                    self.current_capital -= cost\n",
        "\n",
        "                    # Calculate entry costs (slippage and commission on entry)\n",
        "                    entry_slippage = cost * self.slippage_pct\n",
        "                    entry_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (entry_slippage + entry_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Capture entry-specific details from the data_point and other variables\n",
        "                    self.positions[instrument_key] = {\n",
        "                        'quantity': quantity_to_trade,\n",
        "                        'entry_price': price, # This is the execution price for this simple model\n",
        "                        'entry_time': timestamp,\n",
        "                        'strategy': strategy_name,\n",
        "                        'trade_id': trade_id,\n",
        "                        'instrument_type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'side': 'BUY', # Store trade side\n",
        "\n",
        "                        # --- Entry-Specific Columns (Populated from data_point at Entry) ---\n",
        "                        'Strategy_name': strategy_name,\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'name': data_point.get('name'), # Use .get() to avoid errors if column is missing\n",
        "                        'interval': data_point.get('interval'),\n",
        "                        'Position_type': 'Long', # Assuming BUY means Long position\n",
        "                        'Entry_order_type': 'Market', # Assuming market order execution on close\n",
        "                        'Entry_timestamp': timestamp,\n",
        "                        'Entry_price_trigger': None, # Not explicitly handled in this simple model\n",
        "                        'Entry_price_execution': price,\n",
        "                        'Entry_shares': quantity_to_trade, # Using quantity_to_trade as shares\n",
        "                        'Entry_cost': cost, # Gross cost before fees\n",
        "                        'Entry_signal_type': signal, # Ensure signal is captured\n",
        "                        'Entry_Trend': data_point.get('Trend'), # Capture Trend at Entry\n",
        "                        'Entry_SMA20': data_point.get('SMA20'), # Capture SMA20 at Entry\n",
        "                        'Entry_RSI': data_point.get('RSI'), # Capture RSI at Entry\n",
        "                        'Entry_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Entry\n",
        "                        'Entry_ATR': data_point.get('ATR'), # Capture ATR at Entry\n",
        "                        'Entry_ADX': data_point.get('ADX'), # Capture ADX at Entry\n",
        "                        'Entry_Volatility': data_point.get('Volatility'), # Capture Volatility at Entry\n",
        "                        'Entry_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Entry\n",
        "                        'Entry_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Entry\n",
        "                        # Corrected column names to match expected input data\n",
        "                        'Entry_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Entry\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Entry\n",
        "                        'Instrument_Type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'Currency': data_point.get('Currency'),\n",
        "                        'Slippage_Entry': entry_slippage, # Store entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Store entry commission\n",
        "\n",
        "                        # Placeholder for other entry-specific details that might be calculated by strategy (e.g., initial stop/target)\n",
        "                        'Initial_Stop_Loss_Distance (%)': data_point.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': data_point.get('Risk_Amount'),\n",
        "                        'Reward_Amount': data_point.get('Reward_Amount'),\n",
        "\n",
        "\n",
        "                        # Placeholders for exit/other info that will be filled on close\n",
        "                        # These fields are included here so the structure is consistent for retrieval on exit,\n",
        "                        # even though their values are None at the time of entry.\n",
        "                         'Max_Favorable_Excursion_MFE': None, # Will be calculated on exit\n",
        "                         'Max_Adverse_Excursion_MAE': None, # Will be calculated on exit\n",
        "                        'Current_trailing_stop': None, # Need logic for trailing stops\n",
        "                        'Trailing_stop_method': None,\n",
        "                        'Trailing_stop_value': None,\n",
        "                        'Stop_loss_price': None,\n",
        "\n",
        "\n",
        "                        'Exit_Trend': None, 'Exit_signal_type': None, 'Exit_SMA20': None,\n",
        "                        'Exit_RSI': None, 'Exit_RSI_MA': None, 'Exit_ATR': None, 'Exit_ADX': None,\n",
        "                        'Exit_Volatility': None, 'Exit_Breakout_Detected': None,\n",
        "                        'Exit_Breakdown_Detected': None, 'Exit_Bullish_Candlestick_Name': None,\n",
        "                        'Exit_Bearish_Candlestick_Name': None, 'Exit_Bullish_Chart_Pattern_Detected': None,\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': None, 'Exit_shares': None,\n",
        "                        'Exit_cost': None, 'Exit_revenue': None, 'PnL_trade': None,\n",
        "                        'Trade_type': None, 'Profit_loss': None, 'Exit_reason': None,\n",
        "                        'Slippage': None, 'Commission_Fees': None, 'Trade_Duration': None,\n",
        "                        'Exit_Order_Type': None\n",
        "                    }\n",
        "\n",
        "                    # --- Add debug logging for Entry columns here ---\n",
        "                    logger.debug(f\"DEBUG Entry Data Point for {instrument_key} at {timestamp}:\")\n",
        "                    debug_cols_to_check = [\n",
        "                        'Trend', 'SMA20', 'RSI', 'RSI_MA', 'ATR', 'ADX', 'Volatility',\n",
        "                        'Breakout_Detected', 'Breakdown_Detected',\n",
        "                        # Corrected debug column names to match expected input data\n",
        "                        'Bullish_Candlestick_Detected', 'Bearish_Candlestick_Detected',\n",
        "                        'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "                        'Currency', 'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "                        'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE', 'Current_trailing_stop',\n",
        "                        'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price', 'Exit_Trend',\n",
        "                        'Exit_signal_type', 'Exit_SMA20', 'Exit_RSI', 'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX',\n",
        "                        'Exit_Volatility', 'Exit_Breakout_Detected', 'Exit_Breakdown_Detected',\n",
        "                        'Exit_Bullish_Candlestick_Name', 'Exit_Bearish_Candlestick_Name',\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected', 'Exit_Bearish_Chart_Pattern_Detected',\n",
        "                        'Exit_cost'\n",
        "                    ]\n",
        "                    for col in debug_cols_to_check:\n",
        "                         logger.debug(f\"  {col}: {data_point.get(col, 'Column Not Found or None')}\")\n",
        "                    # --- End Debug Logging ---\n",
        "\n",
        "\n",
        "                    logger.info(f\"Executed BUY trade {trade_id} for {instrument_key} at {timestamp} @ {price} (Qty: {quantity_to_trade}). Costs: Slippage={entry_slippage:.4f}, Commission={entry_commission:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'BUY', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'slippage': entry_slippage, 'commission': entry_commission})\n",
        "                else:\n",
        "                    logger.warning(f\"Insufficient capital ({self.current_capital:.2f}) to BUY {instrument_key} at {price} (Cost: {cost:.2f}). Skipping trade {trade_id}.\")\n",
        "                    self.debug_log.append({'type': 'SKIP_BUY_CAPITAL', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Insufficient Capital'})\n",
        "\n",
        "            else:\n",
        "                # Already in a position, maybe add to it or skip depending on strategy rules\n",
        "                logger.debug(f\"Skipping BUY signal for {instrument_key} at {timestamp}. Already in a position.\")\n",
        "                self.debug_log.append({'type': 'SKIP_BUY_POSITION', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Already in Position'})\n",
        "\n",
        "\n",
        "        elif signal == 'SELL':\n",
        "            # For backtesting, a 'SELL' signal usually means closing a long position or opening a short position\n",
        "            # Let's assume 'SELL' means closing a long position if one exists for simplicity in this example.\n",
        "            # For a shorting strategy, you'd need different logic.\n",
        "            if instrument_key in self.positions and self.positions[instrument_key]['side'] == 'BUY':\n",
        "                # Use the dedicated close method\n",
        "                self.close_position_on_trigger(instrument_key, timestamp, price, 'Signal_SELL', data_point)\n",
        "\n",
        "            else:\n",
        "                # No matching long position to close, or maybe a shorting signal\n",
        "                # For this simple backtester, we'll just log and skip if no long position\n",
        "                logger.debug(f\"Skipping SELL signal for {instrument_key} at {timestamp}. No matching long position to close.\")\n",
        "                self.debug_log.append({'type': 'SKIP_SELL_NO_LONG', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'strategy': strategy_name, 'reason': 'No Long Position'})\n",
        "\n",
        "\n",
        "    def close_position_on_trigger(self, instrument_key: str, timestamp: datetime, closing_price: float, reason: str, exit_data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Closes an open position for a specific instrument due to a trigger (SL, TP, etc.).\n",
        "\n",
        "        Args:\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the closure (bar close time).\n",
        "            closing_price: The price at which the position is closed.\n",
        "            reason: The reason for closing ('Stop Loss', 'Take Profit', 'Signal_SELL', 'Forced_Close').\n",
        "            exit_data_point: The pandas Series representing the data row for this bar at exit.\n",
        "        \"\"\"\n",
        "        if instrument_key not in self.positions:\n",
        "            logger.warning(f\"Attempted to close non-existent position for {instrument_key} at {timestamp} (Reason: {reason}).\")\n",
        "            return\n",
        "\n",
        "        position = self.positions[instrument_key]\n",
        "\n",
        "        quantity_to_sell = position['quantity']\n",
        "        entry_price = position['entry_price']\n",
        "        entry_time = position['entry_time']\n",
        "        strategy_opened = position['strategy']\n",
        "        open_trade_id = position['trade_id']\n",
        "        side = position['side']\n",
        "\n",
        "        # Ensure side is 'BUY' for long position closure logic\n",
        "        if side != 'BUY':\n",
        "             logger.warning(f\"Attempted to close non-long position for {instrument_key} at {timestamp} (Side: {side}). Skipping.\")\n",
        "             return\n",
        "\n",
        "        revenue = quantity_to_sell * closing_price\n",
        "        self.current_capital += revenue\n",
        "\n",
        "        # Calculate Profit/Loss (Gross PnL) - For long positions\n",
        "        gross_pnl = (closing_price - entry_price) * quantity_to_sell\n",
        "\n",
        "        # Calculate exit costs (slippage and commission on exit)\n",
        "        exit_slippage = revenue * self.slippage_pct\n",
        "        exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "        self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "        # Calculate Net PnL\n",
        "        total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "        total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "        pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "        # Calculate Trade Duration\n",
        "        trade_duration = (timestamp - entry_time).total_seconds() if pd.notnull(timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "        # Generate a unique trade ID for the closing trade\n",
        "        close_trade_id = self.generate_trade_id(timestamp)\n",
        "\n",
        "        # Record completed trade - Populate all desired columns\n",
        "        trade_record = {\n",
        "            'open_trade_id': open_trade_id,\n",
        "            'close_trade_id': close_trade_id,\n",
        "            'instrument_key': instrument_key,\n",
        "            'instrument_type': position.get('instrument_type'),\n",
        "            'side': side,\n",
        "            'quantity': quantity_to_sell,\n",
        "            'entry_price': entry_price,\n",
        "            'entry_time': entry_time,\n",
        "            'exit_price': closing_price,\n",
        "            'exit_time': timestamp,\n",
        "            'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "            'strategy_opened': strategy_opened,\n",
        "            'strategy_closed': 'Backtester_Trigger' if reason not in ['Signal_SELL', 'Forced_Close'] else reason, # Indicate trigger closure or signal close\n",
        "            'Position_type': position.get('Position_type'),\n",
        "            'Entry_order_type': position.get('Entry_order_type'),\n",
        "            'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "            'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "            'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "            'Entry_shares': position.get('Entry_shares'),\n",
        "            'Entry_cost': position.get('Entry_cost'),\n",
        "            'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "            'Entry_Trend': position.get('Entry_Trend'),\n",
        "            'Entry_SMA20': position.get('Entry_SMA20'),\n",
        "            'Entry_RSI': position.get('Entry_RSI'),\n",
        "            'Entry_RSI_MA': position.get('Entry_RSI_MA'),\n",
        "            'Entry_ATR': position.get('Entry_ATR'),\n",
        "            'Entry_ADX': position.get('Entry_ADX'),\n",
        "            'Entry_Volatility': position.get('Entry_Volatility'),\n",
        "            'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'),\n",
        "            'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'),\n",
        "            'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'),\n",
        "            'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'),\n",
        "            'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'),\n",
        "            'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'),\n",
        "            'Instrument_Type': position.get('Instrument_Type'),\n",
        "            'Currency': position.get('Currency'),\n",
        "            'Slippage_Entry': position.get('Slippage_Entry'),\n",
        "            'Commission_Fees_Entry': position.get('Commission_Fees_Entry'),\n",
        "            'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "            'Risk_Amount': position.get('Risk_Amount'),\n",
        "            'Reward_Amount': position.get('Reward_Amount'),\n",
        "            'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "            'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "            # --- Exit-Specific Columns (Populated from exit_data_point) ---\n",
        "            'Exit_Trend': exit_data_point.get('Trend'),\n",
        "            'Exit_signal_type': reason, # The reason is the \"signal\" for exit\n",
        "            'Exit_SMA20': exit_data_point.get('SMA20'),\n",
        "            'Exit_RSI': exit_data_point.get('RSI'),\n",
        "            'Exit_RSI_MA': exit_data_point.get('RSI_MA'),\n",
        "            'Exit_ATR': exit_data_point.get('ATR'),\n",
        "            'Exit_ADX': exit_data_point.get('ADX'),\n",
        "            'Exit_Volatility': exit_data_point.get('Volatility'),\n",
        "            'Exit_Breakout_Detected': exit_data_point.get('Breakout_Detected'),\n",
        "            'Exit_Breakdown_Detected': exit_data_point.get('Breakdown_Detected'),\n",
        "            'Exit_Bullish_Candlestick_Name': exit_data_point.get('Bullish_Candlestick_Detected'),\n",
        "            'Exit_Bearish_Candlestick_Name': exit_data_point.get('Bearish_Candlestick_Detected'),\n",
        "            'Exit_Bullish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bullish_Chart_Pattern_Name'),\n",
        "            'Exit_Bearish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bearish_Chart_Pattern_Name'),\n",
        "            'Exit_shares': quantity_to_sell,\n",
        "            'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "            'Exit_revenue': revenue,\n",
        "            'PnL_trade': pnl_trade,\n",
        "            'Trade_type': f'Long Close ({reason})', # Indicate the closure type\n",
        "            'Profit_loss': pnl_trade,\n",
        "            'Exit_reason': reason,\n",
        "            'Exit_Order_Type': 'Market' if reason != 'Forced_Close_Error: No_Last_Price' else None, # Assume market order unless error\n",
        "\n",
        "            # Placeholder for other exit-specific details\n",
        "            'Current_trailing_stop': exit_data_point.get('Current_trailing_stop'),\n",
        "            'Trailing_stop_method': exit_data_point.get('Trailing_stop_method'),\n",
        "            'Trailing_stop_value': exit_data_point.get('Trailing_stop_value'),\n",
        "            'Stop_loss_price': exit_data_point.get('Stop_loss_price'),\n",
        "\n",
        "            'Slippage': total_slippage,\n",
        "            'Commission_Fees': total_commission,\n",
        "            'Trade_Duration': trade_duration,\n",
        "        }\n",
        "        self.completed_trades.append(trade_record)\n",
        "\n",
        "        # Remove position\n",
        "        del self.positions[instrument_key]\n",
        "\n",
        "        logger.info(f\"Closed position {open_trade_id} for {instrument_key} at {timestamp} @ {closing_price} (Reason: {reason}). Net PnL: {pnl_trade:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "        self.debug_log.append({'type': 'CLOSE_TRIGGER', 'open_trade_id': open_trade_id, 'close_trade_id': close_trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': closing_price, 'quantity': quantity_to_sell, 'net_pnl': pnl_trade, 'reason': reason})\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the backtesting simulation bar by bar through the data.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting backtest simulation...\")\n",
        "\n",
        "        # Group data by timestamp first, then iterate through timestamps\n",
        "        grouped_by_time = self.data.groupby('timestamp')\n",
        "\n",
        "        for timestamp, time_slice_df in grouped_by_time:\n",
        "            logger.debug(f\"Processing timestamp: {timestamp}\")\n",
        "\n",
        "            # --- Check for Stop Loss and Take Profit triggers BEFORE signal generation ---\n",
        "            # Iterate over a copy of the positions dictionary\n",
        "            positions_to_check = list(self.positions.keys())\n",
        "            for instrument_key in positions_to_check:\n",
        "                # Ensure the position still exists in case it was closed by another trigger\n",
        "                # for a different instrument in the same time slice (unlikely with current structure, but safe)\n",
        "                if instrument_key in self.positions:\n",
        "                    position = self.positions[instrument_key]\n",
        "                    entry_price = position.get('entry_price')\n",
        "                    stop_loss_price = position.get('Stop_loss_price') # Get SL from position details\n",
        "                    reward_amount = position.get('Reward_Amount') # Get Reward from position details\n",
        "                    position_side = position.get('side') # Get side from position details\n",
        "\n",
        "                    # Find the current price for this instrument in the current time slice\n",
        "                    current_bar_data = time_slice_df[time_slice_df['instrument_key'] == instrument_key]\n",
        "\n",
        "                    if current_bar_data.empty:\n",
        "                        logger.warning(f\"No data found for instrument {instrument_key} at timestamp {timestamp}. Cannot check triggers.\")\n",
        "                        continue # Skip trigger check for this instrument at this timestamp\n",
        "\n",
        "                    # Assuming we check triggers against the close price of the current bar\n",
        "                    # You might want to check against low for SL and high for TP for more realism\n",
        "                    current_price = current_bar_data['close'].iloc[0] # Get the close price (assuming one row per instrument per timestamp)\n",
        "\n",
        "                    # Also get the full data point for passing to close method\n",
        "                    current_data_point = current_bar_data.iloc[0]\n",
        "\n",
        "\n",
        "                    if pd.isna(current_price):\n",
        "                        logger.debug(f\"Invalid current price for {instrument_key} at {timestamp}. Cannot check triggers.\")\n",
        "                        continue # Cannot check triggers with invalid price\n",
        "\n",
        "                    # Check Stop Loss for Long Positions\n",
        "                    if position_side == 'BUY' and pd.notna(stop_loss_price) and current_price <= stop_loss_price:\n",
        "                        logger.info(f\"Stop Loss triggered for {instrument_key} at {timestamp} @ {current_price} (SL: {stop_loss_price}).\")\n",
        "                        self.close_position_on_trigger(instrument_key, timestamp, current_price, 'Stop Loss', current_data_point)\n",
        "                        # Position is removed inside close_position_on_trigger, so no need to re-check or process signals for it\n",
        "                        continue # Move to the next position check if this one was closed\n",
        "\n",
        "                    # Check Take Profit for Long Positions\n",
        "                    # Calculate TP price: Entry Price + Reward Amount (assuming Reward Amount is an absolute value)\n",
        "                    # If Reward_Amount is a percentage, calculate accordingly. Assuming absolute for now.\n",
        "                    take_profit_price = None\n",
        "                    if pd.notna(entry_price) and pd.notna(reward_amount):\n",
        "                        take_profit_price = entry_price + reward_amount\n",
        "\n",
        "\n",
        "                    if position_side == 'BUY' and pd.notna(take_profit_price) and current_price >= take_profit_price:\n",
        "                        logger.info(f\"Take Profit triggered for {instrument_key} at {timestamp} @ {current_price} (TP: {take_profit_price}).\")\n",
        "                        self.close_position_on_trigger(instrument_key, timestamp, current_price, 'Take Profit', current_data_point)\n",
        "                        # Position is removed inside close_position_on_trigger\n",
        "                        continue # Move to the next position check if this one was closed\n",
        "\n",
        "\n",
        "            # --- Process data for all instruments available at this timestamp for signals ---\n",
        "            # Filter out instruments for which positions were just closed by triggers\n",
        "            instruments_for_signal = time_slice_df[~time_slice_df['instrument_key'].isin(self.positions.keys())].copy()\n",
        "            # Add back instruments for which positions are still open (though they won't generate new signals of the same type usually)\n",
        "            # This might not be strictly necessary if your strategy logic correctly handles existing positions,\n",
        "            # but ensures all instrument data points are iterated through for potential trailing stop updates, MFE/MAE calculation, etc.\n",
        "            instruments_for_signal = pd.concat([instruments_for_signal, time_slice_df[time_slice_df['instrument_key'].isin(self.positions.keys())].copy()])\n",
        "            instruments_for_signal = instruments_for_signal.drop_duplicates(subset=['instrument_key']).reset_index(drop=True) # Remove duplicates if any\n",
        "\n",
        "            for index, data_point in instruments_for_signal.iterrows():\n",
        "                 instrument_key = data_point['instrument_key']\n",
        "                 current_price = data_point['close'] # Assume close price for execution\n",
        "\n",
        "                 # Debug capture (already done above, can be kept or moved)\n",
        "                 # self._debug_timestamps.append(timestamp)\n",
        "                 # self._debug_close_values.append(current_price)\n",
        "                 # self._debug_validity.append(pd.notna(current_price))\n",
        "\n",
        "\n",
        "                 # Ensure current_price is valid for trading (already checked above, but good redundancy)\n",
        "                 if pd.isna(current_price):\n",
        "                     logger.debug(f\"Skipping signal generation for {instrument_key} at {timestamp} due to invalid close price ({current_price}).\")\n",
        "                     self.debug_log.append({'type': 'SKIP_SIGNAL_PRICE_NAN', 'instrument': instrument_key, 'time': timestamp, 'reason': 'Invalid Price'})\n",
        "                     continue # Skip this data point if price is invalid\n",
        "\n",
        "\n",
        "                 # Check for signals from all active strategies for this data point\n",
        "                 for strategy_name, strategy_instance in self.active_strategies_instances.items():\n",
        "                     try:\n",
        "                         # Pass the single data_point (as a Series converted to DataFrame) to the strategy\n",
        "                         signal = strategy_instance.generate_signal(pd.DataFrame([data_point]))\n",
        "                         # Ensure signal is a string, handle potential None returns gracefully\n",
        "                         signal = str(signal).upper() if signal is not None else 'HOLD'\n",
        "\n",
        "                         if signal in ['BUY', 'SELL']:\n",
        "                             # Generate a unique trade ID for this potential trade using the bar's timestamp\n",
        "                             trade_id = self.generate_trade_id(timestamp) # Pass the historical timestamp\n",
        "                             # Pass the original data_point Series to execute_trade\n",
        "                             self.execute_trade(trade_id, instrument_key, timestamp, signal, strategy_name, current_price, data_point)\n",
        "\n",
        "                     except Exception as e:\n",
        "                         logger.error(f\"Error generating signal for {instrument_key} at {timestamp} using strategy '{strategy_name}': {e}\", exc_info=True)\n",
        "                         self.debug_log.append({'type': 'STRATEGY_ERROR', 'instrument': instrument_key, 'time': timestamp, 'strategy': strategy_name, 'error': str(e)})\n",
        "\n",
        "\n",
        "        # After iterating through all data, close any remaining open positions\n",
        "        self.close_all_positions(self.data['timestamp'].max()) # Use the timestamp of the last data point as exit time\n",
        "\n",
        "        logger.info(\"Backtest simulation completed.\")\n",
        "        logger.info(f\"Final Capital: {self.current_capital:.2f}\")\n",
        "        logger.info(f\"Number of completed trades: {len(self.completed_trades)}\")\n",
        "        logger.info(f\"Number of open positions remaining: {len(self.positions)}\")\n",
        "\n",
        "        # Return completed trades as a DataFrame for analysis\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "            # Ensure numeric columns are numeric\n",
        "            numeric_cols = [\n",
        "                'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "            ]\n",
        "            for col in numeric_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "            return completed_trades_df\n",
        "        else:\n",
        "            logger.warning(\"No completed trades recorded. Returning empty DataFrame.\")\n",
        "            return pd.DataFrame() # Return empty DataFrame if no trades\n",
        "\n",
        "\n",
        "    def close_all_positions(self, exit_timestamp: datetime):\n",
        "        \"\"\"\n",
        "        Closes all remaining open positions at the specified exit timestamp.\n",
        "        Assumes closing at the price of the last available bar for each instrument.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Closing all remaining {len(self.positions)} open positions at {exit_timestamp}...\")\n",
        "\n",
        "        # Get the last known price and data point for each instrument with an open position\n",
        "        last_data_points = self.data.groupby('instrument_key').tail(1).set_index('instrument_key')\n",
        "        last_prices = last_data_points['close'].to_dict()\n",
        "\n",
        "\n",
        "        positions_to_close = list(self.positions.keys()) # Iterate over a copy\n",
        "\n",
        "        for instrument_key in positions_to_close:\n",
        "            # Check if position still exists (wasn't closed by a trigger just before the end)\n",
        "            if instrument_key in self.positions:\n",
        "                position = self.positions[instrument_key]\n",
        "                closing_price = last_prices.get(instrument_key, np.nan) # Get last price, default to NaN if instrument not found\n",
        "\n",
        "                # Get the last data point for the instrument to capture exit conditions\n",
        "                last_data_point = last_data_points.get(instrument_key, pd.Series({})) # Use empty Series if no data found\n",
        "\n",
        "\n",
        "                if pd.notna(closing_price):\n",
        "                    # Use the dedicated close method for forced closure\n",
        "                    self.close_position_on_trigger(instrument_key, exit_timestamp, closing_price, 'Forced_Close', last_data_point)\n",
        "\n",
        "                else:\n",
        "                    logger.warning(f\"Could not find last price for {instrument_key}. Cannot close position {position['trade_id']}. Logging as unresolved.\")\n",
        "                    # Log as an unresolved position or assume zero PnL\n",
        "\n",
        "                    # Calculate Trade Duration even if closing price is NaN\n",
        "                    trade_duration = (exit_timestamp - position.get('entry_time')).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(position.get('entry_time')) else None\n",
        "\n",
        "                    # Transfer known costs\n",
        "                    entry_slippage = position.get('Slippage_Entry', 0)\n",
        "                    entry_commission = position.get('Commission_Fees_Entry', 0)\n",
        "\n",
        "                    unresolved_trade_record = {\n",
        "                        'open_trade_id': position.get('trade_id'),\n",
        "                        'close_trade_id': None, # No closing trade ID\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'),\n",
        "                        'side': position.get('side'),\n",
        "                        'quantity': position.get('quantity'),\n",
        "                        'entry_price': position.get('entry_price'),\n",
        "                        'entry_time': position.get('entry_time'),\n",
        "                        'exit_price': None, # No exit price\n",
        "                        'exit_time': exit_timestamp, # Use the requested exit timestamp\n",
        "                        'pnl': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'strategy_opened': position.get('strategy'),\n",
        "                        'strategy_closed': 'Backtester_Forced_Close_Error', # Indicate error\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': entry_slippage, # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close_Error', # Indicate forced close error\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': position.get('quantity'), # Shares that were supposed to be exited\n",
        "                        'Exit_cost': 0,\n",
        "                        'Exit_revenue': 0, # Assuming zero revenue if cannot close\n",
        "                        'PnL_trade': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Profit_loss': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Exit_reason': 'Backtester_Forced_Close_Error: No_Last_Price', # Reason for exit\n",
        "                        'Exit_Order_Type': None, # Could not execute exit order\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': last_data_point.get('Current_trailing_stop'), # Capture if calculated and available\n",
        "                        'Trailing_stop_method': last_data_point.get('Trailing_stop_method'), # Capture if calculated and available\n",
        "                        'Trailing_stop_value': last_data_point.get('Trailing_stop_value'), # Capture if calculated and available\n",
        "                        'Stop_loss_price': last_data_point.get('Stop_loss_price'), # Capture if calculated and available\n",
        "\n",
        "\n",
        "                        'Slippage': entry_slippage, # Only entry slippage is known\n",
        "                        'Commission_Fees': entry_commission, # Only entry commission is known\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(unresolved_trade_record)\n",
        "\n",
        "                    # Remove position even if it couldn't be closed properly to prevent it from being processed again\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE_ERROR', 'open_trade_id': position['trade_id'], 'instrument': instrument_key, 'time': exit_timestamp, 'reason': 'Last price not available'})\n",
        "\n",
        "\n",
        "        logger.info(\"All remaining positions closed.\")\n",
        "\n",
        "\n",
        "    def analyze_backtest_results(self):\n",
        "        \"\"\"\n",
        "        Analyzes the completed trades and provides performance metrics.\n",
        "        Returns a DataFrame summarizing the analysis.\n",
        "        \"\"\"\n",
        "        logger.info(\"Analyzing backtest results...\")\n",
        "\n",
        "        if not self.completed_trades:\n",
        "            logger.warning(\"No completed trades to analyze.\")\n",
        "            return pd.DataFrame({'Message': ['No completed trades to analyze.']})\n",
        "\n",
        "        # 1. Access the self.completed_trades list and Create a pandas DataFrame\n",
        "        trades_df = pd.DataFrame(self.completed_trades)\n",
        "\n",
        "        # 3. Ensure that relevant columns are converted to appropriate numeric types\n",
        "        numeric_cols = [\n",
        "            'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "            'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "            'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "            'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "            'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "            'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "            'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "            'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Include other potentially numeric cols\n",
        "        ]\n",
        "        for col in numeric_cols:\n",
        "            if col in trades_df.columns:\n",
        "                trades_df[col] = pd.to_numeric(trades_df[col], errors='coerce')\n",
        "\n",
        "        # Handle potential NaN values during conversion - drop rows where PnL_trade (or pnl) is NaN\n",
        "        pnl_col_for_analysis = 'PnL_trade' if 'PnL_trade' in trades_df.columns else 'pnl'\n",
        "        if pnl_col_for_analysis in trades_df.columns:\n",
        "            # Only consider trades with a valid PnL for core analysis metrics\n",
        "            trades_df_analysis = trades_df.dropna(subset=[pnl_col_for_analysis]).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "        else:\n",
        "            logger.warning(\"Neither 'PnL_trade' nor 'pnl' column found for analysis.\")\n",
        "            return pd.DataFrame({'Message': ['No PnL column found for analysis.']})\n",
        "\n",
        "\n",
        "        if trades_df_analysis.empty:\n",
        "            logger.warning(\"No valid trades after numeric conversion/dropna for analysis. Analysis stopped.\")\n",
        "            return pd.DataFrame({'Message': ['No valid trades after numeric conversion/dropna for analysis.']})\n",
        "\n",
        "\n",
        "        # 4. Update the calculation of basic performance metrics using 'PnL_trade'\n",
        "        total_trades = len(trades_df_analysis)\n",
        "        total_pnl = trades_df_analysis[pnl_col_for_analysis].sum()\n",
        "\n",
        "        winning_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] > 0]\n",
        "        losing_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] < 0]\n",
        "        breakeven_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] == 0]\n",
        "\n",
        "        num_winning = len(winning_trades)\n",
        "        num_losing = len(losing_trades)\n",
        "        num_breakeven = len(breakeven_trades)\n",
        "\n",
        "        win_rate = (num_winning / total_trades) * 100 if total_trades > 0 else 0\n",
        "        avg_win = winning_trades[pnl_col_for_analysis].mean() if num_winning > 0 else 0\n",
        "        avg_loss = losing_trades[pnl_col_for_analysis].mean() if num_losing > 0 else 0\n",
        "        expectancy = (win_rate / 100) * avg_win + ((100 - win_rate) / 100) * avg_loss if total_trades > 0 else 0\n",
        "\n",
        "        # 5. Update Max Drawdown calculation to use 'PnL_trade' and sort by exit time\n",
        "        # Calculate cumulative PnL and then cumulative capital\n",
        "        trades_df_analysis = trades_df_analysis.sort_values(by='exit_time') # Sort by exit time for cumulative calculation\n",
        "\n",
        "        trades_df_analysis['cumulative_pnl'] = trades_df_analysis[pnl_col_for_analysis].cumsum()\n",
        "\n",
        "        # Add initial capital to cumulative PnL\n",
        "        trades_df_analysis['cumulative_capital'] = self.initial_capital + trades_df_analysis['cumulative_pnl']\n",
        "\n",
        "        # Calculate peak capital up to each point\n",
        "        trades_df_analysis['peak_capital'] = trades_df_analysis['cumulative_capital'].cummax()\n",
        "\n",
        "        # Calculate drawdown at each point\n",
        "        trades_df_analysis['drawdown'] = trades_df_analysis['peak_capital'] - trades_df_analysis['cumulative_capital']\n",
        "\n",
        "        # Calculate percentage drawdown\n",
        "        # Avoid division by zero if peak_capital is 0 or None\n",
        "        trades_df_analysis['pct_drawdown'] = trades_df_analysis.apply(\n",
        "            lambda row: (row['drawdown'] / row['peak_capital']) * 100 if row['peak_capital'] > 0 and pd.notna(row['peak_capital']) else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        max_drawdown_amount = trades_df_analysis['drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "        max_drawdown_pct = trades_df_analysis['pct_drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "\n",
        "\n",
        "        # 6. Update analysis summary metric names\n",
        "        analysis_summary = {\n",
        "            'Metric': [\n",
        "                'Initial Capital',\n",
        "                'Final Capital',\n",
        "                'Total PnL (Net)', # Indicate Net PnL\n",
        "                'Total Trades',\n",
        "                'Winning Trades (Net)', # Indicate Net PnL\n",
        "                'Losing Trades (Net)', # Indicate Net PnL\n",
        "                'Breakeven Trades (Net)', # Indicate Net PnL\n",
        "                'Win Rate (%) (Net PnL)', # Indicate Net PnL\n",
        "                'Average Win (Net)', # Indicate Net PnL\n",
        "                'Average Loss (Net)', # Indicate Net PnL\n",
        "                'Expectancy per Trade (Net)', # Indicate Net PnL\n",
        "                'Max Drawdown (Amount)',\n",
        "                'Max Drawdown (%)',\n",
        "            ],\n",
        "            'Value': [\n",
        "                self.initial_capital,\n",
        "                self.current_capital,\n",
        "                round(total_pnl, 2), # Format to 2 decimal places\n",
        "                total_trades,\n",
        "                num_winning,\n",
        "                num_losing,\n",
        "                num_breakeven,\n",
        "                round(win_rate, 2), # Format to 2 decimal places\n",
        "                round(avg_win, 2),\n",
        "                round(avg_loss, 2),\n",
        "                round(expectancy, 2),\n",
        "                round(max_drawdown_amount, 2),\n",
        "                round(max_drawdown_pct, 2),\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        analysis_df = pd.DataFrame(analysis_summary)\n",
        "\n",
        "        logger.info(\"Backtest analysis completed.\")\n",
        "        # You can print the analysis_df here or return it\n",
        "        # print(\"\\n--- Backtest Analysis Summary ---\")\n",
        "        # display(analysis_df) # Use display for notebooks\n",
        "\n",
        "        # 8. Ensure the method returns the updated analysis summary DataFrame\n",
        "        return analysis_df\n",
        "\n",
        "    def get_completed_trades(self):\n",
        "        \"\"\"Returns a DataFrame of completed trades.\"\"\"\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "                    # Ensure numeric columns are numeric\n",
        "                    numeric_cols = [\n",
        "                        'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                        'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                        'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                        'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                        'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                        'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                        'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                        'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                        'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "                    ]\n",
        "                    for col in numeric_cols:\n",
        "                        if col in completed_trades_df.columns:\n",
        "                            completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "                    return completed_trades_df\n",
        "                else:\n",
        "                    return pd.DataFrame() # Return empty DataFrame if no trades"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging level set to DEBUG for test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97f95351"
      },
      "source": [
        "## Add trailing stop execution\n",
        "\n",
        "### Subtask:\n",
        "Add a loop or check within `run_backtest` to evaluate trailing stop conditions for open positions on each bar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ef310f"
      },
      "source": [
        "**Reasoning**:\n",
        "Add the logic to check and update trailing stop conditions for open long positions within the `run_backtest` method, before the signal generation loop and after the initial SL/TP checks. This involves calculating the new trailing stop based on the current bar's high and the specified method, updating the trailing stop if it moves favorably, and closing the position if the low breaches the updated trailing stop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c98a460d",
        "outputId": "a2e5bd8a-b79b-4f4b-be01-cd71793a9ecb"
      },
      "source": [
        "# _1113_6BacktesterV6.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "import sys\n",
        "# from _012_instruments import get_instrument_type\n",
        "# --- Logging Configuration ---\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Also ensure the root logger has a handler and is set to DEBUG,\n",
        "# in case basicConfig was called elsewhere previously.\n",
        "if not logging.root.handlers:\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "else:\n",
        "    # If handlers exist, ensure at least one handler's level is DEBUG\n",
        "    # and the root logger's level is DEBUG\n",
        "    logging.root.setLevel(logging.DEBUG)\n",
        "    handler_found = False\n",
        "    for handler in logging.root.handlers:\n",
        "        if isinstance(handler, logging.StreamHandler) and handler.stream in [sys.stdout, sys.stderr]:\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler_found = True\n",
        "    # If no suitable handler is found (e.g., only file handlers), add a StreamHandler\n",
        "    if not handler_found:\n",
        "         stream_handler = logging.StreamHandler(sys.stdout)\n",
        "         stream_handler.setLevel(logging.DEBUG)\n",
        "         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "         stream_handler.setFormatter(formatter)\n",
        "         logging.root.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "print(\"Logging level set to DEBUG for test.\")\n",
        "\n",
        "\n",
        "class BacktesterV3:\n",
        "    \"\"\"\n",
        "    A simple backtesting engine for evaluating trading strategies.\n",
        "    Processes historical data bar by bar, generates signals, and simulates trades.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, instrument_keys: list, active_strategies_instances: dict, initial_capital: float):\n",
        "        \"\"\"\n",
        "        Includes the same parameters as the original __init__\n",
        "\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            data: A pandas DataFrame containing historical market data for all instruments,\n",
        "                expected to have columns like 'timestamp', 'instrument_key',\n",
        "                'open', 'high', 'low', 'close', 'volume', etc. It is also expected\n",
        "                to contain pre-calculated indicator and pattern columns used by\n",
        "                the strategies and for recording trade details.\n",
        "            instrument_keys: A list of unique instrument keys present in the data.\n",
        "            active_strategies_instances: A dictionary where keys are strategy names\n",
        "                                        (strings) and values are instantiated strategy\n",
        "                                        objects with a `generate_signal(data_point)` method.\n",
        "            initial_capital: The starting capital for the backtest simulation.\n",
        "        \"\"\"\n",
        "        if data is None or data.empty:\n",
        "            raise ValueError(\"Input data DataFrame is None or empty.\")\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n",
        "        if data.index.name is not None:\n",
        "            logger.warning(\"Input data index is not None. Consider resetting the index before passing to Backtester.\")\n",
        "\n",
        "\n",
        "        # Ensure essential columns are present and sorted\n",
        "        required_columns = ['timestamp', 'instrument_key', 'open', 'high', 'low', 'close', 'high', 'low'] # Added high, low to required\n",
        "        # Define columns expected to be in the input data for recording trade details.\n",
        "        # These are typically pre-calculated indicators or pattern detection results.\n",
        "        entry_exit_data_columns_expected = [\n",
        "            'Trend', 'SMA20', 'RSI', 'RSIMA', 'ATR', 'ADX', 'Volatility',\n",
        "            'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "            'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "            'name', 'interval', 'Currency',\n",
        "            'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "            'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price' # Added Trailing_stop_value\n",
        "        ]\n",
        "\n",
        "        # The backtester expects these columns to be pre-calculated and provided in the input data.\n",
        "        # Strategies generate signals based on these columns, and their values at the time of\n",
        "        # entry and exit are recorded in the completed_trades DataFrame.\n",
        "\n",
        "\n",
        "        # Perform a relaxed check: log a warning if potential entry/exit columns from data are missing\n",
        "        missing_data_cols = [col for col in entry_exit_data_columns_expected if col not in data.columns]\n",
        "        if missing_data_cols:\n",
        "            logger.warning(f\"Input data is missing expected indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records. Ensure your data preparation includes these columns if strategies or analysis depend on them.\")\n",
        "\n",
        "\n",
        "        # Ensure mandatory required columns are present\n",
        "        missing_required = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_required:\n",
        "            raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "\n",
        "        # Ensure timestamp is datetime and sorted\n",
        "        try:\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
        "                data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True) # Convert to UTC\n",
        "            # Drop rows where timestamp conversion failed\n",
        "            data = data.dropna(subset=['timestamp'])\n",
        "            # Sort by timestamp and then instrument_key to process bars chronologically per instrument\n",
        "            self.data = data.sort_values(by=['timestamp', 'instrument_key']).reset_index(drop=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing timestamp column in data: {e}\")\n",
        "\n",
        "\n",
        "        self.instrument_keys = instrument_keys\n",
        "        self.active_strategies_instances = active_strategies_instances\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # --- Backtesting State Variables ---\n",
        "        self.current_capital = initial_capital\n",
        "        self.positions = {}  # Dictionary to track open positions {instrument_key: {...entry details...}}\n",
        "        self.completed_trades = [] # List to store completed trades\n",
        "        self.trade_id_counter = 0 # Simple counter for trade IDs\n",
        "        self.debug_log = [] # List to store debug information\n",
        "\n",
        "        # Debug lists to capture values\n",
        "        self._debug_timestamps = []\n",
        "        self._debug_close_values = []\n",
        "        self._debug_validity = []\n",
        "\n",
        "        # Simple Slippage and Commission model (can be customized)\n",
        "        self.slippage_pct = 0.001  # 0.1% slippage per trade\n",
        "        self.commission_per_trade = 0.01 # $0.01 fixed commission per trade\n",
        "\n",
        "\n",
        "        logger.info(f\"BacktesterV2 initialized with {len(self.instrument_keys)} instruments and {len(self.active_strategies_instances)} active strategies.\")\n",
        "        logger.info(f\"Initial Capital: {self.initial_capital}\")\n",
        "        logger.info(f\"Data shape for backtesting: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def generate_trade_id(self, timestamp: datetime):\n",
        "        \"\"\"Generates a unique trade ID using a provided timestamp.\"\"\"\n",
        "        # Using microseconds to increase the chance of uniqueness\n",
        "        return timestamp.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    def execute_trade(self, trade_id: str, instrument_key: str, timestamp: datetime, signal: str, strategy_name: str, price: float, data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Simulates executing a trade based on a signal.\n",
        "\n",
        "        Args:\n",
        "            trade_id: Unique identifier for the trade.\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the trade execution (bar close time).\n",
        "            signal: The trading signal ('BUY' or 'SELL').\n",
        "            strategy_name: The name of the strategy generating the signal.\n",
        "            price: The execution price (typically the close price of the bar).\n",
        "            data_point: The pandas Series representing the data row for this bar. This Series\n",
        "                        is expected to contain pre-calculated indicator and pattern data\n",
        "                        used for entry/exit conditions and recording.\n",
        "        \"\"\"\n",
        "        # Determine instrument type to handle lot size/quantity logic\n",
        "        # instrument_type = get_instrument_type(instrument_key) # Removed due to import error\n",
        "        instrument_type = 'Unknown' # Placeholder\n",
        "\n",
        "\n",
        "        # Simple fixed quantity logic (can be replaced with dynamic position sizing)\n",
        "        quantity_to_trade = 1 # Example: trade 1 unit/lot\n",
        "\n",
        "        if signal == 'BUY':\n",
        "            # Check if we already have a position in this instrument (optional, depending on strategy)\n",
        "            if instrument_key not in self.positions:\n",
        "                # Simulate buying\n",
        "                cost = quantity_to_trade * price\n",
        "                # Check if we have enough capital\n",
        "                if self.current_capital >= cost:\n",
        "                    self.current_capital -= cost\n",
        "\n",
        "                    # Calculate entry costs (slippage and commission on entry)\n",
        "                    entry_slippage = cost * self.slippage_pct\n",
        "                    entry_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (entry_slippage + entry_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Capture entry-specific details from the data_point and other variables\n",
        "                    self.positions[instrument_key] = {\n",
        "                        'quantity': quantity_to_trade,\n",
        "                        'entry_price': price, # This is the execution price for this simple model\n",
        "                        'entry_time': timestamp,\n",
        "                        'strategy': strategy_name,\n",
        "                        'trade_id': trade_id,\n",
        "                        'instrument_type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'side': 'BUY', # Store trade side\n",
        "\n",
        "                        # --- Entry-Specific Columns (Populated from data_point at Entry) ---\n",
        "                        'Strategy_name': strategy_name,\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'name': data_point.get('name'), # Use .get() to avoid errors if column is missing\n",
        "                        'interval': data_point.get('interval'),\n",
        "                        'Position_type': 'Long', # Assuming BUY means Long position\n",
        "                        'Entry_order_type': 'Market', # Assuming market order execution on close\n",
        "                        'Entry_timestamp': timestamp,\n",
        "                        'Entry_price_trigger': None, # Not explicitly handled in this simple model\n",
        "                        'Entry_price_execution': price,\n",
        "                        'Entry_shares': quantity_to_trade, # Using quantity_to_trade as shares\n",
        "                        'Entry_cost': cost, # Gross cost before fees\n",
        "                        'Entry_signal_type': signal, # Ensure signal is captured\n",
        "                        'Entry_Trend': data_point.get('Trend'), # Capture Trend at Entry\n",
        "                        'Entry_SMA20': data_point.get('SMA20'), # Capture SMA20 at Entry\n",
        "                        'Entry_RSI': data_point.get('RSI'), # Capture RSI at Entry\n",
        "                        'Entry_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Entry\n",
        "                        'Entry_ATR': data_point.get('ATR'), # Capture ATR at Entry\n",
        "                        'Entry_ADX': data_point.get('ADX'), # Capture ADX at Entry\n",
        "                        'Entry_Volatility': data_point.get('Volatility'), # Capture Volatility at Entry\n",
        "                        'Entry_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Entry\n",
        "                        'Entry_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Entry\n",
        "                        # Corrected column names to match expected input data\n",
        "                        'Entry_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Entry\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Entry\n",
        "                        'Instrument_Type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'Currency': data_point.get('Currency'),\n",
        "                        'Slippage_Entry': entry_slippage, # Store entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Store entry commission\n",
        "\n",
        "                        # Placeholder for other entry-specific details that might be calculated by strategy (e.g., initial stop/target)\n",
        "                        'Initial_Stop_Loss_Distance (%)': data_point.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': data_point.get('Risk_Amount'),\n",
        "                        'Reward_Amount': data_point.get('Reward_Amount'),\n",
        "\n",
        "\n",
        "                        # Placeholders for exit/other info that will be filled on close\n",
        "                        # These fields are included here so the structure is consistent for retrieval on exit,\n",
        "                        # even though their values are None at the time of entry.\n",
        "                         'Max_Favorable_Excursion_MFE': None, # Will be calculated on exit\n",
        "                         'Max_Adverse_Excursion_MAE': None, # Will be calculated on exit\n",
        "                        'Current_trailing_stop': None, # Need logic for trailing stops\n",
        "                        'Trailing_stop_method': data_point.get('Trailing_stop_method'), # Capture method from data point\n",
        "                        'Trailing_stop_value': data_point.get('Trailing_stop_value'), # Capture initial value from data point (if applicable)\n",
        "                        'Stop_loss_price': data_point.get('Stop_loss_price'), # Capture initial SL from data point\n",
        "\n",
        "\n",
        "                        'Exit_Trend': None, 'Exit_signal_type': None, 'Exit_SMA20': None,\n",
        "                        'Exit_RSI': None, 'Exit_RSI_MA': None, 'Exit_ATR': None, 'Exit_ADX': None,\n",
        "                        'Exit_Volatility': None, 'Exit_Breakout_Detected': None,\n",
        "                        'Exit_Breakdown_Detected': None, 'Exit_Bullish_Candlestick_Name': None,\n",
        "                        'Exit_Bearish_Candlestick_Name': None, 'Exit_Bullish_Chart_Pattern_Detected': None,\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': None, 'Exit_shares': None,\n",
        "                        'Exit_cost': None, 'Exit_revenue': None, 'PnL_trade': None,\n",
        "                        'Trade_type': None, 'Profit_loss': None, 'Exit_reason': None,\n",
        "                        'Slippage': None, 'Commission_Fees': None, 'Trade_Duration': None,\n",
        "                        'Exit_Order_Type': None\n",
        "                    }\n",
        "                    # Initialize 'Current_trailing_stop' with the initial 'Stop_loss_price' if a trailing method is specified\n",
        "                    if pd.notna(self.positions[instrument_key].get('Trailing_stop_method')):\n",
        "                         self.positions[instrument_key]['Current_trailing_stop'] = self.positions[instrument_key].get('Stop_loss_price')\n",
        "                         logger.debug(f\"Initialized Trailing Stop for {instrument_key} at {timestamp} to initial SL: {self.positions[instrument_key].get('Current_trailing_stop'):.4f}\")\n",
        "\n",
        "\n",
        "                    # --- Add debug logging for Entry columns here ---\n",
        "                    logger.debug(f\"DEBUG Entry Data Point for {instrument_key} at {timestamp}:\")\n",
        "                    debug_cols_to_check = [\n",
        "                        'Trend', 'SMA20', 'RSI', 'RSI_MA', 'ATR', 'ADX', 'Volatility',\n",
        "                        'Breakout_Detected', 'Breakdown_Detected',\n",
        "                        # Corrected debug column names to match expected input data\n",
        "                        'Bullish_Candlestick_Detected', 'Bearish_Candlestick_Detected',\n",
        "                        'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "                        'Currency', 'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "                        'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE', 'Current_trailing_stop',\n",
        "                        'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price', 'Exit_Trend',\n",
        "                        'Exit_signal_type', 'Exit_SMA20', 'Exit_RSI', 'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX',\n",
        "                        'Exit_Volatility', 'Exit_Breakout_Detected', 'Exit_Breakdown_Detected',\n",
        "                        'Exit_Bullish_Candlestick_Name', 'Exit_Bearish_Candlestick_Name',\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected', 'Exit_Bearish_Chart_Pattern_Detected',\n",
        "                        'Exit_cost'\n",
        "                    ]\n",
        "                    for col in debug_cols_to_check:\n",
        "                         logger.debug(f\"  {col}: {data_point.get(col, 'Column Not Found or None')}\")\n",
        "                    # --- End Debug Logging ---\n",
        "\n",
        "\n",
        "                    logger.info(f\"Executed BUY trade {trade_id} for {instrument_key} at {timestamp} @ {price} (Qty: {quantity_to_trade}). Costs: Slippage={entry_slippage:.4f}, Commission={entry_commission:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'BUY', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'slippage': entry_slippage, 'commission': entry_commission})\n",
        "                else:\n",
        "                    logger.warning(f\"Insufficient capital ({self.current_capital:.2f}) to BUY {instrument_key} at {price} (Cost: {cost:.2f}). Skipping trade {trade_id}.\")\n",
        "                    self.debug_log.append({'type': 'SKIP_BUY_CAPITAL', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Insufficient Capital'})\n",
        "\n",
        "            else:\n",
        "                # Already in a position, maybe add to it or skip depending on strategy rules\n",
        "                logger.debug(f\"Skipping BUY signal for {instrument_key} at {timestamp}. Already in a position.\")\n",
        "                self.debug_log.append({'type': 'SKIP_BUY_POSITION', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Already in Position'})\n",
        "\n",
        "\n",
        "        elif signal == 'SELL':\n",
        "            # For backtesting, a 'SELL' signal usually means closing a long position or opening a short position\n",
        "            # Let's assume 'SELL' means closing a long position if one exists for simplicity in this example.\n",
        "            # For a shorting strategy, you'd need different logic.\n",
        "            if instrument_key in self.positions and self.positions[instrument_key]['side'] == 'BUY':\n",
        "                # Use the dedicated close method\n",
        "                self.close_position_on_trigger(instrument_key, timestamp, price, 'Signal_SELL', data_point)\n",
        "\n",
        "            else:\n",
        "                # No matching long position to close, or maybe a shorting signal\n",
        "                # For this simple backtester, we'll just log and skip if no long position\n",
        "                logger.debug(f\"Skipping SELL signal for {instrument_key} at {timestamp}. No matching long position to close.\")\n",
        "                self.debug_log.append({'type': 'SKIP_SELL_NO_LONG', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'strategy': strategy_name, 'reason': 'No Long Position'})\n",
        "\n",
        "\n",
        "    def close_position_on_trigger(self, instrument_key: str, timestamp: datetime, closing_price: float, reason: str, exit_data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Closes an open position for a specific instrument due to a trigger (SL, TP, etc.).\n",
        "\n",
        "        Args:\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the closure (bar close time).\n",
        "            closing_price: The price at which the position is closed.\n",
        "            reason: The reason for closing ('Stop Loss', 'Take Profit', 'Signal_SELL', 'Forced_Close', 'Trailing Stop').\n",
        "            exit_data_point: The pandas Series representing the data row for this bar at exit.\n",
        "        \"\"\"\n",
        "        if instrument_key not in self.positions:\n",
        "            logger.warning(f\"Attempted to close non-existent position for {instrument_key} at {timestamp} (Reason: {reason}).\")\n",
        "            return\n",
        "\n",
        "        position = self.positions[instrument_key]\n",
        "\n",
        "        quantity_to_sell = position['quantity']\n",
        "        entry_price = position['entry_price']\n",
        "        entry_time = position['entry_time']\n",
        "        strategy_opened = position['strategy']\n",
        "        open_trade_id = position['trade_id']\n",
        "        side = position['side']\n",
        "\n",
        "        # Ensure side is 'BUY' for long position closure logic\n",
        "        if side != 'BUY':\n",
        "             logger.warning(f\"Attempted to close non-long position for {instrument_key} at {timestamp} (Side: {side}). Skipping.\")\n",
        "             return\n",
        "\n",
        "        revenue = quantity_to_sell * closing_price\n",
        "        self.current_capital += revenue\n",
        "\n",
        "        # Calculate Profit/Loss (Gross PnL) - For long positions\n",
        "        gross_pnl = (closing_price - entry_price) * quantity_to_sell\n",
        "\n",
        "        # Calculate exit costs (slippage and commission on exit)\n",
        "        exit_slippage = revenue * self.slippage_pct\n",
        "        exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "        self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "        # Calculate Net PnL\n",
        "        total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "        total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "        pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "        # Calculate Trade Duration\n",
        "        trade_duration = (timestamp - entry_time).total_seconds() if pd.notnull(timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "        # Generate a unique trade ID for the closing trade\n",
        "        close_trade_id = self.generate_trade_id(timestamp)\n",
        "\n",
        "        # Record completed trade - Populate all desired columns\n",
        "        trade_record = {\n",
        "            'open_trade_id': open_trade_id,\n",
        "            'close_trade_id': close_trade_id,\n",
        "            'instrument_key': instrument_key,\n",
        "            'instrument_type': position.get('instrument_type'),\n",
        "            'side': side,\n",
        "            'quantity': quantity_to_sell,\n",
        "            'entry_price': entry_price,\n",
        "            'entry_time': entry_time,\n",
        "            'exit_price': closing_price,\n",
        "            'exit_time': timestamp,\n",
        "            'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "            'strategy_opened': strategy_opened,\n",
        "            'strategy_closed': 'Backtester_Trigger' if reason not in ['Signal_SELL', 'Forced_Close'] else reason, # Indicate trigger closure or signal close\n",
        "            'Position_type': position.get('Position_type'),\n",
        "            'Entry_order_type': position.get('Entry_order_type'),\n",
        "            'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "            'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "            'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "            'Entry_shares': position.get('Entry_shares'),\n",
        "            'Entry_cost': position.get('Entry_cost'),\n",
        "            'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "            'Entry_Trend': position.get('Entry_Trend'),\n",
        "            'Entry_SMA20': position.get('Entry_SMA20'),\n",
        "            'Entry_RSI': position.get('Entry_RSI'),\n",
        "            'Entry_RSI_MA': position.get('Entry_RSI_MA'),\n",
        "            'Entry_ATR': position.get('Entry_ATR'),\n",
        "            'Entry_ADX': position.get('Entry_ADX'),\n",
        "            'Entry_Volatility': position.get('Entry_Volatility'),\n",
        "            'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'),\n",
        "            'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'),\n",
        "            'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'),\n",
        "            'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'),\n",
        "            'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'),\n",
        "            'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'),\n",
        "            'Instrument_Type': position.get('Instrument_Type'),\n",
        "            'Currency': position.get('Currency'),\n",
        "            'Slippage_Entry': position.get('Slippage_Entry'),\n",
        "            'Commission_Fees_Entry': position.get('Commission_Fees_Entry'),\n",
        "            'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "            'Risk_Amount': position.get('Risk_Amount'),\n",
        "            'Reward_Amount': position.get('Reward_Amount'),\n",
        "            'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "            'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "            # --- Exit-Specific Columns (Populated from exit_data_point) ---\n",
        "            'Exit_Trend': exit_data_point.get('Trend'),\n",
        "            'Exit_signal_type': reason, # The reason is the \"signal\" for exit\n",
        "            'Exit_SMA20': exit_data_point.get('SMA20'),\n",
        "            'Exit_RSI': exit_data_point.get('RSI'),\n",
        "            'Exit_RSI_MA': exit_data_point.get('RSI_MA'),\n",
        "            'Exit_ATR': exit_data_point.get('ATR'),\n",
        "            'Exit_ADX': exit_data_point.get('ADX'),\n",
        "            'Exit_Volatility': exit_data_point.get('Volatility'),\n",
        "            'Exit_Breakout_Detected': exit_data_point.get('Breakout_Detected'),\n",
        "            'Exit_Breakdown_Detected': exit_data_point.get('Breakdown_Detected'),\n",
        "            'Exit_Bullish_Candlestick_Name': exit_data_point.get('Bullish_Candlestick_Detected'),\n",
        "            'Exit_Bearish_Candlestick_Name': exit_data_point.get('Bearish_Candlestick_Detected'),\n",
        "            'Exit_Bullish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bullish_Chart_Pattern_Name'),\n",
        "            'Exit_Bearish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bearish_Chart_Pattern_Name'),\n",
        "            'Exit_shares': quantity_to_sell,\n",
        "            'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "            'Exit_revenue': revenue,\n",
        "            'PnL_trade': pnl_trade,\n",
        "            'Trade_type': f'Long Close ({reason})', # Indicate the closure type\n",
        "            'Profit_loss': pnl_trade,\n",
        "            'Exit_reason': reason,\n",
        "            'Exit_Order_Type': 'Market' if reason != 'Forced_Close_Error: No_Last_Price' else None, # Assume market order unless error\n",
        "\n",
        "            # Placeholder for other exit-specific details\n",
        "            'Current_trailing_stop': position.get('Current_trailing_stop'), # Capture the stop level that was active\n",
        "            'Trailing_stop_method': position.get('Trailing_stop_method'),\n",
        "            'Trailing_stop_value': position.get('Trailing_stop_value'), # The value used by the method (e.g., percentage, ATR multiplier)\n",
        "            'Stop_loss_price': position.get('Stop_loss_price'), # Initial Stop Loss\n",
        "\n",
        "            'Slippage': total_slippage,\n",
        "            'Commission_Fees': total_commission,\n",
        "            'Trade_Duration': trade_duration,\n",
        "        }\n",
        "        self.completed_trades.append(trade_record)\n",
        "\n",
        "        # Remove position\n",
        "        del self.positions[instrument_key]\n",
        "\n",
        "        logger.info(f\"Closed position {open_trade_id} for {instrument_key} at {timestamp} @ {closing_price} (Reason: {reason}). Net PnL: {pnl_trade:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "        self.debug_log.append({'type': 'CLOSE_TRIGGER', 'open_trade_id': open_trade_id, 'close_trade_id': close_trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': closing_price, 'quantity': quantity_to_sell, 'net_pnl': pnl_trade, 'reason': reason})\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the backtesting simulation bar by bar through the data.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting backtest simulation...\")\n",
        "\n",
        "        # Group data by timestamp first, then iterate through timestamps\n",
        "        grouped_by_time = self.data.groupby('timestamp')\n",
        "\n",
        "        for timestamp, time_slice_df in grouped_by_time:\n",
        "            logger.debug(f\"Processing timestamp: {timestamp}\")\n",
        "\n",
        "            # --- Check for Stop Loss, Take Profit, and Trailing Stop triggers BEFORE signal generation ---\n",
        "            # Iterate over a copy of the positions dictionary\n",
        "            positions_to_check = list(self.positions.keys())\n",
        "            for instrument_key in positions_to_check:\n",
        "                # Ensure the position still exists in case it was closed by another trigger\n",
        "                if instrument_key not in self.positions:\n",
        "                    continue # Position already closed\n",
        "\n",
        "                position = self.positions[instrument_key]\n",
        "                entry_price = position.get('entry_price')\n",
        "                stop_loss_price = position.get('Stop_loss_price') # Get SL from position details\n",
        "                reward_amount = position.get('Reward_Amount') # Get Reward from position details\n",
        "                position_side = position.get('side') # Get side from position details\n",
        "                trailing_stop_method = position.get('Trailing_stop_method')\n",
        "                current_trailing_stop = position.get('Current_trailing_stop')\n",
        "                trailing_stop_value = position.get('Trailing_stop_value') # The value for the method (e.g., percentage)\n",
        "\n",
        "\n",
        "                # Find the current bar data for this instrument in the current time slice\n",
        "                current_bar_data = time_slice_df[time_slice_df['instrument_key'] == instrument_key]\n",
        "\n",
        "                if current_bar_data.empty:\n",
        "                    logger.warning(f\"No data found for instrument {instrument_key} at timestamp {timestamp}. Cannot check triggers.\")\n",
        "                    continue # Skip trigger check for this instrument at this timestamp\n",
        "\n",
        "                # Get high, low, and close for trigger checks\n",
        "                current_high = current_bar_data['high'].iloc[0]\n",
        "                current_low = current_bar_data['low'].iloc[0]\n",
        "                current_close = current_bar_data['close'].iloc[0] # Use close for TP/SL check consistency\n",
        "\n",
        "\n",
        "                if pd.isna(current_high) or pd.isna(current_low) or pd.isna(current_close):\n",
        "                    logger.debug(f\"Invalid bar data (high, low, or close) for {instrument_key} at {timestamp}. Cannot check triggers.\")\n",
        "                    continue # Cannot check triggers with invalid bar data\n",
        "\n",
        "                # Also get the full data point Series for passing to close method\n",
        "                current_data_point = current_bar_data.iloc[0]\n",
        "\n",
        "\n",
        "                # --- Check Stop Loss (using Low price for long positions for more realistic check) ---\n",
        "                if position_side == 'BUY' and pd.notna(stop_loss_price) and current_low <= stop_loss_price:\n",
        "                    logger.info(f\"Stop Loss triggered for {instrument_key} at {timestamp}. Low: {current_low:.4f} <= SL: {stop_loss_price:.4f}. Closing @ {current_close:.4f}\")\n",
        "                    # Close at the trigger price (stop_loss_price) or the bar's low? Using close for simplicity now.\n",
        "                    # A more realistic model would use the stop_loss_price itself or low, adjusted for slippage.\n",
        "                    self.close_position_on_trigger(instrument_key, timestamp, current_close, 'Stop Loss', current_data_point)\n",
        "                    continue # Position closed, move to the next position check\n",
        "\n",
        "\n",
        "                # --- Check Take Profit (using High price for long positions for more realistic check) ---\n",
        "                take_profit_price = None\n",
        "                if pd.notna(entry_price) and pd.notna(reward_amount):\n",
        "                     # Assuming Reward_Amount is an absolute value add-on to entry price for long positions\n",
        "                    take_profit_price = entry_price + reward_amount\n",
        "\n",
        "                if position_side == 'BUY' and pd.notna(take_profit_price) and current_high >= take_profit_price:\n",
        "                    logger.info(f\"Take Profit triggered for {instrument_key} at {timestamp}. High: {current_high:.4f} >= TP: {take_profit_price:.4f}. Closing @ {current_close:.4f}\")\n",
        "                     # Close at the trigger price (take_profit_price) or the bar's high/close? Using close for simplicity now.\n",
        "                     # A more realistic model would use the take_profit_price itself or high, adjusted for slippage.\n",
        "                    self.close_position_on_trigger(instrument_key, timestamp, current_close, 'Take Profit', current_data_point)\n",
        "                    continue # Position closed, move to the next position check\n",
        "\n",
        "                # --- Check and Update Trailing Stop for Long Positions ---\n",
        "                if position_side == 'BUY' and pd.notna(trailing_stop_method) and pd.notna(trailing_stop_value):\n",
        "                     # Ensure Current_trailing_stop is initialized if not already\n",
        "                    if pd.isna(current_trailing_stop):\n",
        "                        # Initialize with the initial stop loss price or entry price minus value, depending on method\n",
        "                        # For simplicity, initialize with entry price - trailing_stop_value (assuming value is an offset)\n",
        "                        # This needs to be aligned with how 'Trailing_stop_value' is defined in the strategy\n",
        "                        current_trailing_stop = entry_price - trailing_stop_value # Example initialization\n",
        "                        self.positions[instrument_key]['Current_trailing_stop'] = current_trailing_stop\n",
        "                        logger.debug(f\"Initialized Current_trailing_stop for {instrument_key} to {current_trailing_stop:.4f} based on Trailing_stop_method: {trailing_stop_method}\")\n",
        "\n",
        "\n",
        "                    new_trailing_stop = None\n",
        "                    # Example trailing stop logic (needs implementation based on method)\n",
        "                    if trailing_stop_method == 'Percentage':\n",
        "                        # Trailing stop value is a percentage below the high\n",
        "                        new_trailing_stop = current_high * (1 - trailing_stop_value / 100.0)\n",
        "                    elif trailing_stop_method == 'ATR':\n",
        "                         # Trailing stop value is an ATR multiplier\n",
        "                         # You need the current ATR value available in data_point or calculated\n",
        "                         current_atr = data_point.get('ATR') # Get ATR from data_point\n",
        "                         if pd.notna(current_atr):\n",
        "                              new_trailing_stop = current_high - (trailing_stop_value * current_atr)\n",
        "                         else:\n",
        "                              logger.warning(f\"ATR value not found for {instrument_key} at {timestamp}. Cannot calculate ATR trailing stop.\")\n",
        "\n",
        "\n",
        "                    # Update trailing stop only if it moves favorably (up for long positions)\n",
        "                    if pd.notna(new_trailing_stop) and new_trailing_stop > current_trailing_stop:\n",
        "                        self.positions[instrument_key]['Current_trailing_stop'] = new_trailing_stop\n",
        "                        logger.debug(f\"Updated Trailing Stop for {instrument_key} at {timestamp} to {new_trailing_stop:.4f}\")\n",
        "\n",
        "\n",
        "                    # Check if the bar's low breaches the current trailing stop\n",
        "                    updated_trailing_stop = self.positions[instrument_key].get('Current_trailing_stop') # Get the potentially updated stop\n",
        "                    if pd.notna(updated_trailing_stop) and current_low <= updated_trailing_stop:\n",
        "                        logger.info(f\"Trailing Stop triggered for {instrument_key} at {timestamp}. Low: {current_low:.4f} <= TS: {updated_trailing_stop:.4f}. Closing @ {current_close:.4f}\")\n",
        "                        # Close at the trailing stop price (updated_trailing_stop) or the bar's low/close? Using close for simplicity.\n",
        "                        # A more realistic model would use the stop price itself or low, adjusted for slippage.\n",
        "                        self.close_position_on_trigger(instrument_key, timestamp, current_close, 'Trailing Stop', current_data_point)\n",
        "                        continue # Position closed, move to the next position check\n",
        "\n",
        "\n",
        "            # --- Process data for all instruments available at this timestamp for signals ---\n",
        "            # Filter out instruments for which positions were just closed by triggers\n",
        "            instruments_for_signal = time_slice_df[~time_slice_df['instrument_key'].isin(self.positions.keys())].copy()\n",
        "            # Add back instruments for which positions are still open (though they won't generate new signals of the same type usually)\n",
        "            # This might not be strictly necessary if your strategy logic correctly handles existing positions,\n",
        "            # but ensures all instrument data points are iterated through for potential trailing stop updates, MFE/MAE calculation, etc.\n",
        "            instruments_for_signal = pd.concat([instruments_for_signal, time_slice_df[time_slice_df['instrument_key'].isin(self.positions.keys())].copy()])\n",
        "            instruments_for_signal = instruments_for_signal.drop_duplicates(subset=['instrument_key']).reset_index(drop=True) # Remove duplicates if any\n",
        "\n",
        "\n",
        "            for index, data_point in instruments_for_signal.iterrows():\n",
        "                 instrument_key = data_point['instrument_key']\n",
        "                 current_price = data_point['close'] # Assume close price for execution\n",
        "\n",
        "                 # Debug capture (already done above, can be kept or moved)\n",
        "                 # self._debug_timestamps.append(timestamp)\n",
        "                 # self._debug_close_values.append(current_price)\n",
        "                 # self._debug_validity.append(pd.notna(current_price))\n",
        "\n",
        "\n",
        "                 # Ensure current_price is valid for trading (already checked above, but good redundancy)\n",
        "                 if pd.isna(current_price):\n",
        "                     logger.debug(f\"Skipping signal generation for {instrument_key} at {timestamp} due to invalid close price ({current_price}).\")\n",
        "                     self.debug_log.append({'type': 'SKIP_SIGNAL_PRICE_NAN', 'instrument': instrument_key, 'time': timestamp, 'reason': 'Invalid Price'})\n",
        "                     continue # Skip this data point if price is invalid\n",
        "\n",
        "\n",
        "                 # Check for signals from all active strategies for this data point\n",
        "                 for strategy_name, strategy_instance in self.active_strategies_instances.items():\n",
        "                     try:\n",
        "                         # Pass the single data_point (as a Series converted to DataFrame) to the strategy\n",
        "                         signal = strategy_instance.generate_signal(pd.DataFrame([data_point]))\n",
        "                         # Ensure signal is a string, handle potential None returns gracefully\n",
        "                         signal = str(signal).upper() if signal is not None else 'HOLD'\n",
        "\n",
        "                         if signal in ['BUY', 'SELL']:\n",
        "                             # Generate a unique trade ID for this potential trade using the bar's timestamp\n",
        "                             trade_id = self.generate_trade_id(timestamp) # Pass the historical timestamp\n",
        "                             # Pass the original data_point Series to execute_trade\n",
        "                             self.execute_trade(trade_id, instrument_key, timestamp, signal, strategy_name, current_price, data_point)\n",
        "\n",
        "                     except Exception as e:\n",
        "                         logger.error(f\"Error generating signal for {instrument_key} at {timestamp} using strategy '{strategy_name}': {e}\", exc_info=True)\n",
        "                         self.debug_log.append({'type': 'STRATEGY_ERROR', 'instrument': instrument_key, 'time': timestamp, 'strategy': strategy_name, 'error': str(e)})\n",
        "\n",
        "\n",
        "        # After iterating through all data, close any remaining open positions\n",
        "        self.close_all_positions(self.data['timestamp'].max()) # Use the timestamp of the last data point as exit time\n",
        "\n",
        "        logger.info(\"Backtest simulation completed.\")\n",
        "        logger.info(f\"Final Capital: {self.current_capital:.2f}\")\n",
        "        logger.info(f\"Number of completed trades: {len(self.completed_trades)}\")\n",
        "        logger.info(f\"Number of open positions remaining: {len(self.positions)}\")\n",
        "\n",
        "        # Return completed trades as a DataFrame for analysis\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "            # Ensure numeric columns are numeric\n",
        "            numeric_cols = [\n",
        "                'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "            ]\n",
        "            for col in numeric_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "            return completed_trades_df\n",
        "        else:\n",
        "            logger.warning(\"No completed trades recorded. Returning empty DataFrame.\")\n",
        "            return pd.DataFrame() # Return empty DataFrame if no trades\n",
        "\n",
        "\n",
        "    def close_all_positions(self, exit_timestamp: datetime):\n",
        "        \"\"\"\n",
        "        Closes all remaining open positions at the specified exit timestamp.\n",
        "        Assumes closing at the price of the last available bar for each instrument.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Closing all remaining {len(self.positions)} open positions at {exit_timestamp}...\")\n",
        "\n",
        "        # Get the last known price and data point for each instrument with an open position\n",
        "        last_data_points = self.data.groupby('instrument_key').tail(1).set_index('instrument_key')\n",
        "        last_prices = last_data_points['close'].to_dict()\n",
        "\n",
        "\n",
        "        positions_to_close = list(self.positions.keys()) # Iterate over a copy\n",
        "\n",
        "        for instrument_key in positions_to_close:\n",
        "            # Check if position still exists (wasn't closed by a trigger just before the end)\n",
        "            if instrument_key in self.positions:\n",
        "                position = self.positions[instrument_key]\n",
        "                closing_price = last_prices.get(instrument_key, np.nan) # Get last price, default to NaN if instrument not found\n",
        "\n",
        "                # Get the last data point for the instrument to capture exit conditions\n",
        "                last_data_point = last_data_points.get(instrument_key, pd.Series({})) # Use empty Series if no data found\n",
        "\n",
        "\n",
        "                if pd.notna(closing_price):\n",
        "                    # Use the dedicated close method for forced closure\n",
        "                    self.close_position_on_trigger(instrument_key, exit_timestamp, closing_price, 'Forced_Close', last_data_point)\n",
        "\n",
        "                else:\n",
        "                    logger.warning(f\"Could not find last price for {instrument_key}. Cannot close position {position['trade_id']}. Logging as unresolved.\")\n",
        "                    # Log as an unresolved position or assume zero PnL\n",
        "\n",
        "                    # Calculate Trade Duration even if closing price is NaN\n",
        "                    trade_duration = (exit_timestamp - position.get('entry_time')).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(position.get('entry_time')) else None\n",
        "\n",
        "                    # Transfer known costs\n",
        "                    entry_slippage = position.get('Slippage_Entry', 0)\n",
        "                    entry_commission = position.get('Commission_Fees_Entry', 0)\n",
        "\n",
        "                    unresolved_trade_record = {\n",
        "                        'open_trade_id': position.get('trade_id'),\n",
        "                        'close_trade_id': None, # No closing trade ID\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'),\n",
        "                        'side': position.get('side'),\n",
        "                        'quantity': position.get('quantity'),\n",
        "                        'entry_price': position.get('entry_price'),\n",
        "                        'entry_time': position.get('entry_time'),\n",
        "                        'exit_price': None, # No exit price\n",
        "                        'exit_time': exit_timestamp, # Use the requested exit timestamp\n",
        "                        'pnl': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'strategy_opened': position.get('strategy'),\n",
        "                        'strategy_closed': 'Backtester_Forced_Close_Error', # Indicate error\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('Entry_RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('Entry_ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Entry_Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': entry_slippage, # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close_Error', # Indicate forced close error\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': position.get('quantity'), # Shares that were supposed to be exited\n",
        "                        'Exit_cost': 0,\n",
        "                        'Exit_revenue': 0, # Assuming zero revenue if cannot close\n",
        "                        'PnL_trade': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Profit_loss': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Exit_reason': 'Backtester_Forced_Close_Error: No_Last_Price', # Reason for exit\n",
        "                        'Exit_Order_Type': None, # Could not execute exit order\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': position.get('Current_trailing_stop'), # Capture the stop level that was active\n",
        "                        'Trailing_stop_method': position.get('Trailing_stop_method'),\n",
        "                        'Trailing_stop_value': position.get('Trailing_stop_value'), # The value used by the method (e.g., percentage)\n",
        "                        'Stop_loss_price': position.get('Stop_loss_price'), # Initial Stop Loss\n",
        "\n",
        "\n",
        "                        'Slippage': entry_slippage, # Only entry slippage is known\n",
        "                        'Commission_Fees': entry_commission, # Only entry commission is known\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(unresolved_trade_record)\n",
        "\n",
        "                    # Remove position even if it couldn't be closed properly to prevent it from being processed again\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE_ERROR', 'open_trade_id': position['trade_id'], 'instrument': instrument_key, 'time': exit_timestamp, 'reason': 'Last price not available'})\n",
        "\n",
        "\n",
        "        logger.info(\"All remaining positions closed.\")\n",
        "\n",
        "\n",
        "    def analyze_backtest_results(self):\n",
        "        \"\"\"\n",
        "        Analyzes the completed trades and provides performance metrics.\n",
        "        Returns a DataFrame summarizing the analysis.\n",
        "        \"\"\"\n",
        "        logger.info(\"Analyzing backtest results...\")\n",
        "\n",
        "        if not self.completed_trades:\n",
        "            logger.warning(\"No completed trades to analyze.\")\n",
        "            return pd.DataFrame({'Message': ['No completed trades to analyze.']})\n",
        "\n",
        "        # 1. Access the self.completed_trades list and Create a pandas DataFrame\n",
        "        trades_df = pd.DataFrame(self.completed_trades)\n",
        "\n",
        "        # 3. Ensure that relevant columns are converted to appropriate numeric types\n",
        "        numeric_cols = [\n",
        "            'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "            'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "            'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "            'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "            'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "            'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "            'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "            'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Include other potentially numeric cols\n",
        "        ]\n",
        "        for col in numeric_cols:\n",
        "            if col in trades_df.columns:\n",
        "                trades_df[col] = pd.to_numeric(trades_df[col], errors='coerce')\n",
        "\n",
        "        # Handle potential NaN values during conversion - drop rows where PnL_trade (or pnl) is NaN\n",
        "        pnl_col_for_analysis = 'PnL_trade' if 'PnL_trade' in trades_df.columns else 'pnl'\n",
        "        if pnl_col_for_analysis in trades_df.columns:\n",
        "            # Only consider trades with a valid PnL for core analysis metrics\n",
        "            trades_df_analysis = trades_df.dropna(subset=[pnl_col_for_analysis]).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "        else:\n",
        "            logger.warning(\"Neither 'PnL_trade' nor 'pnl' column found for analysis.\")\n",
        "            return pd.DataFrame({'Message': ['No PnL column found for analysis.']})\n",
        "\n",
        "\n",
        "        if trades_df_analysis.empty:\n",
        "            logger.warning(\"No valid trades after numeric conversion/dropna for analysis. Analysis stopped.\")\n",
        "            return pd.DataFrame({'Message': ['No valid trades after numeric conversion/dropna for analysis.']})\n",
        "\n",
        "\n",
        "        # 4. Update the calculation of basic performance metrics using 'PnL_trade'\n",
        "        total_trades = len(trades_df_analysis)\n",
        "        total_pnl = trades_df_analysis[pnl_col_for_analysis].sum()\n",
        "\n",
        "        winning_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] > 0]\n",
        "        losing_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] < 0]\n",
        "        breakeven_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] == 0]\n",
        "\n",
        "        num_winning = len(winning_trades)\n",
        "        num_losing = len(losing_trades)\n",
        "        num_breakeven = len(breakeven_trades)\n",
        "\n",
        "        win_rate = (num_winning / total_trades) * 100 if total_trades > 0 else 0\n",
        "        avg_win = winning_trades[pnl_col_for_analysis].mean() if num_winning > 0 else 0\n",
        "        avg_loss = losing_trades[pnl_col_for_analysis].mean() if num_losing > 0 else 0\n",
        "        expectancy = (win_rate / 100) * avg_win + ((100 - win_rate) / 100) * avg_loss if total_trades > 0 else 0\n",
        "\n",
        "        # 5. Update Max Drawdown calculation to use 'PnL_trade' and sort by exit time\n",
        "        # Calculate cumulative PnL and then cumulative capital\n",
        "        trades_df_analysis = trades_df_analysis.sort_values(by='exit_time') # Sort by exit time for cumulative calculation\n",
        "\n",
        "        trades_df_analysis['cumulative_pnl'] = trades_df_analysis[pnl_col_for_analysis].cumsum()\n",
        "\n",
        "        # Add initial capital to cumulative PnL\n",
        "        trades_df_analysis['cumulative_capital'] = self.initial_capital + trades_df_analysis['cumulative_pnl']\n",
        "\n",
        "        # Calculate peak capital up to each point\n",
        "        trades_df_analysis['peak_capital'] = trades_df_analysis['cumulative_capital'].cummax()\n",
        "\n",
        "        # Calculate drawdown at each point\n",
        "        trades_df_analysis['drawdown'] = trades_df_analysis['peak_capital'] - trades_df_analysis['cumulative_capital']\n",
        "\n",
        "        # Calculate percentage drawdown\n",
        "        # Avoid division by zero if peak_capital is 0 or None\n",
        "        trades_df_analysis['pct_drawdown'] = trades_df_analysis.apply(\n",
        "            lambda row: (row['drawdown'] / row['peak_capital']) * 100 if row['peak_capital'] > 0 and pd.notna(row['peak_capital']) else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        max_drawdown_amount = trades_df_analysis['drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "        max_drawdown_pct = trades_df_analysis['pct_drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "\n",
        "\n",
        "        # 6. Update analysis summary metric names\n",
        "        analysis_summary = {\n",
        "            'Metric': [\n",
        "                'Initial Capital',\n",
        "                'Final Capital',\n",
        "                'Total PnL (Net)', # Indicate Net PnL\n",
        "                'Total Trades',\n",
        "                'Winning Trades (Net)', # Indicate Net PnL\n",
        "                'Losing Trades (Net)', # Indicate Net PnL\n",
        "                'Breakeven Trades (Net)', # Indicate Net PnL\n",
        "                'Win Rate (%) (Net PnL)', # Indicate Net PnL\n",
        "                'Average Win (Net)', # Indicate Net PnL\n",
        "                'Average Loss (Net)', # Indicate Net PnL\n",
        "                'Expectancy per Trade (Net)', # Indicate Net PnL\n",
        "                'Max Drawdown (Amount)',\n",
        "                'Max Drawdown (%)',\n",
        "            ],\n",
        "            'Value': [\n",
        "                self.initial_capital,\n",
        "                self.current_capital,\n",
        "                round(total_pnl, 2), # Format to 2 decimal places\n",
        "                total_trades,\n",
        "                num_winning,\n",
        "                num_losing,\n",
        "                num_breakeven,\n",
        "                round(win_rate, 2), # Format to 2 decimal places\n",
        "                round(avg_win, 2),\n",
        "                round(avg_loss, 2),\n",
        "                round(expectancy, 2),\n",
        "                round(max_drawdown_amount, 2),\n",
        "                round(max_drawdown_pct, 2),\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        analysis_df = pd.DataFrame(analysis_summary)\n",
        "\n",
        "        logger.info(\"Backtest analysis completed.\")\n",
        "        # You can print the analysis_df here or return it\n",
        "        # print(\"\\n--- Backtest Analysis Summary ---\")\n",
        "        # display(analysis_df) # Use display for notebooks\n",
        "\n",
        "        # 8. Ensure the method returns the updated analysis summary DataFrame\n",
        "        return analysis_df\n",
        "\n",
        "    def get_completed_trades(self):\n",
        "        \"\"\"Returns a DataFrame of completed trades.\"\"\"\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "                    # Ensure numeric columns are numeric\n",
        "                    numeric_cols = [\n",
        "                        'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                        'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                        'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                        'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                        'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                        'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                        'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                        'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                        'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "                    ]\n",
        "                    for col in numeric_cols:\n",
        "                        if col in completed_trades_df.columns:\n",
        "                            completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "                    return completed_trades_df\n",
        "                else:\n",
        "                    return pd.DataFrame() # Return empty DataFrame if no trades"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging level set to DEBUG for test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0587bc1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step implemented the basic trailing stop logic. Now, complete the subtask by ensuring the logic correctly handles different trailing stop methods ('Percentage' and 'ATR') and updates the 'Current_trailing_stop' value based on the current bar's high for long positions. Also, add the check to trigger position closure if the bar's low breaches the 'Current_trailing_stop'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2de452",
        "outputId": "7b0c9a63-db99-4ad7-f7db-bb0866e93755"
      },
      "source": [
        "# _1113_6BacktesterV3.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "import sys\n",
        "# from _012_instruments import get_instrument_type\n",
        "# --- Logging Configuration ---\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Also ensure the root logger has a handler and is set to DEBUG,\n",
        "# in case basicConfig was called elsewhere previously.\n",
        "if not logging.root.handlers:\n",
        "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "else:\n",
        "    # If handlers exist, ensure at least one handler's level is DEBUG\n",
        "    # and the root logger's level is DEBUG\n",
        "    logging.root.setLevel(logging.DEBUG)\n",
        "    handler_found = False\n",
        "    for handler in logging.root.handlers:\n",
        "        if isinstance(handler, logging.StreamHandler) and handler.stream in [sys.stdout, sys.stderr]:\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler_found = True\n",
        "    # If no suitable handler is found (e.g., only file handlers), add a StreamHandler\n",
        "    if not handler_found:\n",
        "         stream_handler = logging.StreamHandler(sys.stdout)\n",
        "         stream_handler.setLevel(logging.DEBUG)\n",
        "         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
        "         stream_handler.setFormatter(formatter)\n",
        "         logging.root.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "print(\"Logging level set to DEBUG for test.\")\n",
        "\n",
        "\n",
        "class BacktesterV3:\n",
        "    \"\"\"\n",
        "    A simple backtesting engine for evaluating trading strategies.\n",
        "    Processes historical data bar by bar, generates signals, and simulates trades.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, instrument_keys: list, active_strategies_instances: dict, initial_capital: float):\n",
        "        \"\"\"\n",
        "        Includes the same parameters as the original __init__\n",
        "\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            data: A pandas DataFrame containing historical market data for all instruments,\n",
        "                expected to have columns like 'timestamp', 'instrument_key',\n",
        "                'open', 'high', 'low', 'close', 'volume', etc. It is also expected\n",
        "                to contain pre-calculated indicator and pattern columns used by\n",
        "                the strategies and for recording trade details.\n",
        "            instrument_keys: A list of unique instrument keys present in the data.\n",
        "            active_strategies_instances: A dictionary where keys are strategy names\n",
        "                                        (strings) and values are instantiated strategy\n",
        "                                        objects with a `generate_signal(data_point)` method.\n",
        "            initial_capital: The starting capital for the backtest simulation.\n",
        "        \"\"\"\n",
        "        if data is None or data.empty:\n",
        "            raise ValueError(\"Input data DataFrame is None or empty.\")\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n",
        "        if data.index.name is not None:\n",
        "            logger.warning(\"Input data index is not None. Consider resetting the index before passing to Backtester.\")\n",
        "\n",
        "\n",
        "        # Ensure essential columns are present and sorted\n",
        "        required_columns = ['timestamp', 'instrument_key', 'open', 'high', 'low', 'close', 'high', 'low'] # Added high, low to required\n",
        "        # Define columns expected to be in the input data for recording trade details.\n",
        "        # These are typically pre-calculated indicators or pattern detection results.\n",
        "        entry_exit_data_columns_expected = [\n",
        "            'Trend', 'SMA20', 'RSI', 'RSIMA', 'ATR', 'ADX', 'Volatility',\n",
        "            'Breakout_Detected', 'Breakdown_Detected', 'Bullish_Candlestick_Detected',\n",
        "            'Bearish_Candlestick_Detected', 'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "            'name', 'interval', 'Currency',\n",
        "            'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "            'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price' # Added Trailing_stop_value\n",
        "        ]\n",
        "\n",
        "        # The backtester expects these columns to be pre-calculated and provided in the input data.\n",
        "        # Strategies generate signals based on these columns, and their values at the time of\n",
        "        # entry and exit are recorded in the completed_trades DataFrame.\n",
        "\n",
        "\n",
        "        # Perform a relaxed check: log a warning if potential entry/exit columns from data are missing\n",
        "        missing_data_cols = [col for col in entry_exit_data_columns_expected if col not in data.columns]\n",
        "        if missing_data_cols:\n",
        "            logger.warning(f\"Input data is missing expected indicator/pattern columns: {missing_data_cols}. These will be recorded as None in trade records. Ensure your data preparation includes these columns if strategies or analysis depend on them.\")\n",
        "\n",
        "\n",
        "        # Ensure mandatory required columns are present\n",
        "        missing_required = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_required:\n",
        "            raise ValueError(f\"Input data is missing mandatory required columns: {missing_required}\")\n",
        "\n",
        "\n",
        "        # Ensure timestamp is datetime and sorted\n",
        "        try:\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
        "                data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True) # Convert to UTC\n",
        "            # Drop rows where timestamp conversion failed\n",
        "            data = data.dropna(subset=['timestamp'])\n",
        "            # Sort by timestamp and then instrument_key to process bars chronologically per instrument\n",
        "            self.data = data.sort_values(by=['timestamp', 'instrument_key']).reset_index(drop=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing timestamp column in data: {e}\")\n",
        "\n",
        "\n",
        "        self.instrument_keys = instrument_keys\n",
        "        self.active_strategies_instances = active_strategies_instances\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # --- Backtesting State Variables ---\n",
        "        self.current_capital = initial_capital\n",
        "        self.positions = {}  # Dictionary to track open positions {instrument_key: {...entry details...}}\n",
        "        self.completed_trades = [] # List to store completed trades\n",
        "        self.trade_id_counter = 0 # Simple counter for trade IDs\n",
        "        self.debug_log = [] # List to store debug information\n",
        "\n",
        "        # Debug lists to capture values\n",
        "        self._debug_timestamps = []\n",
        "        self._debug_close_values = []\n",
        "        self._debug_validity = []\n",
        "\n",
        "        # Simple Slippage and Commission model (can be customized)\n",
        "        self.slippage_pct = 0.001  # 0.1% slippage per trade\n",
        "        self.commission_per_trade = 0.01 # $0.01 fixed commission per trade\n",
        "\n",
        "\n",
        "        logger.info(f\"BacktesterV2 initialized with {len(self.instrument_keys)} instruments and {len(self.active_strategies_instances)} active strategies.\")\n",
        "        logger.info(f\"Initial Capital: {self.initial_capital}\")\n",
        "        logger.info(f\"Data shape for backtesting: {self.data.shape}\")\n",
        "\n",
        "\n",
        "    def generate_trade_id(self, timestamp: datetime):\n",
        "        \"\"\"Generates a unique trade ID using a provided timestamp.\"\"\"\n",
        "        # Using microseconds to increase the chance of uniqueness\n",
        "        return timestamp.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    def execute_trade(self, trade_id: str, instrument_key: str, timestamp: datetime, signal: str, strategy_name: str, price: float, data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Simulates executing a trade based on a signal.\n",
        "\n",
        "        Args:\n",
        "            trade_id: Unique identifier for the trade.\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the trade execution (bar close time).\n",
        "            signal: The trading signal ('BUY' or 'SELL').\n",
        "            strategy_name: The name of the strategy generating the signal.\n",
        "            price: The execution price (typically the close price of the bar).\n",
        "            data_point: The pandas Series representing the data row for this bar. This Series\n",
        "                        is expected to contain pre-calculated indicator and pattern data\n",
        "                        used for entry/exit conditions and recording.\n",
        "        \"\"\"\n",
        "        # Determine instrument type to handle lot size/quantity logic\n",
        "        # instrument_type = get_instrument_type(instrument_key) # Removed due to import error\n",
        "        instrument_type = 'Unknown' # Placeholder\n",
        "\n",
        "\n",
        "        # Simple fixed quantity logic (can be replaced with dynamic position sizing)\n",
        "        quantity_to_trade = 1 # Example: trade 1 unit/lot\n",
        "\n",
        "        if signal == 'BUY':\n",
        "            # Check if we already have a position in this instrument (optional, depending on strategy)\n",
        "            if instrument_key not in self.positions:\n",
        "                # Simulate buying\n",
        "                cost = quantity_to_trade * price\n",
        "                # Check if we have enough capital\n",
        "                if self.current_capital >= cost:\n",
        "                    self.current_capital -= cost\n",
        "\n",
        "                    # Calculate entry costs (slippage and commission on entry)\n",
        "                    entry_slippage = cost * self.slippage_pct\n",
        "                    entry_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "\n",
        "                    self.current_capital -= (entry_slippage + entry_commission) # Deduct costs from capital\n",
        "\n",
        "                    # Capture entry-specific details from the data_point and other variables\n",
        "                    self.positions[instrument_key] = {\n",
        "                        'quantity': quantity_to_trade,\n",
        "                        'entry_price': price, # This is the execution price for this simple model\n",
        "                        'entry_time': timestamp,\n",
        "                        'strategy': strategy_name,\n",
        "                        'trade_id': trade_id,\n",
        "                        'instrument_type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'side': 'BUY', # Store trade side\n",
        "\n",
        "                        # --- Entry-Specific Columns (Populated from data_point at Entry) ---\n",
        "                        'Strategy_name': strategy_name,\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'name': data_point.get('name'), # Use .get() to avoid errors if column is missing\n",
        "                        'interval': data_point.get('interval'),\n",
        "                        'Position_type': 'Long', # Assuming BUY means Long position\n",
        "                        'Entry_order_type': 'Market', # Assuming market order execution on close\n",
        "                        'Entry_timestamp': timestamp,\n",
        "                        'Entry_price_trigger': None, # Not explicitly handled in this simple model\n",
        "                        'Entry_price_execution': price,\n",
        "                        'Entry_shares': quantity_to_trade, # Using quantity_to_trade as shares\n",
        "                        'Entry_cost': cost, # Gross cost before fees\n",
        "                        'Entry_signal_type': signal, # Ensure signal is captured\n",
        "                        'Entry_Trend': data_point.get('Trend'), # Capture Trend at Entry\n",
        "                        'Entry_SMA20': data_point.get('SMA20'), # Capture SMA20 at Entry\n",
        "                        'Entry_RSI': data_point.get('RSI'), # Capture RSI at Entry\n",
        "                        'Entry_RSI_MA': data_point.get('RSI_MA'), # Capture RSI_MA at Entry\n",
        "                        'Entry_ATR': data_point.get('ATR'), # Capture ATR at Entry\n",
        "                        'Entry_ADX': data_point.get('ADX'), # Capture ADX at Entry\n",
        "                        'Entry_Volatility': data_point.get('Volatility'), # Capture Volatility at Entry\n",
        "                        'Entry_Breakout_Detected': data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Entry\n",
        "                        'Entry_Breakdown_Detected': data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Entry\n",
        "                        # Corrected column names to match expected input data\n",
        "                        'Entry_Bullish_Candlestick_Name': data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bearish_Candlestick_Name': data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Entry\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Entry\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Entry\n",
        "                        'Instrument_Type': instrument_type, # Store instrument type (now placeholder)\n",
        "                        'Currency': data_point.get('Currency'),\n",
        "                        'Slippage_Entry': entry_slippage, # Store entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Store entry commission\n",
        "\n",
        "                        # Placeholder for other entry-specific details that might be calculated by strategy (e.g., initial stop/target)\n",
        "                        'Initial_Stop_Loss_Distance (%)': data_point.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': data_point.get('Risk_Amount'),\n",
        "                        'Reward_Amount': data_point.get('Reward_Amount'),\n",
        "\n",
        "\n",
        "                        # Placeholders for exit/other info that will be filled on close\n",
        "                        # These fields are included here so the structure is consistent for retrieval on exit,\n",
        "                        # even though their values are None at the time of entry.\n",
        "                         'Max_Favorable_Excursion_MFE': None, # Will be calculated on exit\n",
        "                         'Max_Adverse_Excursion_MAE': None, # Will be calculated on exit\n",
        "                        'Current_trailing_stop': None, # Need logic for trailing stops\n",
        "                        'Trailing_stop_method': data_point.get('Trailing_stop_method'), # Capture method from data point\n",
        "                        'Trailing_stop_value': data_point.get('Trailing_stop_value'), # Capture initial value from data point (if applicable)\n",
        "                        'Stop_loss_price': data_point.get('Stop_loss_price'), # Capture initial SL from data point\n",
        "\n",
        "\n",
        "                        'Exit_Trend': None, 'Exit_signal_type': None, 'Exit_SMA20': None,\n",
        "                        'Exit_RSI': None, 'Exit_RSI_MA': None, 'Exit_ATR': None, 'Exit_ADX': None,\n",
        "                        'Exit_Volatility': None, 'Exit_Breakout_Detected': None,\n",
        "                        'Exit_Breakdown_Detected': None, 'Exit_Bullish_Candlestick_Name': None,\n",
        "                        'Exit_Bearish_Candlestick_Name': None, 'Exit_Bullish_Chart_Pattern_Detected': None,\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': None, 'Exit_shares': None,\n",
        "                        'Exit_cost': None, 'Exit_revenue': None, 'PnL_trade': None,\n",
        "                        'Trade_type': None, 'Profit_loss': None, 'Exit_reason': None,\n",
        "                        'Slippage': None, 'Commission_Fees': None, 'Trade_Duration': None,\n",
        "                        'Exit_Order_Type': None\n",
        "                    }\n",
        "                    # Initialize 'Current_trailing_stop' with the initial 'Stop_loss_price' if a trailing method is specified\n",
        "                    if pd.notna(self.positions[instrument_key].get('Trailing_stop_method')):\n",
        "                         self.positions[instrument_key]['Current_trailing_stop'] = self.positions[instrument_key].get('Stop_loss_price')\n",
        "                         logger.debug(f\"Initialized Trailing Stop for {instrument_key} at {timestamp} to initial SL: {self.positions[instrument_key].get('Current_trailing_stop'):.4f}\")\n",
        "\n",
        "\n",
        "                    # --- Add debug logging for Entry columns here ---\n",
        "                    logger.debug(f\"DEBUG Entry Data Point for {instrument_key} at {timestamp}:\")\n",
        "                    debug_cols_to_check = [\n",
        "                        'Trend', 'SMA20', 'RSI', 'RSI_MA', 'ATR', 'ADX', 'Volatility',\n",
        "                        'Breakout_Detected', 'Breakdown_Detected',\n",
        "                        # Corrected debug column names to match expected input data\n",
        "                        'Bullish_Candlestick_Detected', 'Bearish_Candlestick_Detected',\n",
        "                        'Detected_Bullish_Chart_Pattern_Name', 'Detected_Bearish_Chart_Pattern_Name',\n",
        "                        'Currency', 'Initial_Stop_Loss_Distance (%)', 'Risk_Amount', 'Reward_Amount',\n",
        "                        'Max_Favorable_Excursion_MFE', 'Max_Adverse_Excursion_MAE', 'Current_trailing_stop',\n",
        "                        'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price', 'Exit_Trend',\n",
        "                        'Exit_signal_type', 'Exit_SMA20', 'Exit_RSI', 'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX',\n",
        "                        'Exit_Volatility', 'Exit_Breakout_Detected', 'Exit_Breakdown_Detected',\n",
        "                        'Exit_Bullish_Candlestick_Name', 'Exit_Bearish_Candlestick_Name',\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected', 'Exit_Bearish_Chart_Pattern_Detected',\n",
        "                        'Exit_cost'\n",
        "                    ]\n",
        "                    for col in debug_cols_to_check:\n",
        "                         logger.debug(f\"  {col}: {data_point.get(col, 'Column Not Found or None')}\")\n",
        "                    # --- End Debug Logging ---\n",
        "\n",
        "\n",
        "                    logger.info(f\"Executed BUY trade {trade_id} for {instrument_key} at {timestamp} @ {price} (Qty: {quantity_to_trade}). Costs: Slippage={entry_slippage:.4f}, Commission={entry_commission:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "                    self.debug_log.append({'type': 'BUY', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'slippage': entry_slippage, 'commission': entry_commission})\n",
        "                else:\n",
        "                    logger.warning(f\"Insufficient capital ({self.current_capital:.2f}) to BUY {instrument_key} at {price} (Cost: {cost:.2f}). Skipping trade {trade_id}.\")\n",
        "                    self.debug_log.append({'type': 'SKIP_BUY_CAPITAL', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Insufficient Capital'})\n",
        "\n",
        "            else:\n",
        "                # Already in a position, maybe add to it or skip depending on strategy rules\n",
        "                logger.debug(f\"Skipping BUY signal for {instrument_key} at {timestamp}. Already in a position.\")\n",
        "                self.debug_log.append({'type': 'SKIP_BUY_POSITION', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'quantity': quantity_to_trade, 'strategy': strategy_name, 'reason': 'Already in Position'})\n",
        "\n",
        "\n",
        "        elif signal == 'SELL':\n",
        "            # For backtesting, a 'SELL' signal usually means closing a long position or opening a short position\n",
        "            # Let's assume 'SELL' means closing a long position if one exists for simplicity in this example.\n",
        "            # For a shorting strategy, you'd need different logic.\n",
        "            if instrument_key in self.positions and self.positions[instrument_key]['side'] == 'BUY':\n",
        "                # Use the dedicated close method\n",
        "                self.close_position_on_trigger(instrument_key, timestamp, price, 'Signal_SELL', data_point)\n",
        "\n",
        "            else:\n",
        "                # No matching long position to close, or maybe a shorting signal\n",
        "                # For this simple backtester, we'll just log and skip if no long position\n",
        "                logger.debug(f\"Skipping SELL signal for {instrument_key} at {timestamp}. No matching long position to close.\")\n",
        "                self.debug_log.append({'type': 'SKIP_SELL_NO_LONG', 'trade_id': trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': price, 'strategy': strategy_name, 'reason': 'No Long Position'})\n",
        "\n",
        "\n",
        "    def close_position_on_trigger(self, instrument_key: str, timestamp: datetime, closing_price: float, reason: str, exit_data_point: pd.Series):\n",
        "        \"\"\"\n",
        "        Closes an open position for a specific instrument due to a trigger (SL, TP, etc.).\n",
        "\n",
        "        Args:\n",
        "            instrument_key: The instrument key for the trade.\n",
        "            timestamp: The timestamp of the closure (bar close time).\n",
        "            closing_price: The price at which the position is closed.\n",
        "            reason: The reason for closing ('Stop Loss', 'Take Profit', 'Signal_SELL', 'Forced_Close', 'Trailing Stop').\n",
        "            exit_data_point: The pandas Series representing the data row for this bar at exit.\n",
        "        \"\"\"\n",
        "        if instrument_key not in self.positions:\n",
        "            logger.warning(f\"Attempted to close non-existent position for {instrument_key} at {timestamp} (Reason: {reason}).\")\n",
        "            return\n",
        "\n",
        "        position = self.positions[instrument_key]\n",
        "\n",
        "        quantity_to_sell = position['quantity']\n",
        "        entry_price = position['entry_price']\n",
        "        entry_time = position['entry_time']\n",
        "        strategy_opened = position['strategy']\n",
        "        open_trade_id = position['trade_id']\n",
        "        side = position['side']\n",
        "\n",
        "        # Ensure side is 'BUY' for long position closure logic\n",
        "        if side != 'BUY':\n",
        "             logger.warning(f\"Attempted to close non-long position for {instrument_key} at {timestamp} (Side: {side}). Skipping.\")\n",
        "             return\n",
        "\n",
        "        revenue = quantity_to_sell * closing_price\n",
        "        self.current_capital += revenue\n",
        "\n",
        "        # Calculate Profit/Loss (Gross PnL) - For long positions\n",
        "        gross_pnl = (closing_price - entry_price) * quantity_to_sell\n",
        "\n",
        "        # Calculate exit costs (slippage and commission on exit)\n",
        "        exit_slippage = revenue * self.slippage_pct\n",
        "        exit_commission = self.commission_per_trade # Fixed commission per trade\n",
        "\n",
        "        self.current_capital -= (exit_slippage + exit_commission) # Deduct costs from capital\n",
        "\n",
        "        # Calculate Net PnL\n",
        "        total_slippage = position.get('Slippage_Entry', 0) + exit_slippage\n",
        "        total_commission = position.get('Commission_Fees_Entry', 0) + exit_commission\n",
        "        pnl_trade = gross_pnl - total_slippage - total_commission\n",
        "\n",
        "        # Calculate Trade Duration\n",
        "        trade_duration = (timestamp - entry_time).total_seconds() if pd.notnull(timestamp) and pd.notnull(entry_time) else None\n",
        "\n",
        "        # Generate a unique trade ID for the closing trade\n",
        "        close_trade_id = self.generate_trade_id(timestamp)\n",
        "\n",
        "        # Record completed trade - Populate all desired columns\n",
        "        trade_record = {\n",
        "            'open_trade_id': open_trade_id,\n",
        "            'close_trade_id': close_trade_id,\n",
        "            'instrument_key': instrument_key,\n",
        "            'instrument_type': position.get('instrument_type'),\n",
        "            'side': side,\n",
        "            'quantity': quantity_to_sell,\n",
        "            'entry_price': entry_price,\n",
        "            'entry_time': entry_time,\n",
        "            'exit_price': closing_price,\n",
        "            'exit_time': timestamp,\n",
        "            'pnl': gross_pnl, # Keep gross PnL for reference\n",
        "            'strategy_opened': strategy_opened,\n",
        "            'strategy_closed': 'Backtester_Trigger' if reason not in ['Signal_SELL', 'Forced_Close'] else reason, # Indicate trigger closure or signal close\n",
        "            'Position_type': position.get('Position_type'),\n",
        "            'Entry_order_type': position.get('Entry_order_type'),\n",
        "            'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "            'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "            'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "            'Entry_shares': position.get('Entry_shares'),\n",
        "            'Entry_cost': position.get('Entry_cost'),\n",
        "            'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "            'Entry_Trend': position.get('Entry_Trend'),\n",
        "            'Entry_SMA20': position.get('Entry_SMA20'),\n",
        "            'Entry_RSI': position.get('Entry_RSI'),\n",
        "            'Entry_RSI_MA': position.get('Entry_RSI_MA'),\n",
        "            'Entry_ATR': position.get('Entry_ATR'),\n",
        "            'Entry_ADX': position.get('Entry_ADX'),\n",
        "            'Entry_Volatility': position.get('Entry_Volatility'),\n",
        "            'Entry_Breakout_Detected': position.get('Entry_Breakout_Detected'),\n",
        "            'Entry_Breakdown_Detected': position.get('Breakdown_Detected'),\n",
        "            'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'),\n",
        "            'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'),\n",
        "            'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'),\n",
        "            'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'),\n",
        "            'Instrument_Type': position.get('Instrument_Type'),\n",
        "            'Currency': position.get('Currency'),\n",
        "            'Slippage_Entry': position.get('Slippage_Entry'),\n",
        "            'Commission_Fees_Entry': position.get('Commission_Fees_Entry'),\n",
        "            'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "            'Risk_Amount': position.get('Risk_Amount'),\n",
        "            'Reward_Amount': position.get('Reward_Amount'),\n",
        "            'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "            'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "            # --- Exit-Specific Columns (Populated from exit_data_point) ---\n",
        "            'Exit_Trend': exit_data_point.get('Trend'),\n",
        "            'Exit_signal_type': reason, # The reason is the \"signal\" for exit\n",
        "            'Exit_SMA20': exit_data_point.get('SMA20'),\n",
        "            'Exit_RSI': exit_data_point.get('RSI'),\n",
        "            'Exit_RSI_MA': exit_data_point.get('RSI_MA'),\n",
        "            'Exit_ATR': exit_data_point.get('ATR'),\n",
        "            'Exit_ADX': exit_data_point.get('ADX'),\n",
        "            'Exit_Volatility': exit_data_point.get('Volatility'),\n",
        "            'Exit_Breakout_Detected': exit_data_point.get('Breakout_Detected'),\n",
        "            'Exit_Breakdown_Detected': exit_data_point.get('Breakdown_Detected'),\n",
        "            'Exit_Bullish_Candlestick_Name': exit_data_point.get('Bullish_Candlestick_Detected'),\n",
        "            'Exit_Bearish_Candlestick_Name': exit_data_point.get('Bearish_Candlestick_Detected'),\n",
        "            'Exit_Bullish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bullish_Chart_Pattern_Name'),\n",
        "            'Exit_Bearish_Chart_Pattern_Detected': exit_data_point.get('Detected_Bearish_Chart_Pattern_Name'),\n",
        "            'Exit_shares': quantity_to_sell,\n",
        "            'Exit_cost': 0, # Assuming no cost to exit a long position\n",
        "            'Exit_revenue': revenue,\n",
        "            'PnL_trade': pnl_trade,\n",
        "            'Trade_type': f'Long Close ({reason})', # Indicate the closure type\n",
        "            'Profit_loss': pnl_trade,\n",
        "            'Exit_reason': reason,\n",
        "            'Exit_Order_Type': 'Market' if reason != 'Forced_Close_Error: No_Last_Price' else None, # Assume market order unless error\n",
        "\n",
        "            # Placeholder for other exit-specific details\n",
        "            'Current_trailing_stop': position.get('Current_trailing_stop'), # Capture the stop level that was active\n",
        "            'Trailing_stop_method': position.get('Trailing_stop_method'),\n",
        "            'Trailing_stop_value': position.get('Trailing_stop_value'), # The value used by the method (e.g., percentage)\n",
        "            'Stop_loss_price': position.get('Stop_loss_price'), # Initial Stop Loss\n",
        "\n",
        "            'Slippage': total_slippage,\n",
        "            'Commission_Fees': total_commission,\n",
        "            'Trade_Duration': trade_duration,\n",
        "        }\n",
        "        self.completed_trades.append(trade_record)\n",
        "\n",
        "        # Remove position\n",
        "        del self.positions[instrument_key]\n",
        "\n",
        "        logger.info(f\"Closed position {open_trade_id} for {instrument_key} at {timestamp} @ {closing_price} (Reason: {reason}). Net PnL: {pnl_trade:.2f}. Capital left: {self.current_capital:.2f}\")\n",
        "        self.debug_log.append({'type': 'CLOSE_TRIGGER', 'open_trade_id': open_trade_id, 'close_trade_id': close_trade_id, 'instrument': instrument_key, 'time': timestamp, 'price': closing_price, 'quantity': quantity_to_sell, 'net_pnl': pnl_trade, 'reason': reason})\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the backtesting simulation bar by bar through the data.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting backtest simulation...\")\n",
        "\n",
        "        # Group data by timestamp first, then iterate through timestamps\n",
        "        grouped_by_time = self.data.groupby('timestamp')\n",
        "\n",
        "        for timestamp, time_slice_df in grouped_by_time:\n",
        "            logger.debug(f\"Processing timestamp: {timestamp}\")\n",
        "\n",
        "            # --- Check for Stop Loss, Take Profit, and Trailing Stop triggers BEFORE signal generation ---\n",
        "            # Iterate over a copy of the positions dictionary\n",
        "            positions_to_check = list(self.positions.keys())\n",
        "            for instrument_key in positions_to_check:\n",
        "                # Ensure the position still exists in case it was closed by another trigger\n",
        "                if instrument_key not in self.positions:\n",
        "                    continue # Position already closed\n",
        "\n",
        "                position = self.positions[instrument_key]\n",
        "                entry_price = position.get('entry_price')\n",
        "                stop_loss_price = position.get('Stop_loss_price') # Get SL from position details\n",
        "                reward_amount = position.get('Reward_Amount') # Get Reward from position details\n",
        "                position_side = position.get('side') # Get side from position details\n",
        "                trailing_stop_method = position.get('Trailing_stop_method')\n",
        "                current_trailing_stop = position.get('Current_trailing_stop')\n",
        "                trailing_stop_value = position.get('Trailing_stop_value') # The value used by the method (e.g., percentage)\n",
        "\n",
        "\n",
        "                # Find the current bar data for this instrument in the current time slice\n",
        "                current_bar_data = time_slice_df[time_slice_df['instrument_key'] == instrument_key]\n",
        "\n",
        "                if current_bar_data.empty:\n",
        "                    logger.warning(f\"No data found for instrument {instrument_key} at timestamp {timestamp}. Cannot check triggers.\")\n",
        "                    continue # Skip trigger check for this instrument at this timestamp\n",
        "\n",
        "                # Get high, low, and close for trigger checks\n",
        "                current_high = current_bar_data['high'].iloc[0]\n",
        "                current_low = current_bar_data['low'].iloc[0]\n",
        "                current_close = current_bar_data['close'].iloc[0] # Use close for TP/SL check consistency\n",
        "\n",
        "\n",
        "                if pd.isna(current_high) or pd.isna(current_low) or pd.isna(current_close):\n",
        "                    logger.debug(f\"Invalid bar data (high, low, or close) for {instrument_key} at {timestamp}. Cannot check triggers.\")\n",
        "                    continue # Cannot check triggers with invalid bar data\n",
        "\n",
        "                # Also get the full data point Series for passing to close method\n",
        "                current_data_point = current_bar_data.iloc[0]\n",
        "\n",
        "\n",
        "                # --- Check Stop Loss (using Low price for long positions for more realistic check) ---\n",
        "                if position_side == 'BUY' and pd.notna(stop_loss_price) and current_low <= stop_loss_price:\n",
        "                    logger.info(f\"Stop Loss triggered for {instrument_key} at {timestamp}. Low: {current_low:.4f} <= SL: {stop_loss_price:.4f}. Closing @ {current_close:.4f}\")\n",
        "                    # Close at the trigger price (stop_loss_price) or the bar's low? Using close for simplicity now.\n",
        "                    # A more realistic model would use the stop_loss_price itself or low, adjusted for slippage.\n",
        "                    self.close_position_on_trigger(instrument_key, timestamp, current_close, 'Stop Loss', current_data_point)\n",
        "                    continue # Position closed, move to the next position check\n",
        "\n",
        "\n",
        "                # --- Check Take Profit (using High price for long positions for more realistic check) ---\n",
        "                take_profit_price = None\n",
        "                if pd.notna(entry_price) and pd.notna(reward_amount):\n",
        "                     # Assuming Reward_Amount is an absolute value add-on to entry price for long positions\n",
        "                    take_profit_price = entry_price + reward_amount\n",
        "\n",
        "                if position_side == 'BUY' and pd.notna(take_profit_price) and current_high >= take_profit_price:\n",
        "                    logger.info(f\"Take Profit triggered for {instrument_key} at {timestamp}. High: {current_high:.4f} >= TP: {take_profit_price:.4f}. Closing @ {current_close:.4f}\")\n",
        "                     # Close at the trigger price (take_profit_price) or the bar's high/close? Using close for simplicity now.\n",
        "                     # A more realistic model would use the take_profit_price itself or high, adjusted for slippage.\n",
        "                    self.close_position_on_trigger(instrument_key, timestamp, current_close, 'Take Profit', current_data_point)\n",
        "                    continue # Position closed, move to the next position check\n",
        "\n",
        "                # --- Check and Update Trailing Stop for Long Positions ---\n",
        "                if position_side == 'BUY' and pd.notna(trailing_stop_method) and pd.notna(trailing_stop_value):\n",
        "                     # Ensure Current_trailing_stop is initialized if not already\n",
        "                    if pd.isna(current_trailing_stop):\n",
        "                        # Initialize with the initial stop loss price or entry price minus value, depending on method\n",
        "                        # For simplicity, initialize with entry price - trailing_stop_value (assuming value is an offset)\n",
        "                        # This needs to be aligned with how 'Trailing_stop_value' is defined in the strategy\n",
        "                        current_trailing_stop = entry_price - trailing_stop_value # Example initialization\n",
        "                        self.positions[instrument_key]['Current_trailing_stop'] = current_trailing_stop\n",
        "                        logger.debug(f\"Initialized Current_trailing_stop for {instrument_key} at {timestamp} to {current_trailing_stop:.4f} based on Trailing_stop_method: {trailing_stop_method}\")\n",
        "\n",
        "\n",
        "                    new_trailing_stop = None\n",
        "                    # Example trailing stop logic (needs implementation based on method)\n",
        "                    if trailing_stop_method == 'Percentage':\n",
        "                        # Trailing stop value is a percentage below the high\n",
        "                        new_trailing_stop = current_high * (1 - trailing_stop_value / 100.0)\n",
        "                    elif trailing_stop_method == 'ATR':\n",
        "                         # Trailing stop value is an ATR multiplier\n",
        "                         # You need the current ATR value available in data_point or calculated\n",
        "                         current_atr = data_point.get('ATR') # Get ATR from data_point\n",
        "                         if pd.notna(current_atr):\n",
        "                              new_trailing_stop = current_high - (trailing_stop_value * current_atr)\n",
        "                         else:\n",
        "                              logger.warning(f\"ATR value not found for {instrument_key} at {timestamp}. Cannot calculate ATR trailing stop.\")\n",
        "\n",
        "\n",
        "                    # Update trailing stop only if it moves favorably (up for long positions)\n",
        "                    if pd.notna(new_trailing_stop) and pd.notna(current_trailing_stop) and new_trailing_stop > current_trailing_stop:\n",
        "                        self.positions[instrument_key]['Current_trailing_stop'] = new_trailing_stop\n",
        "                        logger.debug(f\"Updated Trailing Stop for {instrument_key} at {timestamp} to {new_trailing_stop:.4f}\")\n",
        "                    elif pd.isna(current_trailing_stop) and pd.notna(new_trailing_stop):\n",
        "                         # Initialize if it was NaN previously and a new stop can be calculated\n",
        "                         self.positions[instrument_key]['Current_trailing_stop'] = new_trailing_stop\n",
        "                         logger.debug(f\"Initialized Trailing Stop for {instrument_key} at {timestamp} to {new_trailing_stop:.4f} based on first valid calculation.\")\n",
        "\n",
        "\n",
        "                    # Check if the bar's low breaches the current trailing stop\n",
        "                    updated_trailing_stop = self.positions[instrument_key].get('Current_trailing_stop') # Get the potentially updated stop\n",
        "                    if pd.notna(updated_trailing_stop) and current_low <= updated_trailing_stop:\n",
        "                        logger.info(f\"Trailing Stop triggered for {instrument_key} at {timestamp}. Low: {current_low:.4f} <= TS: {updated_trailing_stop:.4f}. Closing @ {current_close:.4f}\")\n",
        "                        # Close at the trailing stop price (updated_trailing_stop) or the bar's low/close? Using close for simplicity.\n",
        "                        # A more realistic model would use the stop price itself or low, adjusted for slippage.\n",
        "                        self.close_position_on_trigger(instrument_key, timestamp, current_close, 'Trailing Stop', current_data_point)\n",
        "                        continue # Position closed, move to the next position check\n",
        "\n",
        "\n",
        "            # --- Process data for all instruments available at this timestamp for signals ---\n",
        "            # Filter out instruments for which positions were just closed by triggers\n",
        "            instruments_for_signal = time_slice_df[~time_slice_df['instrument_key'].isin(self.positions.keys())].copy()\n",
        "            # Add back instruments for which positions are still open (though they won't generate new signals of the same type usually)\n",
        "            # This might not be strictly necessary if your strategy logic correctly handles existing positions,\n",
        "            # but ensures all instrument data points are iterated through for potential trailing stop updates, MFE/MAE calculation, etc.\n",
        "            instruments_for_signal = pd.concat([instruments_for_signal, time_slice_df[time_slice_df['instrument_key'].isin(self.positions.keys())].copy()])\n",
        "            instruments_for_signal = instruments_for_signal.drop_duplicates(subset=['instrument_key']).reset_index(drop=True) # Remove duplicates if any\n",
        "\n",
        "\n",
        "            for index, data_point in instruments_for_signal.iterrows():\n",
        "                 instrument_key = data_point['instrument_key']\n",
        "                 current_price = data_point['close'] # Assume close price for execution\n",
        "\n",
        "                 # Debug capture (already done above, can be kept or moved)\n",
        "                 # self._debug_timestamps.append(timestamp)\n",
        "                 # self._debug_close_values.append(current_price)\n",
        "                 # self._debug_validity.append(pd.notna(current_price))\n",
        "\n",
        "\n",
        "                 # Ensure current_price is valid for trading (already checked above, but good redundancy)\n",
        "                 if pd.isna(current_price):\n",
        "                     logger.debug(f\"Skipping signal generation for {instrument_key} at {timestamp} due to invalid close price ({current_price}).\")\n",
        "                     self.debug_log.append({'type': 'SKIP_SIGNAL_PRICE_NAN', 'instrument': instrument_key, 'time': timestamp, 'reason': 'Invalid Price'})\n",
        "                     continue # Skip this data point if price is invalid\n",
        "\n",
        "\n",
        "                 # Check for signals from all active strategies for this data point\n",
        "                 for strategy_name, strategy_instance in self.active_strategies_instances.items():\n",
        "                     try:\n",
        "                         # Pass the single data_point (as a Series converted to DataFrame) to the strategy\n",
        "                         signal = strategy_instance.generate_signal(pd.DataFrame([data_point]))\n",
        "                         # Ensure signal is a string, handle potential None returns gracefully\n",
        "                         signal = str(signal).upper() if signal is not None else 'HOLD'\n",
        "\n",
        "                         if signal in ['BUY', 'SELL']:\n",
        "                             # Generate a unique trade ID for this potential trade using the bar's timestamp\n",
        "                             trade_id = self.generate_trade_id(timestamp) # Pass the historical timestamp\n",
        "                             # Pass the original data_point Series to execute_trade\n",
        "                             self.execute_trade(trade_id, instrument_key, timestamp, signal, strategy_name, current_price, data_point)\n",
        "\n",
        "                     except Exception as e:\n",
        "                         logger.error(f\"Error generating signal for {instrument_key} at {timestamp} using strategy '{strategy_name}': {e}\", exc_info=True)\n",
        "                         self.debug_log.append({'type': 'STRATEGY_ERROR', 'instrument': instrument_key, 'time': timestamp, 'strategy': strategy_name, 'error': str(e)})\n",
        "\n",
        "\n",
        "        # After iterating through all data, close any remaining open positions\n",
        "        self.close_all_positions(self.data['timestamp'].max()) # Use the timestamp of the last data point as exit time\n",
        "\n",
        "        logger.info(\"Backtest simulation completed.\")\n",
        "        logger.info(f\"Final Capital: {self.current_capital:.2f}\")\n",
        "        logger.info(f\"Number of completed trades: {len(self.completed_trades)}\")\n",
        "        logger.info(f\"Number of open positions remaining: {len(self.positions)}\")\n",
        "\n",
        "        # Return completed trades as a DataFrame for analysis\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "            # Ensure numeric columns are numeric\n",
        "            numeric_cols = [\n",
        "                'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "            ]\n",
        "            for col in numeric_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "            return completed_trades_df\n",
        "        else:\n",
        "            logger.warning(\"No completed trades recorded. Returning empty DataFrame.\")\n",
        "            return pd.DataFrame() # Return empty DataFrame if no trades\n",
        "\n",
        "\n",
        "    def close_all_positions(self, exit_timestamp: datetime):\n",
        "        \"\"\"\n",
        "        Closes all remaining open positions at the specified exit timestamp.\n",
        "        Assumes closing at the price of the last available bar for each instrument.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Closing all remaining {len(self.positions)} open positions at {exit_timestamp}...\")\n",
        "\n",
        "        # Get the last known price and data point for each instrument with an open position\n",
        "        last_data_points = self.data.groupby('instrument_key').tail(1).set_index('instrument_key')\n",
        "        last_prices = last_data_points['close'].to_dict()\n",
        "\n",
        "\n",
        "        positions_to_close = list(self.positions.keys()) # Iterate over a copy\n",
        "\n",
        "        for instrument_key in positions_to_close:\n",
        "            # Check if position still exists (wasn't closed by a trigger just before the end)\n",
        "            if instrument_key in self.positions:\n",
        "                position = self.positions[instrument_key]\n",
        "                closing_price = last_prices.get(instrument_key, np.nan) # Get last price, default to NaN if instrument not found\n",
        "\n",
        "                # Get the last data point for the instrument to capture exit conditions\n",
        "                last_data_point = last_data_points.get(instrument_key, pd.Series({})) # Use empty Series if no data found\n",
        "\n",
        "\n",
        "                if pd.notna(closing_price):\n",
        "                    # Use the dedicated close method for forced closure\n",
        "                    self.close_position_on_trigger(instrument_key, exit_timestamp, closing_price, 'Forced_Close', last_data_point)\n",
        "\n",
        "                else:\n",
        "                    logger.warning(f\"Could not find last price for {instrument_key}. Cannot close position {position['trade_id']}. Logging as unresolved.\")\n",
        "                    # Log as an unresolved position or assume zero PnL\n",
        "\n",
        "                    # Calculate Trade Duration even if closing price is NaN\n",
        "                    trade_duration = (exit_timestamp - position.get('entry_time')).total_seconds() if pd.notnull(exit_timestamp) and pd.notnull(position.get('entry_time')) else None\n",
        "\n",
        "                    # Transfer known costs\n",
        "                    entry_slippage = position.get('Slippage_Entry', 0)\n",
        "                    entry_commission = position.get('Commission_Fees_Entry', 0)\n",
        "\n",
        "                    unresolved_trade_record = {\n",
        "                        'open_trade_id': position.get('trade_id'),\n",
        "                        'close_trade_id': None, # No closing trade ID\n",
        "                        'instrument_key': instrument_key,\n",
        "                        'instrument_type': position.get('instrument_type'),\n",
        "                        'side': position.get('side'),\n",
        "                        'quantity': position.get('quantity'),\n",
        "                        'entry_price': position.get('entry_price'),\n",
        "                        'entry_time': position.get('entry_time'),\n",
        "                        'exit_price': None, # No exit price\n",
        "                        'exit_time': exit_timestamp, # Use the requested exit timestamp\n",
        "                        'pnl': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'strategy_opened': position.get('strategy'),\n",
        "                        'strategy_closed': 'Backtester_Forced_Close_Error', # Indicate error\n",
        "\n",
        "                        # --- Transfer Entry Details from Position ---\n",
        "                        'Strategy_name': position.get('Strategy_name'),\n",
        "                        'instrument_key': position.get('instrument_key'),\n",
        "                        'name': position.get('name'),\n",
        "                        'interval': position.get('interval'),\n",
        "                        'Position_type': position.get('Position_type'),\n",
        "                        'Entry_order_type': position.get('Entry_order_type'),\n",
        "                        'Entry_timestamp': position.get('Entry_timestamp'),\n",
        "                        'Entry_price_trigger': position.get('Entry_price_trigger'),\n",
        "                        'Entry_price_execution': position.get('Entry_price_execution'),\n",
        "                        'Entry_shares': position.get('Entry_shares'),\n",
        "                        'Entry_cost': position.get('Entry_cost'),\n",
        "                        'Entry_signal_type': position.get('Entry_signal_type'),\n",
        "                        'Entry_Trend': position.get('Entry_Trend'), # Get Trend at Entry from Position\n",
        "                        'Entry_SMA20': position.get('Entry_SMA20'), # Get SMA20 at Entry from Position\n",
        "                        'Entry_RSI': position.get('Entry_RSI'), # Get RSI at Entry from Position\n",
        "                        'Entry_RSI_MA': position.get('RSI_MA'), # Get RSI_MA at Entry from Position\n",
        "                        'Entry_ATR': position.get('Entry_ATR'), # Get ATR at Entry from Position\n",
        "                        'Entry_ADX': position.get('ADX'), # Get ADX at Entry from Position\n",
        "                        'Entry_Volatility': position.get('Entry_Volatility'), # Get Volatility at Entry from Position\n",
        "                        'Entry_Breakout_Detected': position.get('Breakout_Detected'), # Get Breakout_Detected at Entry from Position\n",
        "                        'Entry_Breakdown_Detected': position.get('Breakdown_Detected'), # Get Breakdown_Detected at Entry from Position\n",
        "                        'Entry_Bullish_Candlestick_Name': position.get('Entry_Bullish_Candlestick_Name'), # Get Bullish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bearish_Candlestick_Name': position.get('Entry_Bearish_Candlestick_Name'), # Get Bearish Candlestick Name/Flag at Entry from Position\n",
        "                        'Entry_Bullish_Chart_Pattern_Name': position.get('Entry_Bullish_Chart_Pattern_Name'), # Get Bullish Chart Pattern Name at Entry from Position\n",
        "                        'Entry_Bearish_Chart_Pattern_Name': position.get('Entry_Bearish_Chart_Pattern_Name'), # Get Bearish Chart Pattern Name at Entry from Position\n",
        "                        'Instrument_Type': position.get('Instrument_Type'), # Get Instrument Type at Entry from Position\n",
        "                        'Currency': position.get('Currency'), # Get Currency at Entry from Position\n",
        "                        'Slippage_Entry': entry_slippage, # Transfer entry slippage\n",
        "                        'Commission_Fees_Entry': entry_commission, # Transfer entry commission\n",
        "                        'Initial_Stop_Loss_Distance (%)': position.get('Initial_Stop_Loss_Distance (%)'),\n",
        "                        'Risk_Amount': position.get('Risk_Amount'),\n",
        "                        'Reward_Amount': position.get('Reward_Amount'),\n",
        "                        'Max_Favorable_Excursion_MFE': position.get('Max_Favorable_Excursion_MFE'),\n",
        "                        'Max_Adverse_Excursion_MAE': position.get('Max_Adverse_Excursion_MAE'),\n",
        "\n",
        "                        # --- Exit-Specific Columns (Populated from last_data_point or defaults) ---\n",
        "                        'Exit_Trend': last_data_point.get('Trend'), # Capture Trend at Forced Exit\n",
        "                        'Exit_signal_type': 'Forced_Close_Error', # Indicate forced close error\n",
        "                        'Exit_SMA20': last_data_point.get('SMA20'), # Capture SMA20 at Forced Exit\n",
        "                        'Exit_RSI': last_data_point.get('RSI'), # Capture RSI at Forced Exit\n",
        "                        'Exit_RSI_MA': last_data_point.get('RSI_MA'), # Capture RSI_MA at Forced Exit\n",
        "                        'Exit_ATR': last_data_point.get('ATR'), # Capture ATR at Forced Exit\n",
        "                        'Exit_ADX': last_data_point.get('ADX'), # Capture ADX at Forced Exit\n",
        "                        'Exit_Volatility': last_data_point.get('Volatility'), # Capture Volatility at Forced Exit\n",
        "                        'Exit_Breakout_Detected': last_data_point.get('Breakout_Detected'), # Capture Breakout_Detected at Forced Exit\n",
        "                        'Exit_Breakdown_Detected': last_data_point.get('Breakdown_Detected'), # Capture Breakdown_Detected at Forced Exit\n",
        "                        'Exit_Bullish_Candlestick_Name': last_data_point.get('Bullish_Candlestick_Detected'), # Capture Bullish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bearish_Candlestick_Name': last_data_point.get('Bearish_Candlestick_Detected'), # Capture Bearish Candlestick Name/Flag at Forced Exit\n",
        "                        'Exit_Bullish_Chart_Pattern_Detected': last_data_point.get('Detected_Bullish_Chart_Pattern_Name'), # Capture Bullish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_Bearish_Chart_Pattern_Detected': last_data_point.get('Detected_Bearish_Chart_Pattern_Name'), # Capture Bearish Chart Pattern Name at Forced Exit\n",
        "                        'Exit_shares': position.get('quantity'), # Shares that were supposed to be exited\n",
        "                        'Exit_cost': 0,\n",
        "                        'Exit_revenue': 0, # Assuming zero revenue if cannot close\n",
        "                        'PnL_trade': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Profit_loss': -(entry_slippage + entry_commission), # Only entry costs are known\n",
        "                        'Exit_reason': 'Backtester_Forced_Close_Error: No_Last_Price', # Reason for exit\n",
        "                        'Exit_Order_Type': None, # Could not execute exit order\n",
        "\n",
        "                         # Placeholder for other exit-specific details that might be calculated by strategy (e.g., trailing stop)\n",
        "                        'Current_trailing_stop': position.get('Current_trailing_stop'), # Capture the stop level that was active\n",
        "                        'Trailing_stop_method': position.get('Trailing_stop_method'),\n",
        "                        'Trailing_stop_value': position.get('Trailing_stop_value'), # The value used by the method (e.g., percentage)\n",
        "                        'Stop_loss_price': position.get('Stop_loss_price'), # Initial Stop Loss\n",
        "\n",
        "\n",
        "                        'Slippage': entry_slippage, # Only entry slippage is known\n",
        "                        'Commission_Fees': entry_commission, # Only entry commission is known\n",
        "                        'Trade_Duration': trade_duration,\n",
        "\n",
        "\n",
        "                    }\n",
        "                    self.completed_trades.append(unresolved_trade_record)\n",
        "\n",
        "                    # Remove position even if it couldn't be closed properly to prevent it from being processed again\n",
        "                    del self.positions[instrument_key]\n",
        "\n",
        "                    self.debug_log.append({'type': 'FORCED_CLOSE_ERROR', 'open_trade_id': position['trade_id'], 'instrument': instrument_key, 'time': exit_timestamp, 'reason': 'Last price not available'})\n",
        "\n",
        "\n",
        "        logger.info(\"All remaining positions closed.\")\n",
        "\n",
        "\n",
        "    def analyze_backtest_results(self):\n",
        "        \"\"\"\n",
        "        Analyzes the completed trades and provides performance metrics.\n",
        "        Returns a DataFrame summarizing the analysis.\n",
        "        \"\"\"\n",
        "        logger.info(\"Analyzing backtest results...\")\n",
        "\n",
        "        if not self.completed_trades:\n",
        "            logger.warning(\"No completed trades to analyze.\")\n",
        "            return pd.DataFrame({'Message': ['No completed trades to analyze.']})\n",
        "\n",
        "        # 1. Access the self.completed_trades list and Create a pandas DataFrame\n",
        "        trades_df = pd.DataFrame(self.completed_trades)\n",
        "\n",
        "        # 3. Ensure that relevant columns are converted to appropriate numeric types\n",
        "        numeric_cols = [\n",
        "            'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "            'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "            'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "            'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "            'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "            'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "            'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "            'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "            'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Include other potentially numeric cols\n",
        "        ]\n",
        "        for col in numeric_cols:\n",
        "            if col in trades_df.columns:\n",
        "                trades_df[col] = pd.to_numeric(trades_df[col], errors='coerce')\n",
        "\n",
        "        # Handle potential NaN values during conversion - drop rows where PnL_trade (or pnl) is NaN\n",
        "        pnl_col_for_analysis = 'PnL_trade' if 'PnL_trade' in trades_df.columns else 'pnl'\n",
        "        if pnl_col_for_analysis in trades_df.columns:\n",
        "            # Only consider trades with a valid PnL for core analysis metrics\n",
        "            trades_df_analysis = trades_df.dropna(subset=[pnl_col_for_analysis]).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "        else:\n",
        "            logger.warning(\"Neither 'PnL_trade' nor 'pnl' column found for analysis.\")\n",
        "            return pd.DataFrame({'Message': ['No PnL column found for analysis.']})\n",
        "\n",
        "\n",
        "        if trades_df_analysis.empty:\n",
        "            logger.warning(\"No valid trades after numeric conversion/dropna for analysis. Analysis stopped.\")\n",
        "            return pd.DataFrame({'Message': ['No valid trades after numeric conversion/dropna for analysis.']})\n",
        "\n",
        "\n",
        "        # 4. Update the calculation of basic performance metrics using 'PnL_trade'\n",
        "        total_trades = len(trades_df_analysis)\n",
        "        total_pnl = trades_df_analysis[pnl_col_for_analysis].sum()\n",
        "\n",
        "        winning_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] > 0]\n",
        "        losing_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] < 0]\n",
        "        breakeven_trades = trades_df_analysis[trades_df_analysis[pnl_col_for_analysis] == 0]\n",
        "\n",
        "        num_winning = len(winning_trades)\n",
        "        num_losing = len(losing_trades)\n",
        "        num_breakeven = len(breakeven_trades)\n",
        "\n",
        "        win_rate = (num_winning / total_trades) * 100 if total_trades > 0 else 0\n",
        "        avg_win = winning_trades[pnl_col_for_analysis].mean() if num_winning > 0 else 0\n",
        "        avg_loss = losing_trades[pnl_col_for_analysis].mean() if num_losing > 0 else 0\n",
        "        expectancy = (win_rate / 100) * avg_win + ((100 - win_rate) / 100) * avg_loss if total_trades > 0 else 0\n",
        "\n",
        "        # 5. Update Max Drawdown calculation to use 'PnL_trade' and sort by exit time\n",
        "        # Calculate cumulative PnL and then cumulative capital\n",
        "        trades_df_analysis = trades_df_analysis.sort_values(by='exit_time') # Sort by exit time for cumulative calculation\n",
        "\n",
        "        trades_df_analysis['cumulative_pnl'] = trades_df_analysis[pnl_col_for_analysis].cumsum()\n",
        "\n",
        "        # Add initial capital to cumulative PnL\n",
        "        trades_df_analysis['cumulative_capital'] = self.initial_capital + trades_df_analysis['cumulative_pnl']\n",
        "\n",
        "        # Calculate peak capital up to each point\n",
        "        trades_df_analysis['peak_capital'] = trades_df_analysis['cumulative_capital'].cummax()\n",
        "\n",
        "        # Calculate drawdown at each point\n",
        "        trades_df_analysis['drawdown'] = trades_df_analysis['peak_capital'] - trades_df_analysis['cumulative_capital']\n",
        "\n",
        "        # Calculate percentage drawdown\n",
        "        # Avoid division by zero if peak_capital is 0 or None\n",
        "        trades_df_analysis['pct_drawdown'] = trades_df_analysis.apply(\n",
        "            lambda row: (row['drawdown'] / row['peak_capital']) * 100 if row['peak_capital'] > 0 and pd.notna(row['peak_capital']) else 0,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        max_drawdown_amount = trades_df_analysis['drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "        max_drawdown_pct = trades_df_analysis['pct_drawdown'].max() if not trades_df_analysis.empty else 0\n",
        "\n",
        "\n",
        "        # 6. Update analysis summary metric names\n",
        "        analysis_summary = {\n",
        "            'Metric': [\n",
        "                'Initial Capital',\n",
        "                'Final Capital',\n",
        "                'Total PnL (Net)', # Indicate Net PnL\n",
        "                'Total Trades',\n",
        "                'Winning Trades (Net)', # Indicate Net PnL\n",
        "                'Losing Trades (Net)', # Indicate Net PnL\n",
        "                'Breakeven Trades (Net)', # Indicate Net PnL\n",
        "                'Win Rate (%) (Net PnL)', # Indicate Net PnL\n",
        "                'Average Win (Net)', # Indicate Net PnL\n",
        "                'Average Loss (Net)', # Indicate Net PnL\n",
        "                'Expectancy per Trade (Net)', # Indicate Net PnL\n",
        "                'Max Drawdown (Amount)',\n",
        "                'Max Drawdown (%)',\n",
        "            ],\n",
        "            'Value': [\n",
        "                self.initial_capital,\n",
        "                self.current_capital,\n",
        "                round(total_pnl, 2), # Format to 2 decimal places\n",
        "                total_trades,\n",
        "                num_winning,\n",
        "                num_losing,\n",
        "                num_breakeven,\n",
        "                round(win_rate, 2), # Format to 2 decimal places\n",
        "                round(avg_win, 2),\n",
        "                round(avg_loss, 2),\n",
        "                round(expectancy, 2),\n",
        "                round(max_drawdown_amount, 2),\n",
        "                round(max_drawdown_pct, 2),\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        analysis_df = pd.DataFrame(analysis_summary)\n",
        "\n",
        "        logger.info(\"Backtest analysis completed.\")\n",
        "        # You can print the analysis_df here or return it\n",
        "        # print(\"\\n--- Backtest Analysis Summary ---\")\n",
        "        # display(analysis_df) # Use display for notebooks\n",
        "\n",
        "        # 8. Ensure the method returns the updated analysis summary DataFrame\n",
        "        return analysis_df\n",
        "\n",
        "    def get_completed_trades(self):\n",
        "        \"\"\"Returns a DataFrame of completed trades.\"\"\"\n",
        "        if self.completed_trades:\n",
        "            completed_trades_df = pd.DataFrame(self.completed_trades)\n",
        "            # Ensure timestamp columns are datetime objects\n",
        "            timestamp_cols = ['entry_time', 'exit_time', 'Entry_timestamp'] # Add new timestamp columns\n",
        "            for col in timestamp_cols:\n",
        "                if col in completed_trades_df.columns:\n",
        "                    completed_trades_df[col] = pd.to_datetime(completed_trades_df[col], errors='coerce', utc=True)\n",
        "\n",
        "                    # Ensure numeric columns are numeric\n",
        "                    numeric_cols = [\n",
        "                        'Entry_price_trigger', 'Entry_price_execution', 'Entry_shares', 'Entry_cost',\n",
        "                        'Entry_Trend', 'Entry_SMA20', 'Entry_RSI', 'Entry_RSI_MA', 'Entry_ATR',\n",
        "                        'Entry_ADX', 'Entry_Volatility', 'Exit_Trend', 'Exit_SMA20', 'Exit_RSI',\n",
        "                        'Exit_RSI_MA', 'Exit_ATR', 'Exit_ADX', 'Exit_Volatility', 'Exit_shares',\n",
        "                        'Exit_cost', 'Exit_revenue', 'PnL_trade', 'Profit_loss', 'Initial_Stop_Loss_Distance (%)',\n",
        "                        'Risk_Amount', 'Reward_Amount', 'Max_Favorable_Excursion_MFE',\n",
        "                        'Max_Adverse_Excursion_MAE', 'Slippage', 'Commission_Fees', 'Trade_Duration',\n",
        "                        'Current_trailing_stop', 'Trailing_stop_method', 'Trailing_stop_value', 'Stop_loss_price',\n",
        "                        'Slippage_Entry', 'Commission_Fees_Entry', 'pnl', 'quantity', 'entry_price', 'exit_price' # Added original pnl and price/qty\n",
        "                    ]\n",
        "                    for col in numeric_cols:\n",
        "                        if col in completed_trades_df.columns:\n",
        "                            completed_trades_df[col] = pd.to_numeric(completed_trades_df[col], errors='coerce')\n",
        "\n",
        "                    return completed_trades_df\n",
        "                else:\n",
        "                    return pd.DataFrame() # Return empty DataFrame if no trades"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging level set to DEBUG for test.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_2_0_flash.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}